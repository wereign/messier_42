# Stellarium
[![GitHub release](https://img.shields.io/github/release/Stellarium/stellarium.svg)](https://github.com/Stellarium/stellarium/releases/latest)
[![GitHub Release Date](https://img.shields.io/github/release-date/Stellarium/stellarium.svg)](https://github.com/Stellarium/stellarium/releases/latest)
[![Github All Releases](https://img.shields.io/github/downloads/Stellarium/stellarium/total.svg)](https://github.com/Stellarium/stellarium/releases)
[![Backers and sponsors](https://img.shields.io/opencollective/all/stellarium.svg?style=flat)](https://opencollective.com/stellarium)
[![CI](https://github.com/Stellarium/stellarium/actions/workflows/ci.yml/badge.svg)](https://github.com/Stellarium/stellarium/actions/workflows/ci.yml)
[![Build status](https://ci.appveyor.com/api/projects/status/sw8j9l8q95ejkalo?svg=true)](https://ci.appveyor.com/project/alex-w/stellarium)
[![Coverage Status](https://coveralls.io/repos/github/Stellarium/stellarium/badge.svg)](https://coveralls.io/github/Stellarium/stellarium)
[![CodeFactor](https://www.codefactor.io/repository/github/stellarium/stellarium/badge)](https://www.codefactor.io/repository/github/stellarium/stellarium)
[![DOI:10.1558/jsa.17822](http://img.shields.io/badge/DOI-10.1558/jsa.17822-blue.svg)](https://doi.org/10.1558/jsa.17822)
[![DOI:10.5281/zenodo.8105939](http://img.shields.io/badge/DOI-10.5281/zenodo.8105939-blue.svg)](https://doi.org/10.5281/zenodo.8105939)

Stellarium is a free open source planetarium for your computer. It shows a realistic sky
in 3D, just like what you see with the naked eye, binoculars or a telescope.

If you are new to Stellarium, go to [www.stellarium.org](https://www.stellarium.org) for loads of additional information.

## Installation Instructions & Quick Start

Please refer to the [User Guide, Getting Started section](https://github.com/Stellarium/stellarium/releases/download/v23.3/stellarium_user_guide-23.3-1.pdf).

## Get & build the code

See instructions to [building Stellarium from source code](BUILDING.md).

## Full References and Credits

See the [full credit file](CREDITS.md).

## Contributing to Stellarium

See the [contributing guideline](CONTRIBUTING.md).

## Contributors

This project exists thanks to all the people who contribute! List of contributors [on Github](https://github.com/Stellarium/stellarium/graphs/contributors) (code contributors) and [on Open Collective page](https://opencollective.com/stellarium#contributors) (financial contributors).

## Our backers & sponsors

Thank you to all [our backers and sponsors](BACKERS.md)!  Become a [backer](https://opencollective.com/stellarium#backer) or [sponsor](https://opencollective.com/stellarium#sponsor).

## Code Signing
Windows packages of this program uses free code signing provided by [SignPath.io](https://signpath.io?utm_source=foundation&utm_medium=github&utm_campaign=stellarium), and a free code signing certificate by the [SignPath Foundation](https://signpath.org?utm_source=foundation&utm_medium=github&utm_campaign=stellarium)
=======
Astropy
=======

.. container::

    |Actions Status| |CircleCI Status| |Coverage Status| |PyPI Status| |Documentation Status| |Pre-Commit| |isort Status| |black| |Zenodo|

The Astropy Project (http://astropy.org/) is a community effort to develop a
single core package for Astronomy in Python and foster interoperability between
Python astronomy packages. This repository contains the core package which is
intended to contain much of the core functionality and some common tools needed
for performing astronomy and astrophysics with Python.

Releases are `registered on PyPI <https://pypi.org/project/astropy>`_,
and development is occurring at the
`project's GitHub page <http://github.com/astropy/astropy>`_.

For installation instructions, see the `online documentation <https://docs.astropy.org/>`_
or  `docs/install.rst <docs/install.rst>`_ in this source distribution.

Contributing Code, Documentation, or Feedback
---------------------------------------------

The Astropy Project is made both by and for its users, so we welcome and
encourage contributions of many kinds. Our goal is to keep this a positive,
inclusive, successful, and growing community by abiding with the
`Astropy Community Code of Conduct <http://www.astropy.org/about.html#codeofconduct>`_.

More detailed information on contributing to the project or submitting feedback
can be found on the `contributions <http://www.astropy.org/contribute.html>`_
page. A `summary of contribution guidelines <CONTRIBUTING.md>`_ can also be
used as a quick reference when you are ready to start writing or validating
code for submission.

Getting started with GitHub Codespaces
--------------------------------------

Codespaces is a cloud development environment supported by GitHub. None of the Astropy build machinery depends on it, but it is a convenient way to quickly get started doing development on Astropy.

To get started, create a codespace for this repository by clicking this 👇

|Codespaces|

A codespace will open in a web-based version of Visual Studio Code. The `dev container <.devcontainer/devcontainer.json>`_ is fully configured with software needed for this project. Feel free to take a look at `GitHub Codespaces Support <https://support.github.com/features/codespaces>`_ page for help.

**Note**: Dev containers is an open spec which is supported by `GitHub Codespaces <https://github.com/codespaces>`_ and `other tools <https://containers.dev/supporting>`_.

Supporting the Project
----------------------

|NumFOCUS| |Donate|

The Astropy Project is sponsored by NumFOCUS, a 501(c)(3) nonprofit in the
United States. You can donate to the project by using the link above, and this
donation will support our mission to promote sustainable, high-level code base
for the astronomy community, open code development, educational materials, and
reproducible scientific research.

License
-------

Astropy is licensed under a 3-clause BSD style license - see the
`LICENSE.rst <LICENSE.rst>`_ file.

.. |Actions Status| image:: https://github.com/astropy/astropy/workflows/CI/badge.svg
    :target: https://github.com/astropy/astropy/actions
    :alt: Astropy's GitHub Actions CI Status

.. |CircleCI Status| image::  https://img.shields.io/circleci/build/github/astropy/astropy/main?logo=circleci&label=CircleCI
    :target: https://circleci.com/gh/astropy/astropy
    :alt: Astropy's CircleCI Status

.. |Coverage Status| image:: https://codecov.io/gh/astropy/astropy/branch/main/graph/badge.svg
    :target: https://codecov.io/gh/astropy/astropy
    :alt: Astropy's Coverage Status

.. |PyPI Status| image:: https://img.shields.io/pypi/v/astropy.svg
    :target: https://pypi.org/project/astropy
    :alt: Astropy's PyPI Status

.. |Zenodo| image:: https://zenodo.org/badge/DOI/10.5281/zenodo.4670728.svg
   :target: https://doi.org/10.5281/zenodo.4670728
   :alt: Zenodo DOI

.. |Documentation Status| image:: https://img.shields.io/readthedocs/astropy/latest.svg?logo=read%20the%20docs&logoColor=white&label=Docs&version=stable
    :target: https://docs.astropy.org/en/stable/?badge=stable
    :alt: Documentation Status

.. |Pre-Commit| image:: https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white
   :target: https://github.com/pre-commit/pre-commit
   :alt: pre-commit

.. |isort Status| image:: https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat&labelColor=ef8336
    :target: https://pycqa.github.io/isort/
    :alt: isort Status

.. |black| image:: https://img.shields.io/badge/code%20style-black-000000.svg
    :target: https://github.com/psf/black

.. |NumFOCUS| image:: https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A
    :target: http://numfocus.org
    :alt: Powered by NumFOCUS

.. |Donate| image:: https://img.shields.io/badge/Donate-to%20Astropy-brightgreen.svg
    :target: https://numfocus.salsalabs.org/donate-to-astropy/index.html

.. |Codespaces| image:: https://github.com/codespaces/badge.svg
    :target: https://github.com/codespaces/new?hide_repo_select=true&ref=main&repo=2081289
    :alt: Open in GitHub Codespaces


If you locally cloned this repo before 7 Apr 2021
-------------------------------------------------

The primary branch for this repo has been transitioned from ``master`` to
``main``.  If you have a local clone of this repository and want to keep your
local branch in sync with this repo, you'll need to do the following in your
local clone from your terminal::

   git fetch --all --prune
   # you can stop here if you don't use your local "master"/"main" branch
   git branch -m master main
   git branch -u origin/main main

If you are using a GUI to manage your repos you'll have to find the equivalent
commands as it's different for different programs. Alternatively, you can just
delete your local clone and re-clone!
| **`Release`** | **`Localized`** | **`License`** | **`Contribute`** |
|-------------------|---------------|---------------|---------------|
|[![GitHub release](https://img.shields.io/github/v/release/CelestiaProject/Celestia?label=Release)](https://celestiaproject.space/download.html) | [![Localization](https://img.shields.io/badge/Localized-85%25-green.svg)](#) | [![License](https://img.shields.io/github/license/CelestiaProject/Celestia?label=License)](https://github.com/CelestiaProject/Celestia/blob/master/COPYING) | [![Contribute](https://img.shields.io/badge/PRs-Welcome-brightgreen.svg)](#contributing) |

# Celestia
![Celestia](celestia-logo.png)<br>
**A real-time space simulation that lets you experience our universe in three dimensions.**

**Copyright © 2001-2023, Celestia Development Team**<br>
**Celestia website: https://celestiaproject.space**<br>
**Celestia Wikibook: https://en.wikibooks.org/wiki/Celestia**<br>
**Celestia forums: https://celestiaproject.space/forum/**<br>
**Celestia Subreddit: https://www.reddit.com/r/Celestiasoftware/**<br>
**Celestia Archive Repository: https://github.com/Anthony-B-Russo10/Celestia-Archive**
## License

This program is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free Software Foundation;
either version 2 of the License, or (at your option) any later version.

This program is distributed in the hope that it will be useful, but WITHOUT
ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details,
which you should have received along with this program (filename: COPYING).
If not, request a copy from:<br>
Free Software Foundation, Inc.<br>
59 Temple Place - Suite 330<br>
Boston, MA  02111-1307<br>
USA

## Getting started

Celestia will start up in a window, and if everything is working correctly,
you'll see Earth in front of a field of stars.  Displayed on-screen, is some
information about your target (Earth), your speed, and the current time
(Universal Time, so it'll probably be a few hours off from your computer's
clock).

Right drag the mouse to orbit Earth and you might see the Moon and some
familiar constellations.  Left dragging the mouse changes your orientation
also, but the camera rotates about its center instead of rotating around
Earth.  Rolling the mouse wheel will change your distance to Earth--you can
move light years away, then roll the wheel in the opposite direction to get
back to your starting location.  If your mouse lacks a wheel, you can use the
Home and End keys instead.

When running Celestia, you will usually have some object selected.  Currently,
it's Earth, but it could also be a star, moon, spacecraft, galaxy, or some
other object.  The simplest way to select an object is to click on it.  Try
clicking on a star to select it.  The information about Earth is replaced with
some details about the star.  Press G (or use the Navigation menu), and you'll
zoom through space toward the selected star.  If you press G again, you'll
approach the star even closer.

Press H to select our Sun, and then G to go back to our Sun.  Right click on
the sun to bring up a menu of planets and other objects in the solar system.
After selecting a planet from the menu, hit G again to travel toward it.  Once
there, hold down the right mouse button and drag to orbit the planet.

The Tour Guide is a list of some of the more interesting objects you can visit
in Celestia.  Select the Tour Guide option in the Navigation menu to display
the Tour Guide window.  Choose a destination from the list, click the Goto
button, and you're off.

That covers the very basics.  For a more in-depth look at Celestia and the
controls available to you, download the "Celestia User's Guide" (written by
Frank Gregorio), available in several languages, from:<br>
  https://celestiaproject.space/guides.html<br>
This web page also includes links to the Celestia README file translated into
Japanese.

### Star browser
By default, the Star Browser window displays a table of the 100 nearest stars,
along with their Distance, Apparent and Absolute Magnitude, and Type. Clicking
on the column headers will sort the stars.  The table is not continuously
updated, so if you travel to another star, you should press the Refresh button
to update the table for your current position.  The radio buttons beneath the
table let you switch between viewing a list of Nearest, Brightest, or 'With
planets' stars.  As with the solar system browser, clicking on any star name
in the table will select it.  Use this feature along with the Center and Go
To buttons to tour the stars visible from any night sky in the galaxy.

### Solar system browser
The Solar System Browser displays a window with a tree view of all the objects
in the nearest solar system (if there is one within a light year of your current
position.)  Clicking on the name of any object in the window will select it.
You can then use the Center or Go To buttons to display that object in the main
Celestia window.

### Selecting objects by name
Celestia provides several ways to select an object by name...
1. Choose 'Select Object' from the Navigation menu, type in the object name, and click OK.
2. Press Enter, type in the entire object name, and press Enter again.
3. Press Enter, type in the first few characters of the object name,
press the Tab key to move through the displayed listing until the object is highlighted,
then press Enter again.

You can use common names, Bayer designations or catalog numbers for stars.
Celestia currently supports the HIP, HD and SAO catalogs. Catalog numbers must
be entered with a space between the prefix and the catalog number.

### Known issues
For up-to-the-minute answers to some common problems encountered when running
Celestia, please view either the FAQ in the Help menu or take a look at the
"Celestia User's FAQ" located on the Celestia User's Forum:
https://celestiaproject.space/forum/

### User modifiable elements
You can modify how Celestia starts up each time you run it, by defining your
own start-up settings.  Simply open the file "start.cel" in a plain text
editor and follow the in-file instructions.  Also, view the celestia.cfg file
in a plain text editor to see additional settings.

Celestia allows you to easily add real, hypothetical, or fictional objects
by creating new catalog files. It is *not* recommended that you alter the
built-in data files; nearly all desired modifications and additions can be
made by placing new catalog files in Celestia's extras folders. There are three
types of catalog files:
* ssc (solar system catalog: planets, moons, spacecraft, etc.)
* stc (star catalog)
* dsc (deep sky catalog: galaxies, star clusters, and nebulae)

All three types of catalog file are text files that can be updated with your
favorite text editing program.

### Building from sources
See instructions in file [INSTALL.md](INSTALL.md).

## Contributions
| **`Authors`** | **`Contributors`** | **`Documentation`** | **`Other`** |
|-----------------|---------------------|------------------|-------------------|
| Chris Laurel, Clint Weisbrod, Fridger Schrempp, Bob Ippolito, Christophe Teyssier, Hank Ramsey, Grant Hutchison, Pat Suwalski, Toti, Da Woon Jung, Vincent Giangiulio, Andrew Tribick, Hleb Valoshka, Łukasz Buczyński, Li Linfeng | Deon Ramsey, Christopher Andre, Colin Walters, Peter Chapman, James Holmes, Harald Schmidt, Nils Larsson, Sergey Leonov, Alexell, Dmitry Brant, Janus | Selden Ball, Frank Gregorio, Hitoshi Suzuki, Christophe Teyssier, Diego Rodriguez, Don Goyette, Harald Schmidt | Creators of scientific database, texture maps, 3D models and used libraries, you can see in full README.|

### Contributing

**We welcome feedback, bug reports, and pull requests!**

For pull requests, please stick to the following guidelines:
* Be sure to test your code changes.
* Follow the existing code style (e.g., indents).
* Put a lot of comments into the code, if necessary.
* Separate unrelated changes into multiple pull requests.
# Mapping The Solar System

[![License: GPL v3](https://img.shields.io/badge/License-GPL%20v3-blue.svg?style=flat-square)](https://www.gnu.org/licenses/gpl-3.0)
[![GitHub Follow](https://img.shields.io/github/followers/eleanorlutz.svg?style=flat-square&logo=github&label=Follow)](https://github.com/eleanorlutz)

This repository explains how to make a map of the solar system using open-source code and data from NASA. Software used includes `Python 3.7.1`, `NASA HORIZONS`, `Illustrator CC 2019` and `Photoshop CC 2019`. If you have comments or suggestions for this tutorial, please let me know [on my blog](http://tabletopwhale.com/2019/06/10/the-solar-system.html)! You can buy the [finished map here](https://www.redbubble.com/people/eleanorlutz/works/39373641-an-asteroid-map-of-the-solar-system).

**Python dependencies:** `matplotlib` `astropy` `numpy` `pandas` `os` `time` `urllib`. Dependencies can be installed with `pip install -r requirements.txt`.

![Snapshot of final product](./readme_figures/asteroids.jpg)

## Special instructions for beginners

##### If you're new to coding:

[Software Carpentry](https://software-carpentry.org/) has great tutorials for [installing Python](https://carpentries.github.io/workshop-template/) (scroll down and follow the directions in  the Bash Shell and Python sections), [getting starting with Jupyter Notebooks](http://swcarpentry.github.io/python-novice-inflammation/setup/index.html), and [beginner-friendly Python programming](http://swcarpentry.github.io/python-novice-inflammation/aio/index.html). After you've installed Python using these tutorials, you can use [Git Desktop](https://desktop.github.com/) and the instructions in [this tutorial](https://help.github.com/en/desktop/contributing-to-projects/cloning-a-repository-from-github-desktop) to download the code and data in this tutorial.

##### If you're new to design:

You'll need software for editing raster and vector images ([this article](https://vector-conversions.com/vectorizing/raster_vs_vector.html) explains the difference). I use [Adobe Photoshop](https://www.adobe.com/products/photoshop.html) and [Illustrator](https://www.adobe.com/products/illustrator.html), but you can also use the free open-source programs [Gimp](https://www.gimp.org/downloads/) and [Inkscape](https://inkscape.org/release/inkscape-0.92.4/). There is no perfect software that fits everyone's needs, so you'll want to understand the pros and cons for the different [raster](https://www.colorexpertsbd.com/blog/brief-comparison-photoshop-gimp) and [vector](https://logosbynick.com/inkscape-vs-illustrator-vs-coreldraw/) programs before choosing.

## Table of Contents

1. [Gathering and processing data](#data)
2. [Map design in Python](#python)
3. [Map design in Illustrator and Photoshop](#illustrator_photoshop)
4. [References](#references)
5. [License](#license)

<a name="data"/>

## Gathering and processing data

![Data Sources](./readme_figures/data_asteroids.jpg)

#### Small-Body Database Search Engine

This map combines five different datasets from NASA PDS and NASA JPL. The primary dataset at the core of the project is the NASA [JPL Small-Body Database Search Engine](https://ssd.jpl.nasa.gov/sbdb_query.cgi), which I used to make a list of all known asteroids and comets in the solar system. To use this search engine, go to the linked website, fill in the data fields you want to request, and then download the data as a CSV. For this project, these were the data fields I requested:

- `object internal database ID `, `object primary SPK-ID`, `object full name/designation`, `object primary designation`: These were all of the available ID formats for asteroids and comets. I downloaded all of them in case I needed to join or reference different datasets later on in the project.
- `object IAU name`: This is the common name of the object. I used this data to annotate the map with labels.
- `comet designation prefix`, `Near-Earth Object (NEO) flag (Y/N)`, `Potentially Hazardous Asteroid (PHA) flag (Y/N)`, `orbit classification`: At first I wasn't sure what kind of color scheme or symbols I'd use for the map, so I downloaded all interesting-sounding parameters so I could look at them later. In the end I used orbit classifications to determine the color. The rest I didn't end up using, since the information was more or less similar to the orbit classifications.
- `object diameter (from equivalent sphere) (km)`: This is the diameter of each object (not all objects have a known diamater). In this map, each asteroid or comet is plotted proportional to its actual size on a log scale.
- `[q] perihelion distance (au)`: The perihelion distance is the closest distance from the object to the sun. I didn't use this data directly in the map, but I used this information to get an initial idea of the distribution of objects in the solar system.
- `sidereal orbital period (d)`: I use this data to customize the HORIZONS query time range for each object. For most objects I wanted to get the orbit path for a time period of 10 years. But for asteroids that move very quickly, I asked for a maximum of 1/4 the length of a full orbit.

I first downloaded this data into `all_asteroids.csv` and `all_comets.csv`. Next, I added in some missing data from the **TNO Diameter Dataset** (described below) and saved the result in `all_asteroids_wrangled.csv` and `all_comets_wrangled.csv`. Finally, I split the dataset into separate files for large asteroids >20km `large_asteroids.csv`, small asteroids 10-20km `small_asteroids.csv`, and asteroids of unknown size `any_inner_asteroids.csv` and `any_outer_asteroids.csv`. Since there were only 12 comets >10km, I combined all of them into one data file `large_comets.csv`.

#### Trans-Neptunian Object (TNO) Diameter Dataset

The JPL Small-Body Database doesn't seem to include diameter sizes for Trans-Neptunian Objects such as Pluto. I found this information in the [TNO and Centaur Diameters, Albedos, and Densities](https://sbn.psi.edu/pds/resource/tnocenalb.html) dataset from the NASA Planetary Science Institute, and merged it into the records downloaded from the Small-Body Database. Overall I found this dataset difficult to clean, so I might have made mistakes - please use the altered data with caution. These are the cleaning steps I used:

- In some columns, missing values are marked with `-99.999`, `-9.999`, `-999.9`, or some other such variant. Some diameters are also marked with a negative value (but are actual values, not `999`). I wasn't quite sure what these values meant, but regardless I removed any diameter values below 0.
- The designation ID is missing for Pluto, so I added the ID manually: `134340 Pluto`.
- This dataset contains multiple measurements per object, each one from a different scientific study. I used the median value for each object after removing studies with missing diameter values.
- The data appears to be a tab-delimited `.tab` file, but I couldn't find any tabs in either Python or text editing software. So I split the rows as best as I could by whitespace, but this caused several other issues:
  - In some columns, missing values are marked with a space, which was indistinguishable from delimiter whitespace. I manually replaced these spaces with `-` to mark missing data.
  - A couple objects have names with more than one word. I manually deleted the spaces on all these names so the columns would align on whitespace.

#### Planet and Moon Datasets

Planets and moons are not considered "small bodies", so they aren't included in the Small-Body Database. For planets and moons, I compiled two separate `CSV` files containing data for [planets](https://ssd.jpl.nasa.gov/?planet_phys_par) and [moons](https://ssd.jpl.nasa.gov/?sat_phys_par) using data published by the JPL Solar System Dynamics group and the [NASA Space Science Data Coordinated Archive](https://nssdc.gsfc.nasa.gov/planetary/factsheet/): `moons.csv`
and `planets.csv`.

#### Orbit Trajectory Dataset

You can calculate the position of asteroids based on  Keplerian orbital elements in the Small-Body Database, but most of the [tutorials I found](http://www.planetary.org/blogs/emily-lakdawalla/2012/3380.html) seemed to recommend using NASA HORIZONS instead. Additionally, the Keplerian element estimate doesn't take into account the gravitational fields of nearby objects, so I wanted to use the more accurate position data generated by HORIZONS.

##### The HORIZONS Web-Interface

The JPL HORIZONS system generates ephemerides for solar system objects (ephemerides describe movement trajectories over time). It can be accessed in several different ways, and the [Web-Interface](https://ssd.jpl.nasa.gov/horizons.cgi) is probably the most user-friendly. To use the Web-Interface, fill in the `Target Body`, `Observer Location`, and `Time Span` Settings and click `Generate Ephemeris`. For example, to  find the path of Venus as seen from Earth, set the  `Observer Location` to `Geocentric` and the `Target Body` to `Venus`:

![Orbit paths of the planets seen from Earth](./readme_figures/orbit_ribbons.jpg)

##### The HORIZONS Batch-Interface

The Web-Interface is great for single searches, but I needed the orbital trajectories of several thousand asteroids. So for this project I used the [HORIZONS Batch-Interface tutorial](https://ssd.jpl.nasa.gov/horizons_batch.cgi) to structure URL submissions for every asteroid, and then wrote a web scraper to request data for each object: `3_fetch_data.ipynb`.

I'm open-sourcing this code because HORIZONS specifically allows scraping, and even provides [tutorials](https://ssd.jpl.nasa.gov/horizons_batch.cgi) and [sample code](https://ssd.jpl.nasa.gov/txt/sample_horizons_batch_script). But if you're using a web scraper for the first time, it's important to know that scrapers can be unethical, either by accident or on purpose. Even in the best case scenario, you're using the bandwidth of the server owner, which costs money and resources. At worst, you might be [publicizing data that has real consequences for someone's safety and privacy](https://www.vice.com/en_us/article/8q88nx/70000-okcupid-users-just-had-their-data-published). Here are some questions I try to consider before running an automated scraper:
- Is there a public API or dataset I can use instead?
- Does the person who created this data know it's being collected by a scraper?
- Can the data identify or be traced back to real people?
- Does my scraping project help the data owners, or give back to their community in some way?
- Does my scraper identify itself accurately and provide contact information in case of problems?

In this project I've included all output files used in this map in the `data` folder, so if you'd like to recreate the map please use the provided data instead of running the spider again.

<a name="python"/>

##  Map design in Python

Next, I made about ten Python plots with different subsections of data. For example, I saved the orbit paths and scatterpoints as separate files, and I also saved the annotated text separately. I often split up data for plotting so I can easily apply section-specific effects in Photoshop or Illustrator.

![Different pieces of Matplotlib plotting](./readme_figures/asteroid_saved_pieces.png)

#### Mapping different types of orbital data

**Time:** At first I wanted to map each asteroid with an orbit tail reaching back 10 years. But many asteroids didn’t have enough data, and the inner asteroids moved so fast that the map was illegible from overlapping lines. So in the end the asteroid tails reach back to the last possible data point, or 10 years, or a quarter of the object’s orbit - whichever is smallest.. I plotted the full orbit length for all planets (except Neptune, which did not have data available before 1950).

I also spent a long time experimenting with different ways to plot orbit trajectories. Although I didn’t end up using the code, I still really like the orbit ribbons on the far left (the ribbon thickness shows the orbit movement in the z axis):

![Early sketches in visualizing orbit paths](./readme_figures/orbit_ribbons_moons.jpg)

**Distance from the sun:** I used a radial logarithmic plot to map orbit trajectories, with the minimum distance at the center of the plot set to 27,000,000km. In our solar system there are disproportionately more objects closer to the sun, so it's very hard to differentiate important objects like planets using a linear scale:

![Log vs linear axis for displaying the solar system](./readme_figures/linear_log.jpg)

**Diameter:** The size of each object is also scaled to a separate logarithmic scale. If the size is unknown (which is the majority of objects in the outer solar system) I marked the object using a dashed scatterpoint angled to the direction of motion.

**Name:** In the outer solar system there are only 78 named asteroids, so I annotated all of these. For the inner solar system, I tried to annotate all of the largest objects of each asteroid class (I removed some when multiple markers were overplotted on top of each other). I also included many of the named asteroids of relatively rare orbit classes. Finally, I annotated about 50 additional asteroids with names I liked, like Moomintroll, O’Keefe, and Sauron.

**Orbit direction:** In annotated objects, the direction of text follows the direction of motion (Ka'epaoka'awaela is the only named object in this map moving clockwise). In non-annotated objects the orbit tail shows the direction of motion.

**Orbit classification:** I also used colors to encode the orbit classifications of each asteroid. For maps with a lot of different elements, I like to save my design settings as a `CSV` file so I can easily try out different color schemes without rewriting any code. In this project the `./data/plotting_functions/colors.csv` file maps each type of object (comets, main belt asteroids, etc) to a specific color.

#### Saving Matplotlib figures

I usually save figures as a PDF so I can edit the text and shapes in Illustrator. There are a couple standard commands I use to export Matplotlib figures so they're easy to edit:

```python
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.backends.backend_pdf as pdf

# Export text as editable text instead of shapes:
matplotlib.rcParams['pdf.fonttype'] = 42

# Preserve the vertical order of embedded images:
matplotlib.rcParams['image.composite_image'] = False

# Remove borders and ticks from subplots:
ax.axis('off')

# Remove padding and margins from the figure and all its subplots
plt.margins(0,0)
plt.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)
plt.gca().xaxis.set_major_locator(plt.NullLocator())
plt.gca().yaxis.set_major_locator(plt.NullLocator())

# Save the Matplotlib figure as a PDF file:
pp = pdf.PdfPages('./savename.pdf', keep_empty=False)
pp.savefig(fig)
pp.close()

# If I don't need to edit vector paths I save the file as a
# PNG so I can import it directly into Photoshop:
plt.savefig('./savename.png', format='png', dpi=600, pad_inches=0, transparent=True)
```

After saving the figure, the `PDF` file needs to be edited so that each object can be manipulated individually. In Illustrator,  select everything in the file and then go to `Object` --> `Clipping Mask` --> `Release`. At this point you can also delete the background and axis border objects, if you included them in the output file.

<a name="illustrator_photoshop"/>

## Map design in Illustrator and Photoshop

I export Python figures to Illustrator and Photoshop because several great design features are impossible or very time-consuming in Matplotlib. I'm linking tutorials here for the features I use most often - [font alternates](https://helpx.adobe.com/illustrator/using/special-characters.html) and [ligatures](https://helpx.adobe.com/illustrator/using/special-characters.html#use_ligatures_and_contextual_alternates), [custom brushes](https://helpx.adobe.com/illustrator/using/brushes.html), [layering effects](https://helpx.adobe.com/photoshop/using/layer-effects-styles.html), [blur effects](https://helpx.adobe.com/photoshop/using/blur-gallery.html), [gradients along a path](http://blog.gilbertconsulting.com/2017/06/using-gradients-on-strokes-in.html), [variable width paths](https://iamsteve.me/blog/entry/creating-custom-stroke-width-profiles-in-illustrator), [type on a path](https://helpx.adobe.com/illustrator/using/creating-type-path.html), and [selecting objects by characteristic](https://helpx.adobe.com/illustrator/using/selecting-objects.html#select_objects_by_characteristic).

![Features not easily available in Python](./readme_figures/illustrator_photoshop_effects.png)

#### Layering in photoshop

I've included a small section of the map in the `figures` folder as the Photoshop file `asteroid_sample.psd`. The file is small enough to upload online, but since it still has the original layers you should be able to use it as a reference for layering effects.

![Layers of the Photoshop file](./readme_figures/photoshop_sample.jpg)

#### Gradient effect for orbit tails

One of the most important effects in this map is the gradient color in the orbit tails. You can [simulate this in Python](https://stackoverflow.com/questions/8500700/how-to-plot-a-gradient-color-line-in-matplotlib), but these methods are difficult to implement for a map with 18,000 paths, each containing ~4000 data points. Instead, you can apply gradient colors in Illustrator:

1. Select all strokes of the same color using `Select` -> `Same` -> `Stroke color`
2. Change the [stroke color to a gradient](http://blog.gilbertconsulting.com/2017/06/using-gradients-on-strokes-in.html) and select the `Stroke along path` option.
3. Change both sides of the gradient slider to the desired color. Set the right side to 100% opacity and the left to 0%.

#### Text Annotation in Illustrator

To emphasize the radial axis on this map, I decided to label the asteroid names radially as well. First I used Python to plot all of the asteroids I wanted to label in one `PDF` output file. Next I opened the file in Illustrator and manually adjusted each label. For most asteroids, I tried to place the text so that it followed the orbit tail just behind the scatterpoint of the object itself:
1. Use the `Type on a Path` tool to copy and paste the text for each object onto its orbit path vector.
2. Use `Paragraph` -> `Left indent` to offset the label from the object marker.
3. Use `Character` -> `Set the baseline shift` to center the text vertically along the orbit.

The asteroid belt objects were too close together to plot this way, so I shifted the names radially to a nearby spot with a little more room. To do this I needed a lot of concentric circle vectors (to type the names onto), as well as label lines pointing from the center of the object to the shifted name label. The python output already includes these label lines in the correct place and angle, but the length needs to be adjusted in Illustrator:
1. Use the `Direct Selection Tool` to move a vertex from this generated line to an annotation point near the text. While moving the point, the pink helper text `Line Extension` should be visible the entire time.
2. Use the `Direct Selection Tool` to remove the unused annotation vertex on the opposite side of the scatterpoint.

Making concentric circles for the labels was a little more involved:
1. Create one circle the size of the entire map, and one small circle centered in the middle.
2. Go to `Object` -> `Blend` -> `Blend Options` and set the Blend Options to `Specified Steps` : 200
3. Select both objects, then go to `Object` -> `Blend` -> `Make`
4. Select the new blended object, then go to `Object` -> `Blend`  -> `Expand`
5. Use the `Type on a Path` tool to copy and paste the text for each object onto one of the concentric circles an appropriate distance away.
6. Adjust the label line if necessary to point to the text.

#### Glow Effect and Text Shadows in Photoshop

To create a glow effect around an object, duplicate the object layer and go to `Filter` --> `Blur Gallery` --> `Field Blur`. For glowing text I usually create two blur layers set to 20% opacity - one with a `Blur` of 4px and the other 10px. In this map I added a glow effect to the text labels and all of the scatterpoints. You can also make a shadow effect in almost exactly the same way: Before applying the `Field Blur`, change the color of all objects in the duplicated layer to the color you'd like to use for the shadow. I think it's easiest to change the colors in the original Illustrator image instead of in Photoshop (especially for text and complex object shapes).

#### Color and font

I wanted the maps in this series to look cohesive, so I made a palette of ~70 different colors and picked from these choices in every map. I also used the same two fonts ([Redflowers](https://creativemarket.com/TypeandStudio/923689-RedFlower-Typeface) and [Moon](https://harvatt.house/store/moon-font)) in all maps. You're welcome to use the color palette and font styling if you'd like.

![Color palette used in all maps](./readme_figures/colors.jpg)

![Fonts used in all maps](./readme_figures/fonts.jpg)

<a name="references"/>

## References

  - [Astronomy](https://openstax.org/details/astronomy). Andrew Fraknoi, David Morrison, Sidney C. Wolff et al. OpenStax 2016.
  - [NASA HORIZONS](https://ssd.jpl.nasa.gov/horizons.cgi). NASA Jet Propulsion Laboratory, California Institute of Technology 2019.
  - [Object Classifications](https://pdssbn.astro.umd.edu/data_other/objclass.shtml). NASA PDS: Small Bodies Node. JPL Solar Dynamics Group.
  - [Planets and Pluto: Physical Characteristics](https://ssd.jpl.nasa.gov/?planet_phys_par). NASA Jet Propulsion Laboratory, California Institute of Technology 2001.
  - [Planetary Satellite Physical Parameters](https://ssd.jpl.nasa.gov/?sat_phys_par). NASA Jet Propulsion Laboratory, California Institute of Technology.
  - [NEO Earth Close Approaches](https://cneos.jpl.nasa.gov/ca/). NASA Jet Propulsion Laboratory, California Institute of Technology, CNEOS Center for Near Earth Object Studies. 2019.
  - [TNO and Centaur Diameters, Albedos, and Densities V1.0](https://sbn.psi.edu/pds/resource/tnocenalb.html). W.R. Johnston. NASA Planetary Data System, 2018
  - **Fonts:** [Moon](https://harvatt.house/store/moon-font) by Jack Harvatt and [RedFlower](https://creativemarket.com/TypeandStudio/923689-RedFlower-Typeface) by Type & Studio.
  - **Advice:** Thank you to Jeff Heer, Chloe Pursey, and Leah Willey for their helpful advice in making this map.

<a name="license"/>

## License

**Code:** All of the code in this repository is shared under the [GPL-3.0 license](https://www.gnu.org/licenses/gpl-3.0).

**Data:** The data in this repository belongs to the original authors of the data. Please use the references section to look up the original version. In cases where I edited or revised the data, I impose no additional restrictions to the original license. Any data files I created myself are shared under the [ODC Open Database License](https://opendatacommons.org/licenses/odbl/summary/).

**Artwork:** The artwork included in this repository are shared under a [Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License](https://creativecommons.org/licenses/by-nc-nd/4.0/).
*********
``sunpy``
*********

|Latest Version| |DOI| |repostatus| |python|
|ci| |codecov| |Docs|
|matrix|
|Powered by NumFOCUS|

.. |Latest Version| image:: https://img.shields.io/pypi/v/sunpy.svg
   :target: https://pypi.python.org/pypi/sunpy/
.. |DOI| image:: https://zenodo.org/badge/2165383.svg
   :target: https://zenodo.org/badge/latestdoi/2165383
.. |matrix| image:: https://img.shields.io/matrix/sunpy:openastronomy.org.svg?colorB=%23FE7900&label=Chat&logo=matrix&server_fqdn=matrix.org
   :target: https://app.element.io/#/room/#sunpy:openastronomy.org
.. |codecov| image:: https://codecov.io/gh/sunpy/sunpy/branch/main/graph/badge.svg
   :target: https://codecov.io/gh/sunpy/sunpy
.. |Powered by NumFOCUS| image:: https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A
   :target: https://numfocus.org
.. |CI| image:: https://github.com/sunpy/sunpy/actions/workflows/ci.yml/badge.svg?branch=main
   :target: https://github.com/sunpy/sunpy/actions/workflows/ci.yml
.. |Docs| image:: https://readthedocs.org/projects/sunpy/badge/?version=stable
   :target: https://docs.sunpy.org/en/stable/?badge=stable
   :alt: Documentation Status
.. |repostatus| image:: https://www.repostatus.org/badges/latest/active.svg
   :alt: Project Status: Active – The project has reached a stable, usable state and is being actively developed.
   :target: https://www.repostatus.org/#active
.. |python| image:: https://img.shields.io/pypi/pyversions/sunpy
   :alt: PyPI - Python Version

``sunpy`` is a Python software package that provides fundamental tools for accessing, loading and interacting with solar physics data in Python.
It is the core library of the `SunPy Project <https://sunpy.org/>`__.

For some examples of using ``sunpy`` see our `gallery <https://docs.sunpy.org/en/stable/generated/gallery/index.html>`__.
To see the latest changes in ``sunpy`` see our `changelog <https://docs.sunpy.org/en/stable/whatsnew/changelog.html>`__.

Installation
============

The recommended way to install ``sunpy`` is with `miniforge <https://github.com/conda-forge/miniforge#miniforge3>`__.
To install ``sunpy`` once miniforge is installed run the following command:

.. code:: bash

    $ conda install sunpy

For detailed installation instructions, see the `installation guide <https://docs.sunpy.org/en/stable/guide/installation.html>`__ in the ``sunpy`` docs.

Usage
=====

Here is a quick example of plotting an AIA image:

.. code:: python

   >>> import sunpy.map
   >>> from sunpy.data.sample import AIA_171_IMAGE
   >>>
   >>> import matplotlib.pyplot as plt
   >>>
   >>> aia = sunpy.map.Map(AIA_171_IMAGE)
   >>>
   >>> aia.plot()
   >>>
   >>> plt.show()

Getting Help
============

For more information or to ask questions about ``sunpy`` or any other SunPy library, check out:

-  `sunpy documentation <https://docs.sunpy.org/en/stable/>`__
-  `SunPy Chat`_
-  `SunPy mailing list <https://groups.google.com/forum/#!forum/sunpy>`__
-  `SunPy Community forum <https://community.openastronomy.org/c/sunpy/5>`__

Acknowledging or Citing ``sunpy``
=================================

If you use ``sunpy`` in your scientific work, we would appreciate your `citing it in your publications <https://sunpy.org/about#acknowledging-or-citing-sunpy>`__.
The continued growth and development of ``sunpy`` is dependent on the community being aware of ``sunpy``.

Contributing
============

If you would like to get involved, start by joining the `SunPy Chat`_ and check out our `Newcomers' guide <https://docs.sunpy.org/en/latest/dev_guide/contents/newcomers.html>`__.
This will walk you through getting set up for contributing.

Code of Conduct
===============

When you are interacting with the SunPy community you are asked to follow our `Code of Conduct <https://sunpy.org/coc>`__.

.. _SunPy Chat: https://app.element.io/#/room/#sunpy:openastronomy.org
# Trail Sense

> Use your Android phone's sensors to assist with wilderness treks or survival situations. Designed for entirely offline use.

[![](https://github.com/kylecorry31/Trail-Sense/workflows/Android%20CI/badge.svg)](https://github.com/kylecorry31/Trail-Sense/actions/workflows/android.yml)
[![](https://hosted.weblate.org/widgets/trail-sense/-/trail-sense-android/svg-badge.svg)](https://hosted.weblate.org/projects/trail-sense/trail-sense-android)
[![Nightly](https://github.com/kylecorry31/Trail-Sense/actions/workflows/nightly.yml/badge.svg)](https://github.com/kylecorry31/Trail-Sense/actions/workflows/nightly.yml)

Trail Sense is a tool, and just like any other tool that you bring into the wilderness, it's essential to have backup equipment and skills.

As featured in the [#WeArePlay](http://g.co/play/weareplay-usa) campaign!

See the [Technical Blog / Research](https://kylecorry.com/research/categories/trail-sense/)

<table>
    <tr>
        <th>F-Droid</th>
        <th>Google Play</th>
    </tr>
    <tr>
        <td>
            <a href="https://f-droid.org/en/packages/com.kylecorry.trail_sense">
                <img alt="Get it on F-Droid" src="https://fdroid.gitlab.io/artwork/badge/get-it-on.png" height="60" align="middle">
            </a>
        </td>
        <td>
            <a href="https://play.google.com/store/apps/details?id=com.kylecorry.trail_sense">
                <img alt="Get it on Google Play" src="https://play.google.com/intl/en_us/badges/static/images/badges/en_badge_web_generic.png" height="60" align="middle">
            </a>
        </td>
    </tr>
</table>

<img src="fastlane/metadata/android/en-US/images/featureGraphic.png">

## Table of Contents

- [Feature Roadmap](#feature-roadmap)
- [Goals](#goals)
- [Features](#features)
- [Privacy](#privacy)
- [Contributing](#contributing)
- [FAQ](#faq)
- [Support](#support)
- [Open Source Credits](#open-source-credits)
- [License](#license)

## Feature Roadmap
- [x] Q2 2023: Photo Maps
- [ ] Q3-Q4 2023: Usability (at a glance, tutorials, data export)
- [ ] Q1-Q2 2024: Augmented reality
- [ ] Q3 2024: Path navigation

## Goals
- Trail Sense must not use the Internet in any way, as I want the entire app usable when there is no Internet connection
- Features must provide some benefits to people using the app while hiking, in a survival situation, etc.
- Features should make use of the sensors on a phone rather than relying on stored information such as guides
- Features must be based on peer-reviewed science or be verified against real world data
- [Use Cases](https://github.com/kylecorry31/Trail-Sense/wiki/Use-Cases)

## Features

- Navigation
- Weather
- Astronomy
- Tides
- Clinometer
- And many more tools

See the need for a new feature? [Post it here!](https://github.com/kylecorry31/Trail-Sense/issues/59)

### Navigation

Trail Sense's compass helps you determine the direction of North and navigate to saved locations, known as beacons. In addition to navigating to beacons, you can also use the Backtrack feature to record waypoints and retrace your steps. This tool makes it easy to navigate and find your way in the great outdoors.

Example beacons: home, work, trailhead, campsite

<img src="fastlane/metadata/android/en-US/images/phoneScreenshots/1.png" alt="Navigation Screenshot" height="500"/>

### Weather

Trail Sense helps you stay informed about the weather, while completely offline. You can use it to predict if what the weather will be or be notified if a storm is likely to occur. It also displays the historical daily temperatures for your location, so you can be better prepared. This feature is only available on phones that have a barometer.

<img src="fastlane/metadata/android/en-US/images/phoneScreenshots/5.png" alt="Weather Screenshot" height="500"/>

### Astronomy

View reliable and accurate sunrise and sunset times for your location. In addition, you can stay informed about the phases of the moon, lunar eclipses, and meteor showers. These tools can help you plan your outdoor activities and ensure you have the necessary light for your endeavors.

<img src="fastlane/metadata/android/en-US/images/phoneScreenshots/4.png" alt="Astronomy Screenshot" height="500"/>

# Privacy

Location information gathered by this application does not leave your device (as a matter of fact, this app doesn't use the Internet at all). The altitude and pressure history for the last 48 hours is stored in local app storage - this is used to determine weather forecasts. The last known location is also stored in app preferences to allow faster load times and support app functionality when the GPS can not be reached. The beacons and paths store their location information in a local SQLite database. All of this information is cleared when you clear the app storage or delete it.

## Permissions
### Sensitive
- **POST_NOTIFICATIONS**
  - Allows Trail Sense to display notifications (backtrack, weather, sunset alerts, astronomy events, water boil timer, etc)
  - **When denied**: Alerts will not be displayed and some services may not function properly depending on your device manufacturer.
- **ACCESS_FINE_LOCATION / ACCESS_COARSE_LOCATION**
  - Allows Trail Sense to retrieve your location for navigation, weather (sea level calibration), and astronomy. 
  - **When denied**: You will have the ability to mock your location under Settings > Sensors > GPS. On Android 14+, backtrack and weather will be unavailable due to Android OS constraints.
- **ACCESS_BACKGROUND_LOCATION**
  - Allows Trail Sense to retrieve your location for sunset alerts while in the background. On some devices, this will also improve the reliability of backtrack and weather monitor (though shouldn't be needed on most devices).
  - **When denied**: If you travel and do not open Trail Sense, but have Sunset Alerts enabled, the times will likely be inaccurate.
- **ACTIVITY_RECOGNITION**
  - Allows Trail Sense to use your phone's pedometer for distance calculation.
  - **When denied**: The pedometer will not work.
- **CAMERA**
  - Allows Trail Sense to use your camera on the sighting compass, clinometer, and for taking photos used by the Cloud Scanner, QR Code Scanner, and Photo Maps.
  - **When denied**: You will not be able to use the sighting compass, camera clinometer, or QR Code Scanner. You will need to pick an existing photo to use for the Cloud Scanner or Photo Maps.
- **SCHEDULE_EXACT_ALARM**
  - Allows Trail Sense to post a notification at an exact time. This is used by the Clock tool (when updating system time) and Sunset Alerts.
  - **When denied**: The clock and sunset alerts may not be accurate (can be off by several minutes).
 
### Not sensitive (always granted)
- **RECEIVE_BOOT_COMPLETED**
  - Allows Trail Sense to restart when you reboot your device. This will re-enable backtrack, weather monitor, and several other background services.
- **FOREGROUND_SERVICE**
  - Allows Trail Sense to start foreground services, such as backtrack and weather monitor.
- **FLASHLIGHT**
  - Allows Trail Sense to control the phone's flashlight.
- **VIBRATE**
  - Allows Trail Sense to vibrate the phone. Used for haptic feedback on dials and on the metal detector tool.
- **WAKE_LOCK**
  - Allows Trail Sense to reliably run services such as backtrack and weather monitor, especially when the frequency is under 15 minutes.


# Debug features
Only available on debug APKs / builds via Android Studio
- Weather tool's barometer chart shows unsmoothed readings in background
- Weather history, elevation history, path elevations, and latest cloud scan are logged to the files/debug folder in Trail Sense data as CSV files
- Weather settings shows statistics timing (for weather monitor service)
- Paths show statistics about timing (for backtrack service)

# Contributing

- [Request a new feature](https://github.com/kylecorry31/Trail-Sense/issues/59)
- [Submit an issue](https://github.com/kylecorry31/Trail-Sense/issues)
- [Translate Trail Sense on Weblate](https://hosted.weblate.org/projects/trail-sense/trail-sense-android)
- [Test out new features](https://github.com/kylecorry31/Trail-Sense/issues/74)

If you choose to write a new feature yourself, send me a message to verify that it is something that I will accept into Trail Sense before your write it (if not, you can always fork this repo and create your own version of Trail Sense!). I will conduct a code review on incoming pull requests to verify they align nicely with the rest of the code base and the feature works as intended.

Issues marked with the help-wanted label are open for community contribution at any time (just submit a PR to main and I will review it), or leave a comment on the story to say you are working on it / ask for more details. Please leave a comment on any other issue before you work on them because they might not have all the details, I may not want it implemented yet, or I may have to implement it myself - for fun.

If an issue has a milestone and you would like to work on it, please leave a comment before working on it or creating a pull request. If you do not have the feature completed within 4 days of when I plan to release, I will implement it.

If you submit an issue, please be civil and constructive - I will consider all feedback, and if I choose not to implement your suggestion I will post my reasoning. If you are experiencing an issue, please include all relevant details to help me understand and reproduce the issue. If you disagree with a change, please describe why you disagree and how I can improve it (if applicable, please provide research / evidence so I can cross verify).

# FAQ
The FAQ has moved [to the wiki](https://github.com/kylecorry31/Trail-Sense/wiki/Frequently-Asked-Questions-(FAQ))

# Support

The best way to support Trail Sense is to send me your feedback, share how you are using it, test nightly builds, or post your ideas for new features.

# Open Source Credits

- Thank you to everyone who tried out this app and opened issues, suggested features, provided translations, or tested debug builds for me
- Thanks to @qwerty287 and @Portagoras for implementing several features and bugfixes
- Please see the in app licenses for all open source licenses
- Contributors and translators: https://github.com/kylecorry31/Trail-Sense/graphs/contributors

# License

[![License](https://img.shields.io/:license-mit-blue.svg?style=flat-square)](https://badges.mit-license.org)

- **[MIT license](LICENSE)**
# Astronomy Picture of the Day (APOD) microservice

A microservice written in Python with the [Flask micro framework](http://flask.pocoo.org).

## NOTES: 
### Code re-organization has occurred [2020-05-04]!
Code was reorganized to make it work more easily on AWS's Elastic Beanstalk service.

The changes over previous version were :
1. Moved main code out of the APOD folder and into the top level directory as Elastic Beanstalk had a hard time finding the initial python file unless it was in the top-level folder. 
2. Changed service.py to application.py
3. Changed references to app in application.py to application

You can find a frozen version of the previous code in the branch called <a href="https://github.com/nasa/apod-api/tree/prevCodeOrganization">"prevCodeOrganization"</a>

#### API Reliability
A very large number of people use the instance of this API that NASA has set up. If you need a extremely reliable version of this API, you likely want to stand up your own version of the API. You can do that with this code! All information that this API returns is actually just grabbed from the <a href='https://apod.nasa.gov/apod/astropix.html'>Astronomy Photo of the Day Website</a> (APOD).

#### Content Related Issues
No one watching this repository has anything to do with Astronomy Photo of the Day website, so we're unable to deal with issues directly related to their content. Please contact them directly.


# Table of contents
1. [Getting Started](#getting_started)
    1. [Standard environment](#standard_env)
    2. [`virtualenv` environment](#virtualenv)
    3. [`conda` environment](#conda)
2. [Docs](#docs)
3. [APOD parser](#TheAPODParser)
4. [Deployed](#Deployed)
5. [Feedback](#feedback)
6. [Author](#author)

&nbsp;
## Getting started <a name="getting_started"></a>

### Standard environment <a name="standard_env"></a>

1. Clone the repo
```bash
git clone https://github.com/nasa/apod-api
```
2. `cd` into the new directory
```bash
cd apod-api
```
3. Install dependencies into the project's `lib`
```bash
pip install -r requirements.txt -t lib
```
4. Add `lib` to your PYTHONPATH and run the server
```bash
PYTHONPATH=./lib python application.py
```
&nbsp;
### `virtualenv` environment <a name="virtualenv"></a>

1. Clone the repo
```bash
git clone https://github.com/nasa/apod-api
```
2. `cd` into the new directory
```bash
cd apod-api
```
3. Create a new virtual environment `env` in the directory
```bash
python -m venv venv
```
4. Activate the new environment
```bash
.\venv\Scripts\Activate
```
5. Install dependencies in new environment
```bash
pip install -r requirements.txt
```
6. Run the server locally
```bash
python application.py
```
&nbsp;
### `conda` environment <a name="conda"></a>

1. Clone the repo
```bash
git clone https://github.com/nasa/apod-api
```
2. `cd` into the new directory
```bash
cd apod-api
```
3. Create a new virtual environment `env` in the directory
```bash
conda create --prefix ./env
```
4. Activate the new environment
```bash
conda activate ./env
```
5. Install dependencies in new environment
```bash
pip install -r requirements.txt
```
6. Run the server locally
```bash
python application.py
```

### Run it in Docker

1. Clone the repo
```bash
git clone https://github.com/nasa/apod-api.git
```
2. `cd` into the new directory
```bash
cd apod-api
```
3. Build the image
```bash
docker build . -t apod-api
```
4. Run the image
```bash
docker run -p 5000:5000 apod-api
```

&nbsp;
## Docs <a name="docs"></a>

### Endpoint: `/<version>/apod`

There is only one endpoint in this service which takes 2 optional fields
as parameters to a http GET request. A JSON dictionary is returned nominally.

#### URL Search Params | query string parameters

- `api_key` | demo: `DEMO_KEY` | https://api.nasa.gov/#signUp
- `date` A string in YYYY-MM-DD format indicating the date of the APOD image (example: 2014-11-03).  Defaults to today's date.  Must be after 1995-06-16, the first day an APOD picture was posted.  There are no images for tomorrow available through this API.
- `concept_tags` A boolean `True|False` indicating whether concept tags should be returned with the rest of the response.  The concept tags are not necessarily included in the explanation, but rather derived from common search tags that are associated with the description text.  (Better than just pure text search.)  Defaults to False.
- `hd` A boolean `True|False` parameter indicating whether or not high-resolution images should be returned. This is present for legacy purposes, it is always ignored by the service and high-resolution urls are returned regardless.
- `count` A positive integer, no greater than 100. If this is specified then `count` randomly chosen images will be returned in a JSON array. Cannot be used in conjunction with `date` or `start_date` and `end_date`.
- `start_date` A string in YYYY-MM-DD format indicating the start of a date range. All images in the range from `start_date` to `end_date` will be returned in a JSON array. Cannot be used with `date`.
- `end_date` A string in YYYY-MM-DD format indicating that end of a date range. If `start_date` is specified without an `end_date` then `end_date` defaults to the current date.
- `thumbs` A boolean parameter `True|False` inidcating whether the API should return a thumbnail image URL for video files. If set to `True`, the API returns URL of video thumbnail. If an APOD is not a video, this parameter is ignored.

**Returned fields**

- `resource` A dictionary describing the `image_set` or `planet` that the response illustrates, completely determined by the structured endpoint.
- `concept_tags` A boolean reflection of the supplied option.  Included in response because of default values.
- `title` The title of the image.
- `date` Date of image. Included in response because of default values.
- `url` The URL of the APOD image or video of the day.
- `hdurl` The URL for any high-resolution image for that day. Returned regardless of 'hd' param setting but will be omitted in the response IF it does not exist originally at APOD.
- `media_type` The type of media (data) returned. May either be 'image' or 'video' depending on content.
- `explanation` The supplied text explanation of the image.
- `concepts` The most relevant concepts within the text explanation.  Only supplied if `concept_tags` is set to True.
- `thumbnail_url` The URL of thumbnail of the video. 
- `copyright` The name of the copyright holder.
- `service_version` The service version used.

**Example**

```bash
localhost:5000/v1/apod?api_key=DEMO_KEY&date=2014-10-01&concept_tags=True
```
<details><summary>See Return Object</summary>
<p>

```jsoniq
{
    resource: {
        image_set: "apod"
    },
    concept_tags: "True",
    date: "2013-10-01",
    title: "Filaments of the Vela Supernova Remnant",
    url: "http://apod.nasa.gov/apod/image/1310/velafilaments_jadescope_960.jpg",
    explanation: "The explosion is over but the consequences continue. About eleven
    thousand years ago a star in the constellation of Vela could be seen to explode,
    creating a strange point of light briefly visible to humans living near the
    beginning of recorded history. The outer layers of the star crashed into the
    interstellar medium, driving a shock wave that is still visible today. A roughly
    spherical, expanding shock wave is visible in X-rays. The above image captures some
    of that filamentary and gigantic shock in visible light. As gas flies away from the
    detonated star, it decays and reacts with the interstellar medium, producing light
    in many different colors and energy bands. Remaining at the center of the Vela
    Supernova Remnant is a pulsar, a star as dense as nuclear matter that rotates
    completely around more than ten times in a single second.",
    concepts: {
        0: "Astronomy",
        1: "Star",
        2: "Sun",
        3: "Milky Way",
        4: "Hubble Space Telescope",
        5: "Earth",
        6: "Nebula",
        7: "Interstellar medium"
    }
}
```

</p>
</details>


```bash
https://api.nasa.gov/planetary/apod?api_key=DEMO_KEY&count=5
```

<details><summary>See Return Object</summary>
<p>


```jsoniq
[
  {
    "copyright": "Panther Observatory",
    "date": "2006-04-15",
    "explanation": "In this stunning cosmic vista, galaxy M81 is on the left surrounded by blue spiral arms.  On the right marked by massive gas and dust clouds, is M82.  These two mammoth galaxies have been locked in gravitational combat for the past billion years.   The gravity from each galaxy dramatically affects the other during each hundred million-year pass.  Last go-round, M82's gravity likely raised density waves rippling around M81, resulting in the richness of M81's spiral arms.  But M81 left M82 with violent star forming regions and colliding gas clouds so energetic the galaxy glows in X-rays.  In a few billion years only one galaxy will remain.",
    "hdurl": "https://apod.nasa.gov/apod/image/0604/M81_M82_schedler_c80.jpg",
    "media_type": "image",
    "service_version": "v1",
    "title": "Galaxy Wars: M81 versus M82",
    "url": "https://apod.nasa.gov/apod/image/0604/M81_M82_schedler_c25.jpg"
  },
  {
    "date": "2013-07-22",
    "explanation": "You are here.  Everyone you've ever known is here. Every human who has ever lived -- is here. Pictured above is the Earth-Moon system as captured by the Cassini mission orbiting Saturn in the outer Solar System. Earth is the brighter and bluer of the two spots near the center, while the Moon is visible to its lower right. Images of Earth from Saturn were taken on Friday. Quickly released unprocessed images were released Saturday showing several streaks that are not stars but rather cosmic rays that struck the digital camera while it was taking the image.  The above processed image was released earlier today.  At nearly the same time, many humans on Earth were snapping their own pictures of Saturn.   Note: Today's APOD has been updated.",
    "hdurl": "https://apod.nasa.gov/apod/image/1307/earthmoon2_cassini_946.jpg",
    "media_type": "image",
    "service_version": "v1",
    "title": "Earth and Moon from Saturn",
    "url": "https://apod.nasa.gov/apod/image/1307/earthmoon2_cassini_960.jpg"
  },
  {
    "copyright": "Joe Orman",
    "date": "2000-04-06",
    "explanation": "Rising before the Sun on February 2nd, astrophotographer Joe Orman anticipated this apparition of the bright morning star Venus near a lovely crescent Moon above a neighbor's house in suburban Phoenix, Arizona, USA. Fortunately, the alignment of bright planets and the Moon is one of the most inspiring sights in the night sky and one that is often easy to enjoy and share without any special equipment. Take tonight, for example. Those blessed with clear skies can simply step outside near sunset and view a young crescent Moon very near three bright planets in the west Jupiter, Mars, and Saturn. Jupiter will be the unmistakable brightest star near the Moon with a reddish Mars just to Jupiter's north and pale yellow Saturn directly above. Of course, these sky shows create an evocative picture but the planets and Moon just appear to be near each other -- they are actually only approximately lined up and lie in widely separated orbits. Unfortunately, next month's highly publicized alignment of planets on May 5th will be lost from view in the Sun's glare but such planetary alignments occur repeatedly and pose no danger to planet Earth.",
    "hdurl": "https://apod.nasa.gov/apod/image/0004/vm_orman_big.jpg",
    "media_type": "image",
    "service_version": "v1",
    "title": "Venus, Moon, and Neighbors",
    "url": "https://apod.nasa.gov/apod/image/0004/vm_orman.jpg"
  },
  {
    "date": "2014-07-12",
    "explanation": "A new star, likely the brightest supernova in recorded human history, lit up planet Earth's sky in the year 1006 AD. The expanding debris cloud from the stellar explosion, found in the southerly constellation of Lupus, still puts on a cosmic light show across the electromagnetic spectrum. In fact, this composite view includes X-ray data in blue from the Chandra Observatory, optical data in yellowish hues, and radio image data in red. Now known as the SN 1006 supernova remnant, the debris cloud appears to be about 60 light-years across and is understood to represent the remains of a white dwarf star. Part of a binary star system, the compact white dwarf gradually captured material from its companion star. The buildup in mass finally triggered a thermonuclear explosion that destroyed the dwarf star. Because the distance to the supernova remnant is about 7,000 light-years, that explosion actually happened 7,000 years before the light reached Earth in 1006. Shockwaves in the remnant accelerate particles to extreme energies and are thought to be a source of the mysterious cosmic rays.",
    "hdurl": "https://apod.nasa.gov/apod/image/1407/sn1006c.jpg",
    "media_type": "image",
    "service_version": "v1",
    "title": "SN 1006 Supernova Remnant",
    "url": "https://apod.nasa.gov/apod/image/1407/sn1006c_c800.jpg"
  },
  {
    "date": "1997-01-21",
    "explanation": "In Jules Verne's science fiction classic A Journey to the Center of the Earth, Professor Hardwigg and his fellow explorers encounter many strange and exciting wonders. What wonders lie at the center of our Galaxy? Astronomers now know of some of the bizarre objects which exist there, like vast dust clouds,\r bright young stars, swirling rings of gas, and possibly even a large black hole. Much of the Galactic center region is shielded from our view in visible light by the intervening dust and gas. But it can be explored using other forms of electromagnetic radiation, like radio, infrared, X-rays, and gamma rays. This beautiful high resolution image of the Galactic center region in infrared light was made by the SPIRIT III telescope onboard the Midcourse Space Experiment. The center itself appears as a bright spot near the middle of the roughly 1x3 degree field of view, the plane of the Galaxy is vertical, and the north galactic pole is towards the right. The picture is in false color - starlight appears blue while dust is greenish grey, tending to red in the cooler areas.",
    "hdurl": "https://apod.nasa.gov/apod/image/9701/galcen_msx_big.gif",
    "media_type": "image",
    "service_version": "v1",
    "title": "Journey to the Center of the Galaxy \r\nCredit:",
    "url": "https://apod.nasa.gov/apod/image/9701/galcen_msx.jpg"
  }
]
```

</p>
</details>



```bash
https://api.nasa.gov/planetary/apod?api_key=DEMO_KEY&start_date=2017-07-08&end_date=2017-07-10
```

<details><summary>See Return Object</summary>
<p>

```jsoniq
[
  {
    "copyright": "T. Rector",
    "date": "2017-07-08",
    "explanation": "Similar in size to large, bright spiral galaxies in our neighborhood, IC 342 is a mere 10 million light-years distant in the long-necked, northern constellation Camelopardalis. A sprawling island universe, IC 342 would otherwise be a prominent galaxy in our night sky, but it is hidden from clear view and only glimpsed through the veil of stars, gas and dust clouds along the plane of our own Milky Way galaxy. Even though IC 342's light is dimmed by intervening cosmic clouds, this sharp telescopic image traces the galaxy's own obscuring dust, blue star clusters, and glowing pink star forming regions along spiral arms that wind far from the galaxy's core. IC 342 may have undergone a recent burst of star formation activity and is close enough to have gravitationally influenced the evolution of the local group of galaxies and the Milky Way.",
    "hdurl": "https://apod.nasa.gov/apod/image/1707/ic342_rector2048.jpg",
    "media_type": "image",
    "service_version": "v1",
    "title": "Hidden Galaxy IC 342",
    "url": "https://apod.nasa.gov/apod/image/1707/ic342_rector1024s.jpg"
  },
  {
    "date": "2017-07-09",
    "explanation": "Can you find your favorite country or city?  Surprisingly, on this world-wide nightscape, city lights make this task quite possible.  Human-made lights highlight particularly developed or populated areas of the Earth's surface, including the seaboards of Europe, the eastern United States, and Japan.  Many large cities are located near rivers or oceans so that they can exchange goods cheaply by boat.  Particularly dark areas include the central parts of South America, Africa, Asia, and Australia.  The featured composite was created from images that were collected during cloud-free periods in April and October 2012 by the Suomi-NPP satellite, from a polar orbit about 824 kilometers above the surface, using its Visible Infrared Imaging Radiometer Suite (VIIRS).",
    "hdurl": "https://apod.nasa.gov/apod/image/1707/EarthAtNight_SuomiNPP_3600.jpg",
    "media_type": "image",
    "service_version": "v1",
    "title": "Earth at Night",
    "url": "https://apod.nasa.gov/apod/image/1707/EarthAtNight_SuomiNPP_1080.jpg"
  },
  {
    "date": "2017-07-10",
    "explanation": "What's happening around the center of this spiral galaxy? Seen in total, NGC 1512 appears to be a barred spiral galaxy -- a type of spiral that has a straight bar of stars across its center.  This bar crosses an outer ring, though, a ring not seen as it surrounds the pictured region. Featured in this Hubble Space Telescope image is an inner ring -- one that itself surrounds the nucleus of the spiral.  The two rings are connected not only by a bar of bright stars but by dark lanes of dust. Inside of this inner ring, dust continues to spiral right into the very center -- possibly the location of a large black hole. The rings are bright with newly formed stars which may have been triggered by the collision of NGC 1512 with its galactic neighbor, NGC 1510.",
    "hdurl": "https://apod.nasa.gov/apod/image/1707/NGC1512_Schmidt_1342.jpg",
    "media_type": "image",
    "service_version": "v1",
    "title": "Spiral Galaxy NGC 1512: The Nuclear Ring",
    "url": "https://apod.nasa.gov/apod/image/1707/NGC1512_Schmidt_960.jpg"
  }
]
```


</p>
</details>

#### Copyright
If you are re-displaying imagery, you may want to check for the presence of the copyright. Anything without a copyright returned field is generally NASA and in the public domain. Please see the <a href=https://apod.nasa.gov/apod/lib/about_apod.html>"About image permissions"</a> section on the main Astronomy Photo of the Day site for more information.

## The APOD Parser<a name="TheAPODParser"></a>

<i>The APOD Parser is not part of the API itself. </i> Rather is intended to be used for accessing the APOD API quickly with Python without writing much additional code yourself. It is found in the apod_parser folder.

### Usage

1. First import the `apod_object_parser.py` file.

2. Now use the `get_data` function and pass your API key as the only argument. You can get the API key <a href="https://api.nasa.gov/#signUp">here</a>

```python
response = apod_object_parser.get_data(<your_api_key>)
```

3. Now you can use the following functions:

-> `apod_object_parser.get_date(response)`

-> `apod_object_parser.get_explaination(response)`

-> `apod_object_parser.get_hdurl(response)`

-> `apod_object_parser.get_media_type(response)`

-> `apod_object_parser.get_service_version(response)`

-> `apod_object_parser.get_title(response)`

-> `apod_object_parser.get_url(response)`

**for full docs and more functions visit the readme of  the apod parser by clicking <a href="apod_parser/apod_parser_readme.md">here</a>**

## Deployed <a name="Deployed"></a>
The deployed version of this API is based on the `eb` branch. The version that was deployed before that is in the `eb_previous` branch. The `master` branch is used as development as that's where most of the pull requests will come into anyways.

This API is deployed on AWS using elastic beanstalk due to large number of people who use the service. However, if you're planning on using it just yourself, it is small enough to be stood up on a single micro EC2 or any other small size cloud compute machine.

## Feedback <a name="feedback"></a>

Star this repo if you found it useful. Use the github issue tracker to give
feedback on this repo.

## Author <a name="author"></a>
- Brian Thomas (based on code by Dan Hammer) 
- Justin Gosses (made changes to allow this repository to run more easily on AWS Elastic Beanstalk after heroku instance was shut-down)
- Please checkout the <a href="https://github.com/nasa/apod-api/graphs/contributors">contributers</a> to this repository on the righthand side of this page. 

## Contributing
We do accept pull requests from the public. Please note that we can be slow to respond. Please be patient. 

Also, **the people with rights on this repository are not people who can debug problems with the APOD website itself**. If you would like to contribute, right now we could use some attention to the tests. 

## Links

- [YouTube Embedded Players and Player Parameters](https://developers.google.com/youtube/player_parameters)
![OpenSpace Logo](/data/openspace-horiz-logo-crop.png)
[OpenSpace](http://openspaceproject.com) is an open source, non-commercial, and freely available interactive data visualization software designed to visualize the entire known universe and portray our ongoing efforts to investigate the cosmos.  Bringing the latest techniques from data visualization research to the general public, OpenSpace supports interactive presentation of dynamic data from observations, simulations, and space mission planning and operations.  The software works on multiple operating systems (Windows, Linux, MacOS) with an extensible architecture capable of powering both personal computers and also high resolution tiled displays and planetarium domes.  In addition, OpenSpace enables simultaneous connections across the globe creating opportunity for shared experiences among audiences worldwide.  The target audience of the software reaches from the general public who wishes to explore our universe, enthusiasts interested in hacking the underlying components in OpenSpace to create unique experiences, informal science institutions wishing to create a low-cost, yet powerful exhibition piece, but also scientists desiring to visualize their datasets in a contextualized, powerful software.

[![License](https://img.shields.io/badge/License-MIT-purple.svg?style=flat-square)](LICENSE)
[![Download](https://img.shields.io/github/v/tag/OpenSpace/OpenSpace?label=Version&color=maroon&style=flat-square)](https://www.openspaceproject.com/installation)
![Size](https://img.shields.io/github/repo-size/OpenSpace/OpenSpace?style=flat-square&color=red)

[![System Paper](https://img.shields.io/badge/System%20Paper-10.1109%2FTVCG.2019.2934259-blue?style=flat-square)](https://doi.org/10.1109/TVCG.2019.2934259)
[![GlobeBrowsing Paper](https://img.shields.io/badge/GlobeBrowsing%20Paper-https%3A%2F%2Fdoi.org%2F10.1109%2FTVCG.2017.2743958-blue?style=flat-square)](https://doi.org/10.1109/TVCG.2017.2743958)

![Contributors](https://img.shields.io/github/contributors/OpenSpace/OpenSpace?style=flat-square)
![Commits](https://img.shields.io/github/commit-activity/m/OpenSpace/OpenSpace?color=green&style=flat-square)

![Image](https://github.com/OpenSpace/openspace.github.io/raw/master/assets/images/collection.jpg)

# Background
OpenSpace started as a collaboration between Sweden's [Linköping University](https://scivis.github.io) (LiU) and the [American Museum of Natural History](https://www.amnh.org) (AMNH).  Development of the software began several years ago through a close collaboration with NASA Goddard's [Community Coordinated Modeling Center](https://ccmc.gsfc.nasa.gov) (CCMC) to model space weather forecasting and continued with visualizations of NASA's New Horizons mission to Pluto and ESA's Rosetta mission to 67P/Churyumov-Gerasimenko.  This promising set of preliminary work provided a foundation for continued funding from NASA, the Swedish eScience Research Centre, and the Knut and Alice Wallenberg foundation, which has extended the collaboration to include the University of Utah's [Scientific Computing and Imaging](https://www.sci.utah.edu) (SCI) Institute, [New York University](https://www.nyu.edu)'s Tandon School of Engineering, multiple informal science institutions across the world, and multiple, international vendors.

![Image](https://github.com/OpenSpace/openspace.github.io/raw/master/assets/images/presentation.jpg)

# Features
Some of the high-level features supported in OpenSpace are:
 - AMNH's Digital Universe catalog of extrasolar datasets (stars, galaxies, quasars, ...)
 - High-resolution planetary images for major objects in the solar system (Earth, Moon, Mars, Venus, ...)
 - Animated 3D models representing space missions (ISS, New Horizons, JWST, ...)
 - Support for custom profiles with arbitrary user-defined content
 - Ability to drive any type of display environment (flat screen, multi-projector, planetariums, ...)
 - Lua and JavaScript interface into the engine allowing highly customized controls
 - Native support to export an interactive sessions as individual frames for video export
 - much much more (see our [Changelog](http://wiki.openspaceproject.com/docs/general/releases))

OpenSpace requires at least support for [OpenGL](https://www.opengl.org/) version 3.3, some custom components require at least version 4.2.

![Image](https://github.com/OpenSpace/openspace.github.io/raw/master/assets/images/display-systems.jpg)

# Getting Started
This repository contains the source code and example profiles for OpenSpace, but does not contain any data.  To build and install the application, please check out the [GitHub Wiki](https://github.com/OpenSpace/OpenSpace/wiki).  Here, you will find two pages, a [build instruction](https://github.com/OpenSpace/OpenSpace/wiki/Compiling) for all operating systems and then additional instructions for [Windows](https://github.com/OpenSpace/OpenSpace/wiki/Compiling-Windows), [Linux (Ubuntu)](https://github.com/OpenSpace/OpenSpace/wiki/Compiling-Ubuntu), and [MacOS](https://github.com/OpenSpace/OpenSpace/wiki/Compiling-MacOS). Please note that the Apple Silicon series of chips do not support OpenGL natively and Metal 2 does not support `double` precision accuracy (see [here](https://developer.apple.com/metal/Metal-Shading-Language-Specification.pdf) Section 2.1), therefore only the Intel processors for MacOS are supported and maintained.

Requirements for compiling are:
 - CMake version 3.25 or above
 - C++ compiler supporting C++20 (MSVC 19.31, GCC11, Clang14, AppleClang 13.1.6)
 - [Boost](http://www.boost.org/)
 - [Qt](http://www.qt.io/download)

Feel free to create issues for missing features, bug reports, or compile problems or contact us via [email](mailto:openspace@amnh.org?subject=OpenSpace:).  Regarding any issues, you are very welcome on our [Slack support channel](https://openspacesupport.slack.com) to which you can freely [sign-up](https://join.slack.com/t/openspacesupport/shared_invite/zt-37niq6y9-T0JaCIk4UoFLI4VF5U9Vsw).

![Image](https://github.com/OpenSpace/openspace.github.io/raw/master/assets/images/himalaya-nkpg-dome.jpg)

# License
The contents of this repository provided under an [MIT license](https://github.com/OpenSpace/OpenSpace/blob/master/LICENSE.md).

# Support
OpenSpace is supported by the following institutions:

![Image](https://github.com/OpenSpace/openspace.github.io/raw/master/assets/logos/sponsors.png)
`Documentation`_ | Blog_ |  `View on Github`_ |  `Download Stable ZIP`_  |  `Download Stable TAR`_

.. image:: https://pypip.in/v/astroquery/badge.png
   :target: https://img.shields.io/pypi/v/astroquery.svg
   :alt: Latest PyPI version

.. image:: https://readthedocs.org/projects/astroquery/badge/?version=latest
    :target: https://astroquery.readthedocs.io/en/latest/?badge=latest
    :alt: Documentation Status

.. image:: https://github.com/astropy/astroquery/workflows/CI/badge.svg
    :target: https://github.com/astropy/astroquery/actions?query=workflow%3ACI
    :alt: Github Actions CI Status

.. image:: https://codecov.io/gh/astropy/astroquery/branch/main/graph/badge.svg
    :target: https://codecov.io/gh/astropy/astroquery
    :alt: Coverage results

.. image:: https://zenodo.org/badge/DOI/10.5281/zenodo.1160627.svg
   :target: https://doi.org/10.5281/zenodo.1160627
   :alt: Zenodo


==================================
Accessing Online Astronomical Data
==================================

Astroquery is an `astropy <http://www.astropy.org>`_ affiliated package that
contains a collection of tools to access online Astronomical data. Each web
service has its own sub-package. For example, to interface with the `SIMBAD
website <https://simbad.cds.unistra.fr/simbad/>`_, use the ``simbad`` sub-package:

.. code-block:: python

    >>> from astroquery.simbad import Simbad
    >>> theta1c = Simbad.query_object('tet01 Ori C')
    >>> theta1c.pprint()
       MAIN_ID          RA           DEC      ... COO_QUAL COO_WAVELENGTH     COO_BIBCODE
    ------------- ------------- ------------- ... -------- -------------- -------------------
    * tet01 Ori C 05 35 16.4637 -05 23 22.848 ...        A              O 2007A&A...474..653V

Installation and Requirements
-----------------------------

Astroquery works with Python 3.7 or later.
As an `astropy`_ affiliate, astroquery requires `astropy`_ version 4.2.1 or later.

astroquery uses the `requests <https://requests.readthedocs.io/en/latest/>`_
module to communicate with the internet.  `BeautifulSoup
<http://www.crummy.com/software/BeautifulSoup/>`_ and `html5lib'
<https://html5lib.readthedocs.io/en/latest/>`_ are needed for HTML parsing for
some services.  The `keyring <https://pypi.python.org/pypi/keyring>`_ module is
also required for accessing services that require a login.  These can all be
installed using `pip <https://pypi.python.org/pypi/pip>`_ or `anaconda
<http://continuum.io/>`_.  Running the tests requires `curl
<https://curl.haxx.se/>`_ to be installed.

The latest version of astroquery can be pip installed (note the ``--pre`` for
picking up released developer versions, and ``-U`` for upgrade):

.. code-block:: bash

    $ python -m pip install -U --pre astroquery

To install all the mandatory and optional dependencies add the ``[all]``
identifyer to the pip command above (or use ``[docs]`` or ``[test]`` for the
dependencies required to build the documentation or run the tests):

.. code-block:: bash

    $ python -m pip install -U --pre astroquery[all]


To install the 'bleeding edge' version:

.. code-block:: bash

   $ python -m pip install git+https://github.com/astropy/astroquery.git

or cloned and installed from source:

.. code-block:: bash

    $ # If you have a github account:
    $ git clone git@github.com:astropy/astroquery.git
    $ # If you do not:
    $ git clone https://github.com/astropy/astroquery.git
    $ cd astroquery
    $ python -m pip install .

Using astroquery
----------------

Importing astroquery on its own doesn't get you much: you need to import each
sub-module specifically.  See the documentation for a list of `Available
Services <https://astroquery.readthedocs.io/en/latest/#available-services>`_.
The `API`_ shows the standard suite of tools common to most modules, e.g.
`query_object` and `query_region`.

To report bugs and request features, please use the issue tracker.  Code
contributions are very welcome, though we encourage you to follow the `API`_
and `contributing guidelines
<https://github.com/astropy/astroquery/blob/main/CONTRIBUTING.rst>`_ as much
as possible.

Citing Astroquery
-----------------

If you use ``astroquery``, please cite the paper we published in `The
Astronomical Journal <http://adsabs.harvard.edu/abs/2019AJ....157...98G>`__.

The BibTeX entry is available from the package itself::

  import astroquery
  astroquery.__citation__


In addition you may also want to refer to specific versions of the
package. We create a separate Zenodo DOI for each version, they can be
looked up at the following `Zenodo page <https://doi.org/10.5281/zenodo.591669>`__


Additional Links
----------------

`Download Development ZIP`_  |  `Download Development TAR`_

Maintained by `Adam Ginsburg`_ and `Brigitta Sipocz <https://github.com/bsipocz>`_ (`astropy.astroquery@gmail.com`_)


.. _Download Development ZIP: https://github.com/astropy/astroquery/zipball/main
.. _Download Development TAR: https://github.com/astropy/astroquery/tarball/main
.. _Download Stable ZIP: https://github.com/astropy/astroquery/zipball/stable
.. _Download Stable TAR: https://github.com/astropy/astroquery/tarball/stable
.. _View on Github: https://github.com/astropy/astroquery/
.. _Documentation: http://astroquery.readthedocs.io
.. _astropy.astroquery@gmail.com: mailto:astropy.astroquery@gmail.com
.. _Adam Ginsburg: http://www.adamgginsburg.com
.. _Blog: http://astropy.org/astroquery-blog
.. _API: http://astroquery.readthedocs.io/en/latest/api.html
# Allsky Camera ![Release](https://img.shields.io/badge/Version-v2023.05.01_03-green.svg) [![Donate](https://img.shields.io/badge/Donate-PayPal-green.svg)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=MEBU2KN75G2NG&source=url)

This is the source code for the Allsky Camera project described [on Instructables](http://www.instructables.com/id/Wireless-All-Sky-Camera/).
&nbsp;  
<p align="center">
<img src="https://github.com/thomasjacquin/allsky/blob/master/assets/allsky_camera.png" width="50%" title="Example of an allsky camera">
</p>

> **This README and the [Allsky documentation](https://htmlpreview.github.io/?https://raw.githubusercontent.com/thomasjacquin/allsky/master/html/documentation/index.html) will help get your allsky camera up and running.**

&nbsp;  

<!-- =============================================================================== --> 
## Requirements

You will need the following:

 * A Raspberry Pi (Zero 2, 2, 3, 4) running Pi OS.
 * A camera (Raspberry Pi HQ, Module 3, or RPi compatible, or ZWO ASI)


&nbsp;  
> **NOTES:**
>	- Only the Raspberry Pi OS is supported.  Other operating systems like Ubuntu are NOT supported.
>	- The ZWO ASI120-series cameras are not recommended due to somewhat poor quality. See [Troubleshooting --> ZWO Cameras](https://htmlpreview.github.io/?https://raw.githubusercontent.com/thomasjacquin/allsky/master/html/documentation/troubleshooting/ZWOCameras.html) for notes on the ASI120-series and related T7 / T7C cameras.
>	- The Pi Zero with its limited memory and _very_ limited CPU power (single CPU core), is not recommended.  You will likely not be able to create keograms, startrails, or timelapse videos.
>	- The Pi Zero 2 with its limited memory and somewhat limited CPU power, is not recommended unless cost is the only concern.  Creating keograms, startrails, and timelapse videos may or may not be possible.
>	- The Le Potato is the only "Pi-compatible" board that we've found to actually be compatible, so buyer beware.
---


&nbsp;
<!-- =============================================================================== --> 
## Software Installation

PatriotAstro created a great [video](https://www.youtube.com/watch?v=7TGpGz5SeVI) describing the installation steps below.
**We highly suggest viewing it before installing the software.**

Detailed installation instructions can be found at [Installing / Upgrading --> Allsky](https://htmlpreview.github.io/?https://raw.githubusercontent.com/thomasjacquin/allsky/master/html/documentation/installations/Allsky.html).

---


&nbsp;
<!-- =============================================================================== --> 
## Web User Interface (WebUI)

<p align="center">
<img src="https://github.com/thomasjacquin/allsky/blob/master/html/documentation/settings/AllskySettingsPage.png" style="border: 1px solid black">
</p>

The WebUI is now installed as part of Allsky and is used to administer Allsky, and to a lesser extent, your Pi. It can also be used to view the current image as well as all saved images, keograms, startrails, and timelapse videos.

A public page is also available in order to view the current image without having to log into the WebUI and without being able to do any administrative tasks. This can be useful for people who don't have a Allsky Website but still want to share a view of their sky:

```
http://your_raspberry_IP/public.php
```

Make sure this page is publically viewable.
If it is behind a firewall consult the documentation for your network equipment for information on allowing inbound connections.

---

&nbsp;
<!-- =============================================================================== --> 
## Allsky Website

By installling the optional Allsky Website you can display your files on a website on the Pi, on another machine, or on both.

See [Installation / Upgrading --> Website](https://htmlpreview.github.io/?https://raw.githubusercontent.com/thomasjacquin/allsky/master/html/documentation/installations/AllskyWebsite.html) for information on how to install and configure an Allsky Website.

---


&nbsp;
<!-- =============================================================================== --> 
## Post-capture processing

Captured images can be resized, cropped, and stretched, and bad images (i.e., too light or too dark) can be removed automatically.

Allsky supports running "modules" after each picture is taken to change the image (e.g., add an overlay) or perform other tasks (e.g., count the number of stars in the image).  You can determine what modules to run and in what order.  Modules can pass data to other modules, for example, the Start Count Module can pass the star count to the Overlay Module to be added to the overlay.

The Overlay Editor lets you easily specify what text and images you want in your overlay, and place them using drag-and-drop.  Each field can be formatted however you want (font, color, size, position, rotation, etc.).  The only limit is your imagination!!

See [Explanations / How To -> Overlays](https://htmlpreview.github.io/?https://raw.githubusercontent.com/thomasjacquin/allsky/master/html/documentation/overlays/overlays.html) and [Explanations / How To -> Modules](https://htmlpreview.github.io/?https://raw.githubusercontent.com/thomasjacquin/allsky/master/html/documentation/modules/modules.html) for more information.

---


&nbsp;
<!-- =============================================================================== --> 
## Dark frame subtraction

Dark frame subtraction removes hot pixels from images by taking images at different temperatures with a cover on your camera lens and subtracting those images from nighttime images.

See [Explanations / How To -> Dark frames](https://htmlpreview.github.io/?https://raw.githubusercontent.com/thomasjacquin/allsky/master/html/documentation/explanations/darkFrames.html) for more information.

---


&nbsp;
<!-- =============================================================================== --> 
## Timelapse and mini timelapse

By default, a timelapse video is generated at the end of nighttime from all of the images captured in the last 24 hours.

"Mini" timelapse videos can also be created every few images, and contain the last several images.  They are useful to see what the sky was recently like.

---


&nbsp;
<!-- =============================================================================== --> 
## Keograms

<p align="center">
<img src="https://github.com/thomasjacquin/allsky/blob/master/assets/Keogram.png" width="75%">
</p>

A **Keogram** is an image giving a quick view of the day's activity.
For each image a central vertical column 1 pixel wide is extracted. All these columns are then stitched together from left to right. This results in a timeline that reads from dawn to the end of nighttime (the image above only shows nighttime data since daytime images were turned off).

See [Explanations / How To --> Keograms](https://htmlpreview.github.io/?https://raw.githubusercontent.com/thomasjacquin/allsky/master/html/documentation/explanations/keograms.html).


---


&nbsp;
<!-- =============================================================================== --> 
## Startrails

<p align="center">
<img src="https://github.com/thomasjacquin/allsky/blob/master/assets/Startrails.png" width="50%">
</p>

**Startrails** are generated by stacking all the images from a night on top of each other.
In the image above, Polaris is centered about one-fourth the way from the top.

See [Explanations / How To --> Startrails](https://htmlpreview.github.io/?https://raw.githubusercontent.com/thomasjacquin/allsky/master/html/documentation/explanations/startrails.html).
	

---


&nbsp;
<!-- =============================================================================== --> 
## Automatic deletion of old data

You can specify how many days worth of images to keep in order to keep the Raspberry Pi SD card from filling up.  If you have the Allsky Website installed on your Pi, you can specify how many days worth of its imags to keep.


See the **DAYS_TO_KEEP** and **WEB_DAYS_TO_KEEP** settings in [Settings --> Allsky](https://htmlpreview.github.io/?https://raw.githubusercontent.com/thomasjacquin/allsky/master/html/documentation/settings/allsky.html).

---



&nbsp;
<!-- =============================================================================== --> 
## Share your sky


If you want your allsky camera added to the [Allsky map](http://www.thomasjacquin.com/allsky-map), see [Put your camera on Allsky Map](https://htmlpreview.github.io/?https://raw.githubusercontent.com/thomasjacquin/allsky/master/html/documentation/miscellaneous/AllskyMap.html).

If you know anyone in Greenland or Antartica, send them a camera!!

<p align="center">
<a href="https://www.thomasjacquin.com/allsky-map/" title="Allsky map example - click to see real map">
<img src="https://github.com/thomasjacquin/allsky/blob/master/html/documentation/miscellaneous/allsky-map-with-pins.png">
</a>
</p>

---


&nbsp;
<!-- =============================================================================== --> 
## Release changes

See the
[Allsky Version Change Log](https://htmlpreview.github.io/?https://raw.githubusercontent.com/thomasjacquin/allsky/master/html/documentation/changeLog.html)
for a list of changes in this release and all prior releases.

---


&nbsp;
<!-- =============================================================================== --> 
## Donation
If you found this project useful, here's a link to send Thomas a cup of coffee :)

[![](https://www.paypalobjects.com/en_US/i/btn/btn_donate_SM.gif)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=MEBU2KN75G2NG&source=url)
# Astronomy for Meteor

[![Gitter](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/jagi/meteor-astronomy?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=body_badge)

<img src="http://jagi.github.io/meteor-astronomy/images/logo.png" />

The [Astronomy](https://atmospherejs.com/jagi/astronomy) package introduces the [Model Layer](http://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller) into Meteor applications. It can also be named the Object Document Mapping system (ODM) or for people coming from relational database environments the Object-Relational Mapping system (ORM). Astronomy extends MongoDB documents with functionalities defined in a schema.

## Documentation

Astronomy documentation can be found [here](http://jagi.github.io/meteor-astronomy/).

## Tutorials

You can learn more about Astronomy by watching video tutorials that I'm creating. I'm trying to add a new one every week. You can access them here https://goo.gl/9gnrav

## Installation

```sh
$ meteor add jagi:astronomy
```

## Support Astronomy development

[<img src="https://www.patreon.com/images/patreon_navigation_logo_mini_orange.png" width="100" />](https://www.patreon.com/jagi)

I've decided to start [Patreon](https://www.patreon.com/jagi) page. If you enjoy using Astronomy and want to support development of future versions, then any donation will be welcome :).

## Introduction

When fetching documents from Mongo collections, you get plain JavaScript objects without any logic. You have to validate values of objects' properties, check what fields have changed, save only modified fields, transform values coming from forms, in every place you are playing with a document; a lot of things to do. Wouldn't it be great if you could define some simple rules and leave everything else to framework? It's actually possible thanks to Astronomy. But first let's take a look at how your code would look like without using Astronomy.

```js
var post = Posts.findOne(id);
// Assign values manually instead doing it automatically.
post.createdAt = new Date();
post.userId = Meteor.userId();
// Manually convert values coming from the form.
post.title = tmpl.find('input[name=title]').value;
post.publishedAt = new Date(tmpl.find('input[name=publishedAt]').value);
// Every time implement custom validation logic.
if (post.title.length < 3) {
  // Implement an error messages system.
  throw new Error('The "title" field has to be at least 3 characters long');
} else {
  // Detect what fields have changed and update only those.
  // Access collection directly.
  Posts.update({
    _id: post._id
  }, {
    $set: {
      title: post.title,
      publishedAt: post.publishedAt,
      createdAt: post.updateAt
    }
  });
}
```

With Astronomy and defined schema your code would look like follows:
```js
// Notice that we call the "findOne" method
// from the "Post" class not from the "Posts" collection.
var post = Post.findOne(id);
// Auto convert a string input value to a number.
post.title = tmpl.find('input[name=title]').value;
post.publishedAt = new Date(tmpl.find('input[name=publishedAt]').value);
// Check if all fields are valid and update document
// with only the fields that have changed.
post.save();
```

What approach is simpler? I think the choice is obvious.

For clarity, here is a sample schema that allows that. May seem to be a lot of
code but have in mind that you write it only once.

```js
import { Class } from 'meteor/jagi:astronomy';

const Posts = new Mongo.Collection('posts');
const Post = Class.create({
  name: 'Post',
  collection: Posts,
  fields: {
    title: {
      type: String,
      validators: [{
        type: 'minLength',
        param: 3
      }]
    },
    userId: String,
    publishedAt: Date
  },
  behaviors: {
    timestamp: {}
  }
});
```

## Supporters

[<img src="http://jagi.github.io/meteor-astronomy/images/usefulio.png" />](http://useful.io/)

## Contribution

Bigs thanks for all the [contributions](https://github.com/jagi/meteor-astronomy/graphs/contributors) in form of commits and bug reports. Without you it would not be possible to improve Astronomy. Special thanks to:
- [Faberle](https://github.com/Faberle) - for help with Meteor methods feature
- [Ben305](https://github.com/Ben305) - for several PRs
- [peterchoo](https://github.com/peterchoo) - for several PRs
- [talha-asad](https://github.com/talha-asad) - for updating History of changes
- all other commiters that I forgot to mention

If you have any suggestions or want to write new features or behaviors please contact me, or just create an issue or a pull request. If you found any error please create a reproduction repository and create an issue. Thanks to that it will be easier for me to tell what is wrong. Please, don't use CoffeeScript for creating a reproduction.

## License

Astronomy is released under the [MIT License](http://opensource.org/licenses/MIT).
# JWST Calibration Pipeline

[![Build Status](https://github.com/spacetelescope/jwst/workflows/CI/badge.svg?branch=master)](https://github.com/spacetelescope/jwst/actions)
[![codecov](https://codecov.io/gh/spacetelescope/jwst/branch/master/graph/badge.svg?token=Utf5Zs9g7z)](https://codecov.io/gh/spacetelescope/jwst)
[![Documentation Status](https://readthedocs.org/projects/jwst-pipeline/badge/?version=latest)](http://jwst-pipeline.readthedocs.io/en/latest/?badge=latest)
[![Powered by STScI Badge](https://img.shields.io/badge/powered%20by-STScI-blue.svg?colorA=707170&colorB=3e8ddd&style=flat)](http://www.stsci.edu)
[![Powered by Astropy Badge](http://img.shields.io/badge/powered%20by-AstroPy-orange.svg?style=flat)](http://www.astropy.org/)
[![DOI](https://zenodo.org/badge/60551519.svg)](https://zenodo.org/badge/latestdoi/60551519)

![STScI Logo](docs/_static/stsci_logo.png)

**JWST requires Python 3.9 or above and a C compiler for dependencies.**

**Linux and MacOS platforms are tested and supported.  Windows is not currently supported.**

**If installing on MacOS Mojave 10.14, you must install
  into an environment with python 3.9. Installation will fail on python 3.10 due
  to lack of a stable build for dependency ``opencv-python``.**

## Installation

Please contact the [JWST Help Desk](https://jwsthelp.stsci.edu) for installation issues.

The easiest way to install the latest `jwst` release into a fresh virtualenv or conda environment is

    pip install jwst

### Detailed Installation

The `jwst` package can be installed into a virtualenv or conda environment via `pip`.
We recommend that for each installation you start by creating a fresh
environment that only has Python installed and then install the `jwst` package and
its dependencies into that bare environment.
If using conda environments, first make sure you have a recent version of Anaconda
or Miniconda installed.
If desired, you can create multiple environments to allow for switching between different
versions of the `jwst` package (e.g. a released version versus the current development version).

In all cases, the installation is generally a 3-step process:
* Create a conda environment
* Activate that environment
* Install the desired version of the `jwst` package into that environment

Details are given below on how to do this for different types of installations,
including tagged releases, DMS builds used in operations, and development versions.
Remember that all conda operations must be done from within a bash/zsh shell.


### Installing latest releases

You can install the latest released version via `pip`.  From a bash/zsh shell:

    conda create -n <env_name> python
    conda activate <env_name>
    pip install jwst

You can also install a specific version:

    conda create -n <env_name> python
    conda activate <env_name>
    pip install jwst==1.9.4

### Installing the development version from Github

You can install the latest development version (not as well tested) from the
Github master branch:

    conda create -n <env_name> python
    conda activate <env_name>
    pip install git+https://github.com/spacetelescope/jwst


### Installing a DMS Operational Build

There may be occasions where an exact copy of an operational DMS build is
desired (e.g. for validation testing or debugging operational issues).
We package releases for DMS builds via environment snapshots that specify the
exact versions of all packages to be installed.

To install a particular DMS build, consult the
[Software vs DMS build version map](https://github.com/spacetelescope/jwst#software-vs-dms-build-version-map)
table shown below to determine the correct jwst tag. For example, to install the
version of `jwst` used in DMS build 9.0, use jwst tag 1.8.2. The overall
procedure is similar to the 3-step process outlined in the previous section, but the
details of each command vary, due to the use of environment snapshot files that specify
all of the particular packages to install. Also note that different snapshot files are
used for Linux and Mac OS systems.

Linux:

    conda create -n jwstdp-1.8.2 --file https://ssb.stsci.edu/releases/jwstdp/1.8.2/conda_python_stable-deps.txt
    conda activate jwstdp-1.8.2
    pip install -r https://ssb.stsci.edu/releases/jwstdp/1.8.2/reqs_stable-deps.txt

MacOS:

    conda create -n jwstdp-1.8.2 --file https://ssb.stsci.edu/releases/jwstdp/1.8.2/conda_python_macos-stable-deps.txt
    conda activate jwstdp-1.8.2
    pip install -r https://ssb.stsci.edu/releases/jwstdp/1.8.2/reqs_macos-stable-deps.txt

Each DMS delivery has its own installation instructions, which may be found in
the corresponding release documentation linked from this page:
https://github.com/astroconda/astroconda-releases/tree/master/jwstdp
The installation procedures may change from time to time, so consulting the
documentation page for the specific version in question is the best way to get
that version installed.


### Installing for Developers

If you want to be able to work on and test the source code with the `jwst` package,
the high-level procedure to do this is to first create a conda environment using
the same procedures outlined above, but then install your personal copy of the
code overtop of the original code in that environment. Again, this should be done
in a separate conda environment from any existing environments that you may have
already installed with released versions of the `jwst` package.

As usual, the first two steps are to create and activate an environment:

    conda create -n <env_name> python
    conda activate <env_name>

To install your own copy of the code into that environment, you first need to
fork and clone the `jwst` repo:

    cd <where you want to put the repo>
    git clone https://github.com/<your_github_username>/jwst.git
    cd jwst

*Note: `python setup.py install` and `python setup.py develop` commands do not work.*

Install from your local checked-out copy as an "editable" install:

    pip install -e .

If you want to run the unit or regression tests and/or build the docs, you can make
sure those dependencies are installed too:

    pip install -e ".[test]"
    pip install -e ".[docs]"
    pip install -e ".[test,docs]"

Need other useful packages in your development environment?

    pip install ipython jupyter matplotlib pylint


## Calibration References Data System (CRDS) Setup

**Note: As of November 10, 2022, the process of deprecating the CRDS PUB Server will start.
For details, refer to the [CRDS PUB Server Freeze
and Deprecation page](https://jwst-pipeline.readthedocs.io/en/stable/jwst/pub_deprecation.html#pub-deprecation)**


CRDS is the system that manages the reference files needed to run the pipeline.
For details about CRDS, see the [User's
Guide](https://jwst-crds.stsci.edu/static/users_guide/index.html)

The JWST CRDS server is available at  https://jwst-crds.stsci.edu

It supports the automatic processing pipeline at STScI.
Inside the STScI network, the same server is used by the pipeline by default with no modifications.
To run the pipeline outside the STScI network, CRDS must be configured by setting
two environment variables:

    export CRDS_PATH=<locally-accessable-path>/crds_cache/jwst_ops
    export CRDS_SERVER_URL=https://jwst-crds.stsci.edu


``<locally-accessable-path>`` can be any the user has permissions to use, such as `$HOME`.
Expect to use upwards of 200GB of disk space to cache the latest couple of contexts.

## Documentation

Documentation (built daily from the Github `master` branch) is available at:

https://jwst-pipeline.readthedocs.io/en/latest/

To build the docs yourself, clone this repository and build the documentation with:

    pip install -e ".[docs]"
    cd docs
    make html
    make latexpdf


## Contributions and Feedback

We welcome contributions and feedback on the project. Please follow the
[contributing guidelines](CONTRIBUTING.md) to submit an issue or a pull request.

We strive to provide a welcoming community to all of our users by abiding with
the [Code of Conduct](CODE_OF_CONDUCT.md).

If you have questions or concerns regarding the software, please open an issue
at https://github.com/spacetelescope/jwst/issues or
contact the [JWST Help Desk](https://jwsthelp.stsci.edu).


## Software vs DMS build version map

The table below provides information on each release of the `jwst` package
and its relationship to software builds used in the STScI JWST DMS operations
environment. The `Released` column gives the date on which the `jwst` tag
was released on PyPi and the `Ops Install` column gives the date on which
the build incorporating that release was installed in DMS operations.
Note that the `CRDS_CONTEXT` listed is a minimum context that can be used with
that release. A release should work with any contexts between
the specified context and less than the context for the next release.

| jwst tag            | DMS build | SDP_VER  | CRDS_CONTEXT | Released   | Ops Install | Notes                                         |
|---------------------|-----------|----------|--------------|------------|-------------|-----------------------------------------------|
| 1.12.3              | B10.0rc4  | 2023.3.x | 1135         | 2023-10-03 |             | Fourth release candidate for B10.0            |
| 1.12.2              | B10.0rc3  | 2023.3.x | 1135         | 2023-10-02 |             | Third release candidate for B10.0             |
| 1.12.1              | B10.0rc2  | 2023.3.x | 1132         | 2023-09-26 |             | Second release candidate for B10.0            |
| 1.12.0              | B10.0rc1  | 2023.3.x | 1130         | 2023-09-18 |             | First release candidate for B10.0             |
| 1.11.4              | B9.3.1    | 2023.2.1 | 1107         | 2023-08-14 |             | Final release for B9.3.1 patch                |
| 1.11.3              | B9.3      | 2023.2.0 | 1097         | 2023-07-17 |             | Final release candidate for B9.3              |
| 1.11.2              | B9.3rc3   |          | 1097         | 2023-07-12 |             | Third release candidate for B9.3              |
| 1.11.1              | B9.3rc2   |          | 1094         | 2023-06-29 |             | Second release candidate for B9.3             |
| 1.11.0              | B9.3rc1   |          | 1094         | 2023-06-21 |             | First release candidate for B9.3              |
| 1.10.2              |           |          | 1077         | 2023-04-14 |             | Pinning dependencies for external users       |
| 1.10.1              | B9.2.x    | 2023.1.1 | 1077         | 2023-04-13 | 2023-05-23  | Final release candidate for B9.2              |
| 1.10.0              | B9.2rc1   |          | 1075         | 2023-03-31 |             | First release candidate for B9.2              |
| 1.9.6               | B9.1.2    | 2022.5.2 | 1068         | 2023-03-09 | 2023-03-15  | Final release candidate for B9.1.2            |
| 1.9.5               |           |          | 1061         | 2023-03-02 |             | First release candidate for B9.1.2            |
| 1.9.4               | B9.1.1    | 2022.5.1 | 1041         | 2023-01-27 | 2023-02-28  | Final release candidate for B9.1.1            |
| 1.9.3               | B9.1      | 2022.5.0 | 1030         | 2023-01-12 | 2023-02-28  | Final release candidate for B9.1              |
| 1.9.2               | B9.1rc2   |          |              | 2023-01-04 |             | Second release candidate for B9.1 (hotfix)    |
| 1.9.1               | B9.1rc2   |          |              | 2023-01-03 |             | Second release candidate for B9.1             |
| 1.9.0               | B9.1rc1   |          |              | 2022-12-27 |             | First release candidate for B9.1              |
| 1.8.5               | B9.0      |          | 1019         | 2022-12-12 |             | Documentation patch release for B9.0          |
| 1.8.4               | B9.0      |          |              | 2022-11-16 |             | Documentation patch release for B9.0          |
| 1.8.3               | B9.0      |          |              | 2022-11-11 |             | Documentation patch release for B9.0          |
| 1.8.2               | B9.0      | 2022.4.0 | 1017         | 2022-10-19 | 2022-11-17  | Final release candidate for B9.0              |
| 1.8.1               | B9.0rc2   |          |              | 2022-10-17 |             | Second release candidate for B9.0             |
| 1.8.0               | B9.0rc1   |          |              | 2022-10-10 |             | First release candidate for B9.0              |
| 1.7.2               | B8.1.2    | 2022.3.1 | 0984         | 2022-09-12 | 2022-09-21  | Final release candidate for B8.1.2            |
| 1.7.1               | B8.1.2rc2 |          |              | 2022-09-07 |             | Second release candidate for B8.1.2           |
| 1.7.0               | B8.1.2rc1 |          |              | 2022-09-01 |             | First release candidate for B8.1.2            |
| 1.6.2               | B8.1      | 2022.3.0 | 0953         | 2022-07-19 | 2022-08-19  | Final release candidate for B8.1              |
| 1.6.1               | B8.1rc2   |          |              | 2022-07-15 |             | Second release candidate for B8.1             |
| 1.6.0               | B8.1rc1   |          |              | 2022-07-11 |             | First release candidate for B8.1              |
| 1.5.3               | B8.0.1    | 2022.2.1 | 0913         | 2022-06-20 | 2022-06-30  | Patch release B8.0.1                          |
| 1.5.2               | B8.0      | 2022.2.0 | 0874         | 2022-05-20 | 2022-06-16  | Final release candidate for B8.0              |
| 1.5.1               | B8.0rc2   |          |              | 2022-05-17 |             | Second release candidate for B8.0             |
| 1.5.0               | B8.0rc1   |          |              | 2022-05-05 |             | First release candidate for B8.0              |
| 1.4.6               | B7.9.3    | 2022.1.2 | 0800         | 2022-03-25 |             | Final release candidate for B7.9.3            |
| 1.4.5               | B7.9.3rc2 |          |              | 2022-03-23 |             | Second release candidate for B7.9.3           |
| 1.4.4               | B7.9.3rc1 |          |              | 2022-03-16 |             | First release candidate for B7.9.3            |
| 1.4.3               | B7.9.1    | 2022.1.1 | 0800         | 2022-02-03 |             | Final B7.9.1                                  |
| 1.4.2               | B7.9      | 2022.1.0 | 0797         | 2022-01-20 |             | Final release candidate for B7.9              |
| 1.4.1               | B7.9rc2   |          |              | 2022-01-15 |             | Second release candidate for B7.9             |
| 1.4.0               | B7.9rc1   |          |              | 2022-01-10 |             | First release candidate for B7.9              |
| Pre-launch releases |           |          |              |            |             |                                               |
| 1.3.3               | B7.8.2    | 2021.4.0 | 0764         | 2021-10-05 |             | Same as 1.3.2, but with installation bug fix  |
| 1.3.2               | B7.8.2    | 2021.4.0 | 0764         | 2021-09-03 |             | Final release candidate for B7.8.2            |
| 1.3.1               | B7.8.1    | 2021.3.0 | 0742         | 2021-08-09 |             | Final release candidate for B7.8.1            |
| 1.3.0               | B7.8.1rc1 |          | 0741         | 2021-08-02 |             | First release candidate for B7.8.1            |
| 1.2.3               | B7.8      | 2021.2.0 | 0732         | 2021-06-08 |             | Final release candidate for B7.8              |
| 1.2.2               | B7.8rc3   |          |              | 2021-06-08 |             | Third release candidate for B7.8              |
| 1.2.1               | B7.8rc2   |          |              | 2021-06-07 |             | Second release candidate for B7.8             |
| 1.2.0               | B7.8rc1   |          | 0723         | 2021-05-24 |             | First release candidate for B7.8              |
| 1.1.0               | B7.7.1    | 2021.1.0 | 0682         | 2021-02-26 |             | Final release candidate for B7.7.1            |
| 1.0.0               | B7.7.1rc1 |          | 0678         | 2021-02-22 |             | First release candidate for B7.7.1            |
| 0.18.3              | B7.7      | 2020.4.0 | 0670         | 2021-01-25 |             | Final release candidate for B7.7              |
| 0.18.2              | B7.7rc3   |          | 0668         | 2021-01-19 |             | Third release candidate for B7.7              |
| 0.18.1              | B7.7rc2   |          | 0664         | 2021-01-08 |             | Second release candidate for B7.7             |
| 0.18.0              | B7.7rc1   |          | 0645         | 2020-12-21 |             | First release candidate for B7.7              |
| 0.17.1              | B7.6      | 2020.3.0 | 0641         | 2020-09-15 |             | Final release candidate for B7.6              |
| 0.17.0              | B7.6rc1   |          | 0637         | 2020-08-28 |             | First release candidate for B7.6              |
| 0.16.2              | B7.5      | 2020.2.0 | 0619         | 2020-06-10 |             | Same as 0.16.1, but with installation bug fix |
| 0.16.1              | B7.5      | 2020.2.0 | 0619         | 2020-05-19 |             | Final release candidate for B7.5              |
| 0.16.0              | B7.5rc1   |          | 0614         | 2020-05-04 |             | First release candidate for B7.5              |
| 0.15.1              | B7.4.2    | 2020.1.0 | 0586         | 2020-03-10 |             | Final release candidate for B7.4.2            |
| 0.15.0              | B7.4.2rc1 |          | 0585         | 2020-02-28 |             | First release candidate for B7.4.2            |
| 0.14.2              | B7.4      | 2019.3.0 | 0570         | 2019-11-18 |             | Final release candidate for B7.4              |
| 0.14.1              | B7.4rc2   |          | 0568         | 2019-11-11 |             | Second release candidate for B7.4             |
| 0.14.0              | B7.4rc1   |          | 0563         | 2019-10-25 |             | First release candidate for B7.4              |
| 0.13.8              | B7.3.1    | 2019.2.0 | 0541         | 2019-09-05 |             | Patch for Build 7.3 released as Build 7.3.1   |
| 0.13.7              | B7.3      | 2019.1.0 | 0535         | 2019-06-21 |             | Final release candidate for Build 7.3         |
| 0.13.6              | B7.3rc4   |          | 0534         | 2019-06-20 |             | Fourth release candidate for Build 7.3        |
| 0.13.5              | B7.3rc3   |          | 0534         | 2019-06-19 |             | Third release candidate for Build 7.3         |
| 0.13.4              | B7.3rc2   |          | 0534         | 2019-06-18 |             | Second release candidate for Build 7.3        |
| 0.13.3              | B7.3rc1   |          | 0532         | 2019-06-04 |             | First release candidate for Build 7.3         |
| 0.13.2              |           |          | 0500         | 2019-05-14 |             | DMS test, no delivery to I&T                  |
| 0.13.1              |           |          | 0500         | 2019-03-08 |             | DMS test, no delivery to I&T                  |
| 0.13.0              |           |          | 0500         | 2019-02-15 |             | DMS test, no delivery to I&T                  |
| 0.12.3              | B7.2.1    |          | 0500         | 2019-01-15 |             | DMS Build 7.2.1 patch release                 |
| 0.12.2              | B7.2      | 2018_2   | 0495         | 2018-11-07 |             | Final release candidate for Build 7.2         |
| 0.12.1              | B7.2rc2   |          | 0495         | 2018-11-01 |             | Second release candidate for Build 7.2        |
| 0.12.0              | B7.2rc1   |          | 0493         | 2018-10-09 |             | First release candidate for Build 7.2         |
| 0.11.0              |           |          | 0482         | 2018-09-10 |             | DMS test, no delivery to I&T                  |
| 0.10.0              |           |          | 0477         | 2018-07-31 |             | DMS test, no delivery to I&T                  |
| 0.9.6               | B7.1.3    | 2018_1   | 0468         | 2018-06-08 |             | Final release candidate for Build 7.1.3       |
| 0.9.5               | B7.1.3rc3 |          | 0468         | 2018-06-06 |             | Third release candidate for Build 7.1.3       |
| 0.9.4               | B7.1.3rc2 |          | 0463         | 2018-05-29 |             | Second release candidate for Build 7.1.3      |
| 0.9.3               | B7.1.3rc1 |          | 0457         | 2018-05-11 |             | First release candidate for Build 7.1.3       |
| 0.9.2               |           |          | 0441         | 2018-03-28 |             | DMS test, no delivery to I&T                  |
| 0.9.1               |           |          | 0432         | 2018-02-16 |             | DMS test, no delivery to I&T                  |
| 0.9.0               | B7.1.2    |          | 0422         | 2017-12-22 |             | DMS patch release to I&T 2018-02-15           |
| 0.8.0               | B7.1.1    |          | 0422         | 2017-11-06 |             | DMS patch release to I&T 2018-01-17           |
| 0.8.0               | B7.1      | 2017_1   | 0422         | 2017-11-06 |             | Final release for Build 7.1                   |
| 0.7.7               | B7.0      | 2016_2   | 0303         | 2016-12-13 |             | Final release for Build 7.0                   |


## Unit Tests

Unit tests can be run via `pytest`.  Within the top level of your local `jwst` repo checkout:

    pip install -e ".[test]"
    pytest

Need to parallelize your test runs over all available cores?

    pip install pytest-xdist
    pytest -n auto


## Regression Tests

Latest regression test results can be found here (STScI staff only):

https://plwishmaster.stsci.edu:8081/job/RT/job/JWST/

The test builds start at 6pm local Baltimore time Monday through Saturday on `jwcalibdev`.

To run the regression tests on your local machine, get the test dependencies
and set the environment variable TEST_BIGDATA to our Artifactory server
(STSci staff members only):

    pip install -e ".[test]"
    export TEST_BIGDATA=https://bytesalad.stsci.edu/artifactory

To run all the regression tests (except the very slow ones):

    pytest --bigdata jwst/regtest

You can control where the test results are written with the
`--basetemp=<PATH>` arg to `pytest`.  _NOTE that `pytest` will wipe this directory clean
for each test session, so make sure it is a scratch area._

If you would like to run a specific test, find its name or ID and use the `-k` option:

    pytest --bigdata jwst/regtest -k nirspec

If developers need to update the truth files in our nightly regression tests,
there are instructions in the repository wiki.

https://github.com/spacetelescope/jwst/wiki/Maintaining-Regression-Tests
<div align="center"><img src="https://raw.githubusercontent.com/PlasmaPy/PlasmaPy-logo/main/exports/with-text-dark.png" width="600"/></div>

# PlasmaPy

[![PyPI version](https://img.shields.io/pypi/v/plasmapy?style=flat&logo=pypi)](https://pypi.org/project/plasmapy/)
[![Conda version](https://img.shields.io/conda/v/conda-forge/plasmapy?style=flat&logo=anaconda)](https://img.shields.io/conda/v/conda-forge/plasmapy)
[![PyPI version](https://img.shields.io/pypi/pyversions/plasmapy?style=flat&logo=python)](https://img.shields.io/pypi/pyversions/plasmapy?style=plastic)
[![License](https://img.shields.io/badge/License-BSD%203--Clause-blue.svg)](./LICENSE.md)
[![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg)](https://docs.plasmapy.org/en/latest/CODE_OF_CONDUCT.html)

[![Matrix](https://img.shields.io/badge/Matrix-join%20chat-blueviolet?style=flat&logo=matrix)](https://app.element.io/#/room/#plasmapy:openastronomy.org)
<a rel="me" href="https://fosstodon.org/@plasmapy">![Mastodon](https://img.shields.io/badge/Mastodon-plasmapy%40fosstodon.org-blue?logo=mastodon&style=fla)</a>
[![Twitter](https://img.shields.io/badge/Twitter%20-follow-red?style=flat&logo=twitter)](https://twitter.com/plasmapy)
[![YouTube](https://img.shields.io/badge/YouTube%20-subscribe-red?style=flat&logo=youtube)](https://www.youtube.com/channel/UCSH6qzslhqIZKTAJmHPxIxw)

[![GitHub Actions — CI](https://github.com/PlasmaPy/PlasmaPy/workflows/CI/badge.svg)](https://github.com/PlasmaPy/PlasmaPy/actions?query=workflow%3ACI+branch%3Amain)
[![weekly tests](https://github.com/PlasmaPy/PlasmaPy/actions/workflows/weekly.yml/badge.svg?branch=main)](https://github.com/PlasmaPy/PlasmaPy/actions/workflows/weekly.yml)
[![pre-commit.ci status](https://results.pre-commit.ci/badge/github/PlasmaPy/PlasmaPy/main.svg)](https://results.pre-commit.ci/latest/github/PlasmaPy/PlasmaPy/main)
[![codecov](https://codecov.io/gh/PlasmaPy/PlasmaPy/branch/main/graph/badge.svg)](https://codecov.io/gh/PlasmaPy/PlasmaPy)
[![Read the Docs Status](https://readthedocs.org/projects/plasmapy/badge/?version=latest&logo=twitter)](http://plasmapy.readthedocs.io/en/latest/?badge=latest)

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.1436011.svg)](https://doi.org/10.5281/zenodo.1436011)
[![astropy](http://img.shields.io/badge/powered%20by-AstroPy-orange.svg?style=flat&logo=astropy)](http://www.astropy.org/)
[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://github.com/pre-commit/pre-commit)
[![Open Source Helpers](https://www.codetriage.com/plasmapy/plasmapy/badges/users.svg)](https://www.codetriage.com/plasmapy/plasmapy)

[Anaconda Navigator]: https://docs.anaconda.com/anaconda/navigator/index.html
[Astropy]: https://www.astropy.org
[3-clause BSD license]: ./LICENSE.md
[calendar]: https://calendar.google.com/calendar/embed?src=c_sqqq390s24jjfjp3q86pv41pi8%40group.calendar.google.com&ctz=America%2FNew_York
[citation instructions]: https://docs.plasmapy.org/en/latest/about/citation.html
[code of conduct]: http://docs.plasmapy.org/en/latest/CODE_OF_CONDUCT.html
[collaborative award]: https://doi.org/10.5281/zenodo.2633286
[command line]: https://tutorial.djangogirls.org/en/intro_to_command_line/
[community meetings]: https://www.plasmapy.org/meetings/weekly
[contributor guide]: https://docs.plasmapy.org/en/latest/development/index.html
[Cyberinfrastructure for Sustained Scientific Innovation]: https://beta.nsf.gov/funding/opportunities/cyberinfrastructure-sustained-scientific-innovation-cssi
[Department of Energy]: https://www.energy.gov
[emerging best practice for software citation]: https://doi.org/10.7717/peerj-cs.86
[example gallery]: https://docs.plasmapy.org/en/stable/examples.html
[GitHub discussions]: https://github.com/PlasmaPy/PlasmaPy/discussions
[Gitter]: https://gitter.im/PlasmaPy/Lobby
[good first issues]: https://github.com/PlasmaPy/PlasmaPy/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22
[Google Summer of Code]: https://summerofcode.withgoogle.com
[hack week]: https://doi.org/10.1073/pnas.1717196115
[how to install plasmapy]: https://docs.plasmapy.org/en/stable/install.html
[installed Conda]: https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html
[download and install Python]: https://wiki.python.org/moin/BeginnersGuide/Download
[GitHub repository]: https://github.com/PlasmaPy/PlasmaPy
[installing PlasmaPy]: https://docs.plasmapy.org/en/latest/install.html
[installing PlasmaPy from source]: http://docs.plasmapy.org/en/latest/install.html#building-and-installing-from-source-code
[Mailing list]: https://groups.google.com/forum/#!forum/plasmapy
[Matrix]: https://app.element.io/#/room/#plasmapy:openastronomy.org
[meetings]: https://www.plasmapy.org/meetings/weekly
[NASA]: https://www.nasa.gov/
[National Science Foundation]: https://nsf.gov
[office hours]: http://www.plasmapy.org/meetings/office_hours
[pip]: https://pypi.org/project/pip
[Plasma Hack Week]: https://hack.plasma.org
[PlasmaPy Community on Zenodo]: https://zenodo.org/communities/plasmapy
[PlasmaPy]: https://www.plasmapy.org
[PlasmaPy's online documentation]: https://docs.plasmapy.org
[protections against software patents]: ./PATENT.md
[Python]: https://www.python.org
[Smithsonian Institution]: https://www.si.edu
[submit a bug report]: https://github.com/PlasmaPy/PlasmaPy/issues/new?assignees=&labels=Bug&template=bug_report.yml
[submit a feature request]: https://github.com/PlasmaPy/PlasmaPy/issues/new?assignees=&labels=Feature+request&template=feature_request.yml
[Suggestion box]: https://docs.google.com/forms/d/e/1FAIpQLSdT3O5iHZrLJRuavFyzoR23PGy0Prfzx2SQOcwJGWtvHyT2lw/viewform?usp=sf_link
[team@plasmapy.org]: mailto:team@plasmapy.org
[this video]: https://youtu.be/E8RwQF5wcXM
[Zoom]: https://zoom.us/j/91633383503?pwd=QWNkdHpWeFhrYW1vQy91ODNTVG5Ndz09

[PlasmaPy] is an open source, community-developed [Python] package for
plasma research and education. PlasmaPy intends to be for plasma
science what [Astropy] is for astronomy — a collection of
functionality commonly needed by plasma scientists and researchers
globally, running within and leveraging the open source scientific
Python ecosystem. The goals of PlasmaPy are more thoroughly described
in [this video]. Current functionality is described in [PlasmaPy's
online documentation]. If you would like an idea of what PlasmaPy can
do, check out our [example gallery] of Jupyter notebooks. Many of our
recent presentations are available from the [PlasmaPy Community on
Zenodo].

Please [submit a feature request] in our [GitHub repository] if you
have an idea for new functionality. PlasmaPy is community-driven, and
feature requests really help guide the direction of software
development. Please also [submit a bug report] if you notice any
problems. We really appreciate it!

If you are interested in contributing, please check out our
[contributor guide] and [code of conduct]. There are also a number of
[good first issues] in our GitHub repository. New contributors are
very welcome!

## Installation

PlasmaPy requires Python 3.9 or newer. If you do not have Python
installed already, here are the instructions to [download and install
Python].

To install PlasmaPy on macOS or Linux, open a terminal and run:
```Shell
python -m pip install plasmapy
```
On some systems, it might be necessary to specify the Python version
number, for example by using `python3` or `python3.11` instead of
`python`.

To install PlasmaPy on Windows, open a terminal and run
```Shell
py -3.11 -m pip install plasmapy
```
The `3.11` may be replaced by any version of Python that is supported by
PlasmaPy.

If you have [installed Conda], then you can also install PlasmaPy into
an activated Conda environment by running:
```Shell
conda install -c conda-forge plasmapy
```
PlasmaPy can also be installed using [Anaconda Navigator] so long as
`conda-forge` is added as a channel.

Check out our instructions on [installing PlasmaPy] for more details.

Please check out our documentation for more information on [how to
install PlasmaPy]. To contribute to the package or use the most recent
version, check out our instructions on [installing PlasmaPy from
source].

## Events

PlasmaPy has several [meetings] that are on our [calendar]. Events are
usually held on PlasmaPy's [Zoom] room.

Last-minute changes are usually announced on the [Matrix]/[Gitter]
chat room. The most up-to-date information about these meetings is on
the [meetings] page of PlasmaPy's website.

### Office hours

Our weekly informal [office hours] are an opportunity to chat with
active members of the PlasmaPy community about topics related to
Python and plasma science. If you'd like to learn more about PlasmaPy,
our office hours are one of the best places to start. As of October
2023, our office hours are on most Thursdays at 2 pm Eastern. Please
feel free to come by!

### Community meetings

PlasmaPy's weekly [community meetings] are a place to talk about code
development. If you have an idea for a new feature or would like to
make a code contribution, community meetings are a good place to go
to.  As of October 2023, our community meetings are on most Tuesdays
at 2 pm Eastern.

### Project meetings

PlasmaPy's weekly project meetings are a place to discuss education,
outreach, and project coordination. Topics might range from creating
educational notebooks to organizing community events. As of October
2023, project meetings are held on most Wednesdays at 3 pm Eastern.

### Working group meetings

PlasmaPy has started several working groups, including on diagnostics,
dispersion relations, and simulation. These working groups usually
meet fortnightly, and their meeting times can be found in PlasmaPy's
event [calendar]. If you would like to join a PlasmaPy working group
or even start a new one, please email us at [team@plasmapy.org]!

### Plasma Hack Week

A [hack week] is a mix of a hackathon and a summer school. Hack weeks
provide an opportunity to learn from each other and code together. The
inaugural [Plasma Hack Week] was held virtually in the summer of 2021,
and will hopefully be held annually. Please check out the [Plasma Hack
Week] website for more details, and email [team@plasmapy.org] if you
would like to become an organizer.

## Community

### Matrix chat

If you have any questions, the quickest way to get a response is to
ask on our [Matrix]/[Gitter] channel. Both of these are the same chat
channel; Gitter uses a bridge to link the two.

### GitHub discussions

We're trying out [GitHub discussions] as a place to suggest ideas,
bring up discussion topics, and ask questions.

### Mailing list

You can subscribe to PlasmaPy's low-volume [mailing list] to receive
PlasmaPy newsletters and other announcements.

### Suggestion box

We have a [suggestion box] if you would like to (optionally
anonymously) suggest a feature/topic for consideration. These
suggestions might be changed into GitHub issues for further
discussion.

## Contact information

Please feel free to reach out to us at [team@plasmapy.org] or stop by
our [office hours] with any ideas, questions, and/or puns about
computational magnetohydrodynamics.

## License

PlasmaPy is permissively licensed under a [3-clause BSD license] with
added [protections against software patents].

## Citing PlasmaPy

An [emerging best practice for software citation] is to cite the
_specific version_ of each software package used in a research project
(instead of only citing a journal article, website, or GitHub
repository). The citation should include a persistent identifier that
uniquely identifies which version of the software was used. We
therefore ask that you cite the specific version of PlasmaPy used in
your research project. Releases of PlasmaPy are available from the
[PlasmaPy community on Zenodo], along with many other PlasmaPy
resources. Please check our documentation for more detailed [citation
instructions].

## Acknowledgments

Early development on PlasmaPy was supported in part by the U.S.
[Department of Energy], the [Smithsonian Institution], [NASA], and
[Google Summer of Code]. Ongoing PlasmaPy development is being
supported through a [collaborative award] from the
[Cyberinfrastructure for Sustained Scientific Innovation] program of
the U.S. [National Science Foundation].
ASDF - Advanced Scientific Data Format
======================================

.. _begin-badges:

.. image:: https://github.com/asdf-format/asdf/workflows/CI/badge.svg
    :target: https://github.com/asdf-format/asdf/actions
    :alt: CI Status

.. image:: https://github.com/asdf-format/asdf/workflows/s390x/badge.svg
    :target: https://github.com/asdf-format/asdf/actions
    :alt: s390x Status

.. image:: https://github.com/asdf-format/asdf/workflows/Downstream/badge.svg
    :target: https://github.com/asdf-format/asdf/actions
    :alt: Downstream CI Status

.. image:: https://readthedocs.org/projects/asdf/badge/?version=latest
    :target: https://asdf.readthedocs.io/en/latest/

.. image:: https://codecov.io/gh/asdf-format/asdf/branch/main/graphs/badge.svg
    :target: https://codecov.io/gh/asdf-format/asdf

.. _begin-zenodo:

.. image:: https://zenodo.org/badge/18112754.svg
    :target: https://zenodo.org/badge/latestdoi/18112754

.. _end-zenodo:

.. image:: https://img.shields.io/pypi/l/asdf.svg
    :target: https://img.shields.io/pypi/l/asdf.svg

.. image:: https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white
    :target: https://github.com/pre-commit/pre-commit
    :alt: pre-commit

.. image:: https://img.shields.io/badge/code%20style-black-000000.svg
    :target: https://github.com/psf/black

.. _end-badges:

.. _begin-summary-text:

The **A**\ dvanced **S**\ cientific **D**\ ata **F**\ ormat (ASDF) is a
next-generation interchange format for scientific data. This package
contains the Python implementation of the ASDF Standard. More
information on the ASDF Standard itself can be found
`here <https://asdf-standard.readthedocs.io>`__.

The ASDF format has the following features:

* A hierarchical, human-readable metadata format (implemented using `YAML
  <http://yaml.org>`__)
* Numerical arrays are stored as binary data blocks which can be memory
  mapped. Data blocks can optionally be compressed.
* The structure of the data can be automatically validated using schemas
  (implemented using `JSON Schema <http://json-schema.org>`__)
* Native Python data types (numerical types, strings, dicts, lists) are
  serialized automatically
* ASDF can be extended to serialize custom data types

.. _end-summary-text:

ASDF is under active development `on github
<https://github.com/asdf-format/asdf>`__. More information on contributing
can be found `below <#contributing>`__.

Overview
--------

This section outlines basic use cases of the ASDF package for creating
and reading ASDF files.

Creating a file
~~~~~~~~~~~~~~~

.. _begin-create-file-text:

We're going to store several `numpy` arrays and other data to an ASDF file. We
do this by creating a "tree", which is simply a `dict`, and we provide it as
input to the constructor of `AsdfFile`:

.. code:: python

    import asdf
    import numpy as np

    # Create some data
    sequence = np.arange(100)
    squares = sequence**2
    random = np.random.random(100)

    # Store the data in an arbitrarily nested dictionary
    tree = {
        "foo": 42,
        "name": "Monty",
        "sequence": sequence,
        "powers": {"squares": squares},
        "random": random,
    }

    # Create the ASDF file object from our data tree
    af = asdf.AsdfFile(tree)

    # Write the data to a new file
    af.write_to("example.asdf")

If we open the newly created file's metadata section, we can see some of the key features
of ASDF on display:

.. _begin-example-asdf-metadata:

.. code:: yaml

    #ASDF 1.0.0
    #ASDF_STANDARD 1.2.0
    %YAML 1.1
    %TAG ! tag:stsci.edu:asdf/
    --- !core/asdf-1.1.0
    asdf_library: !core/software-1.0.0 {author: The ASDF Developers, homepage: 'http://github.com/asdf-format/asdf',
      name: asdf, version: 2.0.0}
    history:
      extensions:
      - !core/extension_metadata-1.0.0
        extension_class: asdf.extension.BuiltinExtension
        software: {name: asdf, version: 2.0.0}
    foo: 42
    name: Monty
    powers:
      squares: !core/ndarray-1.0.0
        source: 1
        datatype: int64
        byteorder: little
        shape: [100]
    random: !core/ndarray-1.0.0
      source: 2
      datatype: float64
      byteorder: little
      shape: [100]
    sequence: !core/ndarray-1.0.0
      source: 0
      datatype: int64
      byteorder: little
      shape: [100]
    ...

.. _end-example-asdf-metadata:

The metadata in the file mirrors the structure of the tree that was stored. It
is hierarchical and human-readable. Notice that metadata has been added to the
tree that was not explicitly given by the user. Notice also that the numerical
array data is not stored in the metadata tree itself. Instead, it is stored as
binary data blocks below the metadata section (not shown above).

.. _end-create-file-text:
.. _begin-compress-file:

It is possible to compress the array data when writing the file:

.. code:: python

    af.write_to("compressed.asdf", all_array_compression="zlib")

The built-in compression algorithms are ``'zlib'``, and ``'bzp2'``.  The
``'lz4'`` algorithm becomes available when the `lz4 <https://python-lz4.readthedocs.io/>`__ package
is installed.  Other compression algorithms may be available via extensions.

.. _end-compress-file:

Reading a file
~~~~~~~~~~~~~~

.. _begin-read-file-text:

To read an existing ASDF file, we simply use the top-level `open` function of
the `asdf` package:

.. code:: python

    import asdf

    af = asdf.open("example.asdf")

The `open` function also works as a context handler:

.. code:: python

    with asdf.open("example.asdf") as af:
        ...

To get a quick overview of the data stored in the file, use the top-level
`AsdfFile.info()` method:

.. code:: pycon

    >>> import asdf
    >>> af = asdf.open("example.asdf")
    >>> af.info()
    root (AsdfObject)
    ├─asdf_library (Software)
    │ ├─author (str): The ASDF Developers
    │ ├─homepage (str): http://github.com/asdf-format/asdf
    │ ├─name (str): asdf
    │ └─version (str): 2.8.0
    ├─history (dict)
    │ └─extensions (list)
    │   └─[0] (ExtensionMetadata)
    │     ├─extension_class (str): asdf.extension.BuiltinExtension
    │     └─software (Software)
    │       ├─name (str): asdf
    │       └─version (str): 2.8.0
    ├─foo (int): 42
    ├─name (str): Monty
    ├─powers (dict)
    │ └─squares (NDArrayType): shape=(100,), dtype=int64
    ├─random (NDArrayType): shape=(100,), dtype=float64
    └─sequence (NDArrayType): shape=(100,), dtype=int64

The `AsdfFile` behaves like a Python `dict`, and nodes are accessed like
any other dictionary entry:

.. code:: pycon

    >>> af["name"]
    'Monty'
    >>> af["powers"]
    {'squares': <array (unloaded) shape: [100] dtype: int64>}

Array data remains unloaded until it is explicitly accessed:

.. code:: pycon

    >>> af["powers"]["squares"]
    array([   0,    1,    4,    9,   16,   25,   36,   49,   64,   81,  100,
            121,  144,  169,  196,  225,  256,  289,  324,  361,  400,  441,
            484,  529,  576,  625,  676,  729,  784,  841,  900,  961, 1024,
           1089, 1156, 1225, 1296, 1369, 1444, 1521, 1600, 1681, 1764, 1849,
           1936, 2025, 2116, 2209, 2304, 2401, 2500, 2601, 2704, 2809, 2916,
           3025, 3136, 3249, 3364, 3481, 3600, 3721, 3844, 3969, 4096, 4225,
           4356, 4489, 4624, 4761, 4900, 5041, 5184, 5329, 5476, 5625, 5776,
           5929, 6084, 6241, 6400, 6561, 6724, 6889, 7056, 7225, 7396, 7569,
           7744, 7921, 8100, 8281, 8464, 8649, 8836, 9025, 9216, 9409, 9604,
           9801])

    >>> import numpy as np
    >>> expected = [x**2 for x in range(100)]
    >>> np.equal(af["powers"]["squares"], expected).all()
    True

By default, uncompressed data blocks are memory mapped for efficient
access. Memory mapping can be disabled by using the ``copy_arrays``
option of `open` when reading:

.. code:: python

    af = asdf.open("example.asdf", copy_arrays=True)

.. _end-read-file-text:

For more information and for advanced usage examples, see the
`documentation <#documentation>`__.

Extending ASDF
~~~~~~~~~~~~~~

Out of the box, the ``asdf`` package automatically serializes and
deserializes native Python types. It is possible to extend ``asdf`` by
implementing custom tags that correspond to custom user types. More
information on extending ASDF can be found in the `official
documentation <http://asdf.readthedocs.io/en/latest/#extending-asdf>`__.

Installation
------------

.. _begin-pip-install-text:

Stable releases of the ASDF Python package are registered `at
PyPi <https://pypi.python.org/pypi/asdf>`__. The latest stable version
can be installed using ``pip``:

::

    $ pip install asdf

.. _begin-source-install-text:

The latest development version of ASDF is available from the ``main`` branch
`on github <https://github.com/asdf-format/asdf>`__. To clone the project:

::

    $ git clone https://github.com/asdf-format/asdf

To install:

::

    $ cd asdf
    $ pip install .

To install in `development
mode <https://packaging.python.org/tutorials/distributing-packages/#working-in-development-mode>`__::

    $ pip install -e .

.. _end-source-install-text:

Testing
-------

.. _begin-testing-text:

To install the test dependencies from a source checkout of the repository:

::

    $ pip install -e ".[tests]"

To run the unit tests from a source checkout of the repository:

::

    $ pytest

It is also possible to run the test suite from an installed version of
the package.

::

    $ pip install "asdf[tests]"
    $ pytest --pyargs asdf

It is also possible to run the tests using `tox
<https://tox.readthedocs.io/en/latest/>`__.

::

   $ pip install tox

To list all available environments:

::

   $ tox -va

To run a specific environment:

::

   $ tox -e <envname>


.. _end-testing-text:

Documentation
-------------

More detailed documentation on this software package can be found
`here <https://asdf.readthedocs.io>`__.

More information on the ASDF Standard itself can be found
`here <https://asdf-standard.readthedocs.io>`__.

There are two mailing lists for ASDF:

* `asdf-users <https://groups.google.com/forum/#!forum/asdf-users>`_
* `asdf-developers <https://groups.google.com/forum/#!forum/asdf-developers>`_

    If you are looking for the **A**\ daptable **S**\ eismic **D**\ ata
    **F**\ ormat, information can be found
    `here <https://seismic-data.org/>`__.

License
-------

ASDF is licensed under a BSD 3-clause style license. See `LICENSE.rst <LICENSE.rst>`_
for the `licenses folder <licenses>`_ for
licenses for any included software.

Contributing
------------

We welcome feedback and contributions to the project. Contributions of
code, documentation, or general feedback are all appreciated. Please
follow the `contributing guidelines <CONTRIBUTING.rst>`__ to submit an
issue or a pull request.

We strive to provide a welcoming community to all of our users by
abiding to the `Code of Conduct <CODE_OF_CONDUCT.md>`__.
TermTrack
---------

Track orbiting objects (such as the International Space Station) in your terminal!

.. image:: https://raw.githubusercontent.com/trehn/termtrack/master/screenshot.png
    :alt: Screenshot

Requires Python 3.3+ and a terminal with 256 colors. A black background is highly recommended.

.. code-block::

	pip3 install termtrack
	termtrack -figmntxo 1 iss

.. code-block::

	Usage: termtrack [OPTIONS] [SATELLITE]

	  Shows a world map tracking SATELLITE. Valid values for SATELLITE are
	  numbers from http://www.celestrak.com/NORAD/elements/master.php (for
	  your convenience, a number of aliases have been provided).

	  Example satellite aliases (find more with --aliases):
	      hubble          Hubble Space Telescope
	      iss             International Space Station

	  Hotkeys:
	      a       Toggle apsides markers
	      c       Toggle next-orbit coverage overlay
	      d       Toggle ascent/descent markers
	      f       Toggle footprint (satellite horizon)
	      g       Toggle latitude/longitude grid
	      i       Toggle info panels
	      n       Toggle night shading
	      o       Cycle through drawing 0-3 next orbits
	      p       Pause/resume
	      q       Quit
	      r       Reset plotted time to current
	      t       Toggle topography
	      x       Toggle crosshair
	      left    Small step back in time
	      right   Small step forward in time
	      down    Large step back in time
	      up      Large step forward in time

	Options:
	  --aliases                 Show all satellite aliases and exit
	  --apsides                 Draw apoapsis and periapsis markers
	  -b, --body BODY           Which celestial body to draw: Earth, Moon or Mars
	                            (defaults to Earth)
	  -c, --coverage            Show next-orbit coverage overlay
	  -f, --footprint           Draw satellite footprint/horizon
	  --fps N                   Frames per second (defaults to 1)
	  -g, --grid                Draw latitude/longitude grid
	  -i, --info                Show info panels
	  -m, --me                  Auto-detect your location as observer
	  -n, --night               Shade night side
	  -o, --orbits N            Draw this many orbits ahead of the satellite
	  --orbit-ascdesc           Draw orbits with ascent/descent markers
	  -O, --observer 'LAT LON'  Space-separated latitude and longitude of an
	                            observer; overrides IP-geolocation
	  -p, --paused              Start paused
	  -P, --planets PLANETS     Comma-separated list of celestial objects to draw
	                            (e.g. 'sun,moon')
	  -r, --orbit-res [/]N[+]   Set distance of orbit markers: 'N' means N
	                            minutes, '/N' means 1/Nth of orbital period,
	                            append a plus sign to interpolate in between
	                            markers (defaults to /70)
	  -t, --topo                Enable coloring of topographical features
	  --tle FILE                read TLE data from FILE instead of downloading it
	                            (SATELLITE will have no effect and can be omitted)
	  -x, --crosshair           Draw crosshair around satellite location
	  --version                 Show version and exit
	  --help                    Show this message and exit

Credit goes to `vain/asciiworld <https://github.com/vain/asciiworld>`_ for inspiration and some tasty pieces of code.

------------------------------------------------------------------------

.. image:: http://img.shields.io/pypi/v/termtrack.svg
    :target: https://pypi.python.org/pypi/termtrack/
    :alt: Latest Version

.. image:: http://img.shields.io/badge/Python-3.3+-green.svg
    :target: https://pypi.python.org/pypi/termtrack/
    :alt: Python 3.3+

.. image:: http://img.shields.io/badge/License-GPLv3-red.svg
    :target: https://pypi.python.org/pypi/termtrack/
    :alt: License

------------------------------------------------------------------------

How Stuff Works
===============

To draw the map, TermTrack will look at a shapefile from `Natural Earth <http://www.naturalearthdata.com>`_ in order to find coordinates that are within a landmass. While computationally expensive, this method yields the most accurate and good-looking maps at all terminal sizes. To determine the color of each pixel, a relatively low-resolution and low-quality JPEG image is used. If you look at the image (``termtrack/data/earth.jpg``), you'll notice it has green oceans. This is to ensure that ocean blue will not spill over into coastal areas during downsampling. Same goes for the expanded white coast of Antarctica. Finally, the image has been tuned to produce good-looking colors against a black background. The resolution and quality of the image is not really a concern since we do not need maximum per-pixel precision to make the Sahara appear yellow. After computing land/ocean status and land color, this information is cached in ``~/.termtrack_map_cache``, so it will not have to be rendered again for the current terminal size.

For Mars and the Moon there is no shapefile to read and the entire area is colored according to similar JPEG color maps.

Night shading for each pixel is done by looking at the Sun's elevation (as computed by `pyephem <http://rhodesmill.org/pyephem/>`_) and shifting the color of the pixel towards blue accordingly. Twilight starts when the Sun is 18° below the horizon (`astronomical twilight <https://en.wikipedia.org/wiki/Twilight#Astronomical_twilight>`_) and ends when it has risen to 0°.

Satellite locations are derived from `TLE <https://en.wikipedia.org/wiki/Two-line_element_set>`_ data downloaded from `CelesTrak <https://celestrak.com/>`_. The data is fed into pyephem where the current position of the satellite is computed using `SGP4 <https://en.wikipedia.org/wiki/Simplified_perturbations_models>`_. Most of the data you see in the info panels is provided by pyephem, but the apsides' locations as well as the satellite footprint outline are computed by TermTrack itself.


Known Issues
============

When looking at the ISS, you may notice some inconsistencies:

* the apoapsis/periapsis altitudes from the info panel do not match up with live altitude values when the satellite actually is at that point
* sometimes the current altitude is lower/higher than periapsis/apoapsis altitude
* the location of apoapsis/periapsis markers from ``--apsides`` are not located at the transition points between plus and minus signs drawn by ``--orbit-ascdesc``

Where do these errors come from? The locations of the apsides are derived from the true anomaly which matches values from http://www.satellite-calculations.com/TLETracker/SatTracker.htm so I'm assuming that's not the source of the error. The shape of the Earth also does not explain the deviations in altitude.

Interestingly enough, when you look at more eccentric orbits like that of QZS-1 (37158) the errors seem to disappear, suggesting that the issue is merely inaccuracy instead of a plain wrong calculation somewhere.
# The yt Project

[![PyPI](https://img.shields.io/pypi/v/yt)](https://pypi.org/project/yt)
[![Supported Python Versions](https://img.shields.io/pypi/pyversions/yt)](https://pypi.org/project/yt/)
[![Latest Documentation](https://img.shields.io/badge/docs-latest-brightgreen.svg)](http://yt-project.org/docs/dev/)
[![Users' Mailing List](https://img.shields.io/badge/Users-List-lightgrey.svg)](https://mail.python.org/archives/list/yt-users@python.org//)
[![Devel Mailing List](https://img.shields.io/badge/Devel-List-lightgrey.svg)](https://mail.python.org/archives/list/yt-dev@python.org//)
[![Data Hub](https://img.shields.io/badge/data-hub-orange.svg)](https://hub.yt/)
[![Powered by NumFOCUS](https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A)](http://numfocus.org)
[![Sponsor our Project](https://img.shields.io/badge/donate-to%20yt-blueviolet)](https://numfocus.salsalabs.org/donate-to-yt/index.html)

<!--- Tests and style --->
[![Build and Test](https://github.com/yt-project/yt/actions/workflows/build-test.yaml/badge.svg)](https://github.com/yt-project/yt/actions/workflows/build-test.yaml)
[![CI (bleeding edge)](https://github.com/yt-project/yt/actions/workflows/bleeding-edge.yaml/badge.svg)](https://github.com/yt-project/yt/actions/workflows/bleeding-edge.yaml)
[![pre-commit.ci status](https://results.pre-commit.ci/badge/github/yt-project/yt/main.svg)](https://results.pre-commit.ci/latest/github/yt-project/yt/main)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/charliermarsh/ruff/main/assets/badge/v2.json)](https://github.com/charliermarsh/ruff)

<!--- [![codecov](https://codecov.io/gh/yt-project/yt/branch/main/graph/badge.svg)](https://codecov.io/gh/yt-project/yt) --->

<a href="http://yt-project.org"><img src="https://raw.githubusercontent.com/yt-project/yt/main/doc/source/_static/yt_logo.png" width="300"></a>

yt is an open-source, permissively-licensed Python library for analyzing and
visualizing volumetric data.

yt supports structured, variable-resolution meshes, unstructured meshes, and
discrete or sampled data such as particles. Focused on driving
physically-meaningful inquiry, yt has been applied in domains such as
astrophysics, seismology, nuclear engineering, molecular dynamics, and
oceanography. Composed of a friendly community of users and developers, we want
to make it easy to use and develop - we'd love it if you got involved!

We've written a [method
paper](https://ui.adsabs.harvard.edu/abs/2011ApJS..192....9T) you may be interested
in; if you use yt in the preparation of a publication, please consider citing
it.

## Code of Conduct

yt abides by a code of conduct partially modified from the PSF code of conduct,
and is found [in our contributing
guide](http://yt-project.org/docs/dev/developing/developing.html#yt-community-code-of-conduct).

## Installation

You can install the most recent stable version of yt either with conda from
[conda-forge](https://conda-forge.org/):

```shell
conda install -c conda-forge yt
```

or with pip:

```shell
python -m pip install yt
```

More information on the various ways to install yt, and in particular to install from source,
can be found on [the project's website](https://yt-project.org/docs/dev/installing.html).

## Getting Started

yt is designed to provide meaningful analysis of data.  We have some Quickstart
example notebooks in the repository:

 * [Introduction](https://github.com/yt-project/yt/tree/main/doc/source/quickstart/1\)_Introduction.ipynb)
 * [Data Inspection](https://github.com/yt-project/yt/tree/main/doc/source/quickstart/2\)_Data_Inspection.ipynb)
 * [Simple Visualization](https://github.com/yt-project/yt/tree/main/doc/source/quickstart/3\)_Simple_Visualization.ipynb)
 * [Data Objects and Time Series](https://github.com/yt-project/yt/tree/main/doc/source/quickstart/4\)_Data_Objects_and_Time_Series.ipynb)
 * [Derived Fields and Profiles](https://github.com/yt-project/yt/tree/main/doc/source/quickstart/5\)_Derived_Fields_and_Profiles.ipynb)
 * [Volume Rendering](https://github.com/yt-project/yt/tree/main/doc/source/quickstart/6\)_Volume_Rendering.ipynb)

If you'd like to try these online, you can visit our [yt Hub](https://hub.yt/)
and run a notebook next to some of our example data.

## Contributing

We love contributions!  yt is open source, built on open source, and we'd love
to have you hang out in our community.

We have developed some [guidelines](CONTRIBUTING.rst) for contributing to yt.

**Imposter syndrome disclaimer**: We want your help. No, really.

There may be a little voice inside your head that is telling you that you're not
ready to be an open source contributor; that your skills aren't nearly good
enough to contribute. What could you possibly offer a project like this one?

We assure you - the little voice in your head is wrong. If you can write code at
all, you can contribute code to open source. Contributing to open source
projects is a fantastic way to advance one's coding skills. Writing perfect code
isn't the measure of a good developer (that would disqualify all of us!); it's
trying to create something, making mistakes, and learning from those
mistakes. That's how we all improve, and we are happy to help others learn.

Being an open source contributor doesn't just mean writing code, either. You can
help out by writing documentation, tests, or even giving feedback about the
project (and yes - that includes giving feedback about the contribution
process). Some of these contributions may be the most valuable to the project as
a whole, because you're coming to the project with fresh eyes, so you can see
the errors and assumptions that seasoned contributors have glossed over.

(This disclaimer was originally written by
[Adrienne Lowe](https://github.com/adriennefriend) for a
[PyCon talk](https://www.youtube.com/watch?v=6Uj746j9Heo), and was adapted by yt
based on its use in the README file for the
[MetPy project](https://github.com/Unidata/MetPy))

## Resources

We have some community and documentation resources available.

 * Our latest documentation is always at http://yt-project.org/docs/dev/ and it
   includes recipes, tutorials, and API documentation
 * The [discussion mailing
   list](https://mail.python.org/archives/list/yt-users@python.org//)
   should be your first stop for general questions
 * The [development mailing
   list](https://mail.python.org/archives/list/yt-dev@python.org//) is
   better suited for more development issues
 * You can also join us on Slack at yt-project.slack.com ([request an
   invite](https://yt-project.org/slack.html))

Is your code compatible with yt ? Great ! Please consider giving us a shoutout as a shiny badge in your README

- markdown
```markdown
[![yt-project](https://img.shields.io/static/v1?label="works%20with"&message="yt"&color="blueviolet")](https://yt-project.org)
```
- rst
```reStructuredText
|yt-project|

.. |yt-project| image:: https://img.shields.io/static/v1?label="works%20with"&message="yt"&color="blueviolet"
   :target: https://yt-project.org
```

## Powered by NumFOCUS

yt is a fiscally sponsored project of [NumFOCUS](https://numfocus.org/).
If you're interested in
supporting the active maintenance and development of this project, consider
[donating to the project](https://numfocus.salsalabs.org/donate-to-yt/index.html).
# Tao Tie (饕餮) - A curated collection of resources for astrophysical research

<img src="doc/images/taotie_logo.png" width="100%">

[![Repo on GitHub](https://img.shields.io/badge/repo-GitHub-3D76C2.svg)](https://github.com/dr-guangtou/taotie)
[![Repo on GitLab](https://img.shields.io/badge/repo-GitLab-6C488A.svg)](https://gitlab.com/dr-guangtou/taotie)
![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)
[![Documentation Status](https://readthedocs.org/projects/taotie/badge/?version=latest)](https://taotie.readthedocs.io/en/latest/?badge=latest)

----

> “The taotie is a motif commonly found on Chinese ritual bronze vessels from the Shang and Zhou dynasty...In ancient Chinese mythology like "Classic of Mountains and Seas", the "taotie" (饕餮) is one of the "four evil creatures of the world"...a greedy and gluttonous son of the Jinyun clan, who lived during the time of the legendary Yellow Emperor.” - [Wikipedia](https://en.wikipedia.org/wiki/Taotie)

> "缙云氏有不才子，贪于饮食，冒于货贿，天下谓之饕餮" - [《吕氏春秋·先识》](https://zh.wikipedia.org/wiki/%E9%A5%95%E9%A4%AE)

Motivation and Goals
--------------------

* Over the past ~10 years, I have gradually accumulated some useful resources for astrophysical research and I believe the best way to make use of these information is to share them.
* The name `taotie` (饕餮) refers to a greedy and gluttonous monster in ancient Chinese myth. It is indeed very greedy and over-ambitious to collect all useful resources for astrophysics and cosmology.
* **The goal of `taotie`** is to become a curated list of resources for astronomy and astrophysics maintained by the community. Just like many other `awesome` lists available on `GitHub`. We hope `taotie` can become the first stop for new student or researcher in astronomy to seek for practical guidance and experience.  And `taotie` can also be a handy and organized "bookmark" for researchers in different fields.

Progress and Plans
------------------

* **Under Construction**: This repo is still under heavy and frequent development. I am currently working on this as a weekend project.
* Currently working on improving the collections of `taotie`, especially for research fields outside my personal comfort zone. **Any help will be highly appreciated!**
* Also working on improving the presentation by making a user-friendly website based on a list of markdown files.

On Using `taotie` (饕餮)
-----------------------

* You can find `taotie` on [this website](https://taotie.readthedocs.io/en/latest/python.html)
* Now `taotie` is available on both [`GitHub`](https://github.com/dr-guangtou/taotie) and [`GitLab`](https://gitlab.com/dr-guangtou/taotie).  And you can also find `taotie` using [this address](https://dr-guangtou.github.io/taotie/)
* For users in mainland China: in case the `Github` link below is not available, please replace `github` with `gitlab` and try again. Please let me know if you have trouble accessing both sites.
* The main language for `taotie` is English. Some of the important documents will be slowly translated into Chinese.

* Please let me know if you have any suggestion or recommendation.

Contents
--------

## [Research in General](https://github.com/dr-guangtou/taotie/tree/master/research)

- Here, we tried to provide some basic information and practical guidance on important topics related to your life as a researcher. These topics include:
    - [Start your life as a researcher in astronomy](https://github.com/dr-guangtou/taotie/blob/master/research/getting_started.md)
        * [A Chinese version is also available (中文版)](https://github.com/dr-guangtou/taotie/blob/master/research/getting_started_cn.md)
    - [Getting a job inside or outside astronomy](https://github.com/dr-guangtou/taotie/blob/master/research/job_and_career.md)
    - [Setting up your computer for research](https://github.com/dr-guangtou/taotie/blob/master/research/computer_basics.md)
    - [Writing scientific papers](https://github.com/dr-guangtou/taotie/blob/master/research/writing_paper.md)
    - [A little bit background in statistics](https://github.com/dr-guangtou/taotie/blob/master/research/stats_basic.md)
    - [A little bit background in data science](https://github.com/dr-guangtou/taotie/blob/master/research/data_science.md)
    - [Also some information about machine learning](https://github.com/dr-guangtou/taotie/tree/master/research/machine_learning.md)
        * Including the [basic learning materials](https://github.com/dr-guangtou/taotie/blob/master/research/machine_learning.md/machine_learning_basic.md), [some useful tools](https://github.com/dr-guangtou/taotie/blob/master/research/machine_learning.md/machine_learning_tools.md), and [examples of applications in astronomy](https://github.com/dr-guangtou/taotie/blob/master/research/machine_learning.md/mlearning_astro_application.md)

## [Astronomy or Astrophysics Related Topics](https://github.com/dr-guangtou/taotie/tree/master/astro)

- [Basic tools for astrophysical research](https://github.com/dr-guangtou/taotie/blob/master/astro/astro_research_basic.md) e.g. Flux, extinction, coordinates, and planning your observations.  Whatever you need.
- [Good reference for all astronomers](https://github.com/dr-guangtou/taotie/blob/master/astro/astro_readme.md): Reference and handbooks that will be handy in research.
- [Useful resources and tools for specific field or topic](https://github.com/dr-guangtou/taotie/tree/master/astro/topics). Right now, we collect some resources for topics about:
    * [Basic astronomical CCD reduction](https://github.com/dr-guangtou/taotie/blob/master/astro/topics/ccd_reduction.md)
    * [Photometry and photometric measurement in astrophysics](https://github.com/dr-guangtou/taotie/blob/master/astro/topics/photometry.md)
    * [Spectroscopy and spectroscopic measurement in astrophysics](https://github.com/dr-guangtou/taotie/blob/master/astro/topics/spectroscopy.md)
    * [Extragalactic astrophysics](https://github.com/dr-guangtou/taotie/blob/master/astro/topics/extragalactic_astronomy.md)
        - More details on [different approaches to model galaxy formation and evolution](https://github.com/dr-guangtou/taotie/blob/master/astro/topics/galaxy_formation_model.md)
    * [Galactic astronomy and Milky Way-related topics](https://github.com/dr-guangtou/taotie/blob/master/astro/topics/galactic_astronomy.md)
    * [Dust, inter-stellar or other diffuse medium in astrophysics](https://github.com/dr-guangtou/taotie/blob/master/astro/topics/ism_and_dust.md) (**Help Needed**)
    * [Observational and theoretical cosmological research](https://github.com/dr-guangtou/taotie/blob/master/astro/topics/cosmology_tools.md)
        - More details on finding [massive dark matter halo or galaxy group/cluster](https://github.com/dr-guangtou/taotie/blob/master/astro/topics/cluster_finder.md)
        - More details on estimating [photometric redshift](https://github.com/dr-guangtou/taotie/blob/master/astro/topics/photoz.md)
    * [Gravitational lensing: micro, weak, and strong](https://github.com/dr-guangtou/taotie/blob/master/astro/topics/lensing.md)
    * [Time-domain astrophysics and transient targets](https://github.com/dr-guangtou/taotie/blob/master/astro/topics/transient_and_time_domain.md) (**Help Needed**)
    * [Observational and theoretical high-energy astrophysics](https://github.com/dr-guangtou/taotie/blob/master/astro/topics/high_energy_astrophy.md) (**Help Needed**)
    * [Radio and sub-mm observations in astrophysics](https://github.com/dr-guangtou/taotie/blob/master/astro/topics/radio_submm_astrophy.md) (**Help Needed**)
    * [Exoplanet and astrobiology](https://github.com/dr-guangtou/taotie/blob/master/astro/topics/exoplanet.md) (**Help Needed**)
    * [Astrophysical and cosmological numerical simulations](https://github.com/dr-guangtou/taotie/blob/master/astro/topics/simulations.md)
    * [Stellar physics and the study of stellar population](https://github.com/dr-guangtou/taotie/blob/master/astro/topics/stellar_and_spops.md)
    * [Solar physics and space weather](https://github.com/dr-guangtou/taotie/blob/master/astro/topics/solar_physics.md) (**Help Needed**)
    * [Solar system and planetary science](https://github.com/dr-guangtou/taotie/blob/master/astro/topics/solar_system.md) (**Help Needed**)
- [Information and resources about key projects in astrophysics and cosmology](https://github.com/dr-guangtou/taotie/tree/master/astro/projects)
    * We want to provide a list of "cheat sheets" for people who want to become familar with a specific project. **Still under heavy constructions!!**
    * Current list includes: [_Gaia_ satellite](https://github.com/dr-guangtou/taotie/blob/master/astro/projects/gaia.md), [Large Synoptic Survey Telescope (LSST)](https://github.com/dr-guangtou/taotie/blob/master/astro/projects/lsst.md), [Dark Energy Spectroscopic Instrument (DESI)](https://github.com/dr-guangtou/taotie/blob/master/astro/projects/desi.md), and [Wide Field Infrared Survey Telescope (WFIRST)](https://github.com/dr-guangtou/taotie/blob/master/astro/projects/wfirst.md)
    * **Still working on including more projects** like the Dark Energy Survey (DES), _Euclid_ satellite, James Webb Space Telescope (JWST), Thirty Meter Telescope (TMT), etc.
- [List of important references and reading list on some specific topics](https://github.com/dr-guangtou/taotie/tree/master/astro/reference)
    * **This is still very preliminary** and only reflects one person's taste and interests.
    * [Recent review articles on arXiv](https://github.com/dr-guangtou/taotie/blob/master/astro/reference/reviews.md)
    * Reading list on some specific topics. Right now, only includes a few examples. e.g. [on cosmology using galaxy clusters](https://github.com/dr-guangtou/taotie/blob/master/astro/reference/cluster_cosmology.md), [on the splash-back radius of dark matter halo](https://github.com/dr-guangtou/taotie/blob/master/astro/reference/halo_splashback_radius.md), and [on the intrinsic alignment of galaxies and its impact on cosmology](https://github.com/dr-guangtou/taotie/blob/master/astro/reference/wl_intrinsic_alignment.md).
    * In the future, will separate them into different categories or sub-fields.

## [Programming and Developing Software](https://github.com/dr-guangtou/taotie/tree/master/programing)

- Resources and tools for `Python`, which is the most popular programming language in astrophysics (for now).
    * [Basic learning materials and documents for `Python`](https://github.com/dr-guangtou/taotie/blob/master/programing/python_basic.md)
    * [On writing your own `Python` package](https://github.com/dr-guangtou/taotie/blob/master/programing/python_write_your_project.md)
    - [On improving the performance of your `Python` code](https://github.com/dr-guangtou/taotie/blob/master/programing/python_performance.md)
    - [On fitting data, optimizing models...you know, astrophysics](https://github.com/dr-guangtou/taotie/blob/master/programing/python_optimizaton.md)
    - [On doing statistical analysis right in `Python`](https://github.com/dr-guangtou/taotie/blob/master/programing/python_statistics.md)
    - [On visualizing data using `Python`](https://github.com/dr-guangtou/taotie/blob/master/programing/python_visualization.md)
- Resources and tools for the [C programming language](https://github.com/dr-guangtou/taotie/blob/master/programing/clang_basic.md) and the [C++ programming langunage](https://github.com/dr-guangtou/taotie/blob/master/programing/cpp_basic.md).
- [Resources and tools for the `Julia` programming language](https://github.com/dr-guangtou/taotie/blob/master/programing/julia_basic.md)
- [Resources and tools for numerical method and scientific computing in general](https://github.com/dr-guangtou/taotie/blob/master/programing/numerical_method.md)


Contribution
------------

Contribution from the community is highly welcomed! Please feel free to fork the repo and make you own change.  If you want your modifications be included in this repo, please submit a pull request (and make sure to describe the changes you made).

And if you notice anything wrong with the current content (wrong or unavailable link for example), please raise an issue.

Also, if your repo or project is included here and you are not comfortable with that, just let me know.


License
-------

Copyright 2019 Song Huang and contributors.

`taotie` is under the MIT License. For details see the LICENSE file.
# Little Sun Gazer

A miniature device depicting the relative position of the Sun and moon.

![pic](docs/pic.jpg)

### Hardware
* Raspberry Pi Pico
* Precision RTC Module (DS3231)
* Waveshare e-Paper 3.7
* Pimoroni LiPo SHIM
* Li-Po 2000mAh 103450

### Case
A 3d printable case for this project will be [here](https://www.thingiverse.com/dr2mod/designs).

### Support the project
If you would like to support what I do and keep me caffeinated, you can do it here:

[!["Buy Me A Coffee"](https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png)](https://www.buymeacoffee.com/drmod)

### Disclaimer 
This is not a finished project, but at the moment I don't have access to required hardware to finish it.Lightkurve
==========

**A friendly package for Kepler & TESS time series analysis in Python.**

**Documentation: https://docs.lightkurve.org**

|test-badge| |conda-badge| |pypi-badge| |pypi-downloads| |doi-badge| |astropy-badge|

.. |conda-badge| image:: https://img.shields.io/conda/vn/conda-forge/lightkurve.svg
                 :target: https://anaconda.org/conda-forge/lightkurve
.. |pypi-badge| image:: https://img.shields.io/pypi/v/lightkurve.svg
                :target: https://pypi.python.org/pypi/lightkurve
.. |pypi-downloads| image:: https://pepy.tech/badge/lightkurve
                :target: https://pepy.tech/project/lightkurve
.. |test-badge| image:: https://github.com/lightkurve/lightkurve/workflows/Lightkurve-tests/badge.svg
                 :target: https://github.com/lightkurve/lightkurve/actions?query=branch%3Amain
.. |astropy-badge| image:: https://img.shields.io/badge/powered%20by-AstroPy-orange.svg?style=flat
                   :target: http://www.astropy.org
.. |doi-badge| image:: https://zenodo.org/badge/DOI/10.5281/zenodo.1181928.svg
              :target: https://docs.lightkurve.org/about/citing.html             

**Lightkurve** is a community-developed, open-source Python package which offers a beautiful and user-friendly way
to analyze astronomical flux time series data,
in particular the pixels and lightcurves obtained by
**NASA's Kepler and TESS exoplanet missions**.

.. image:: https://raw.githubusercontent.com/lightkurve/lightkurve/main/docs/source/_static/images/lightkurve-teaser.gif

This package aims to lower the barrier for students, astronomers,
and citizen scientists interested in analyzing Kepler and TESS space telescope data.
It does this by providing **high-quality building blocks and tutorials**
which enable both hand-tailored data analyses and advanced automated pipelines.


Documentation
-------------

Read the documentation at `https://docs.lightkurve.org <https://docs.lightkurve.org>`_.


Quickstart and Installation
---------------------------

Please visit our quickstart guide at `https://docs.lightkurve.org/quickstart.html <https://docs.lightkurve.org/quickstart.html>`_. 

The easiest way to install *Lightkurve* and all of its dependencies is to use the ``pip`` command,
which is a standard part of all Python distributions.
To install *Lightkurve*, run the following command in a terminal window::

    $ python -m pip install lightkurve --upgrade

The ``--upgrade`` flag is optional, but recommended if you already
have *Lightkurve* installed and want to upgrade to the latest version.

Depending on the specific Python environment, you may need to replace ``python``
with the correct Python interpreter, e.g., ``python3``.

If you want to experiment with the latest development version of
*Lightkurve*, you can install it straight from the main branch on GitHub:

.. code-block:: bash

    $ git clone https://github.com/lightkurve/lightkurve.git
    $ cd lightkurve
    $ python -m pip install .

If you want to have a so-called editable install which enables the installed
version to immediately reflect changes made in the source tree, you can use:

.. code-block:: bash

    $ python -m pip install poetry
    $ poetry install

Please see our guide on `https://docs.lightkurve.org/development/index.html <https://docs.lightkurve.org/development/index.html>`_
for additional instructions.


Contributing
------------

We welcome community contributions!
Please read the  guidelines at `https://docs.lightkurve.org/development/contributing.html <https://docs.lightkurve.org/development/contributing.html>`_.


Citing
------

If you find Lightkurve useful in your research, please cite it and give us a GitHub star!
Please read the citation instructions at `https://docs.lightkurve.org/about/citing.html <https://docs.lightkurve.org/about/citing.html>`_.


Contact
-------
Lightkurve is an open source community project created by `the authors <AUTHORS.rst>`_.
The best way to contact us is to `open an issue <https://github.com/lightkurve/lightkurve/issues/new>`_ or to e-mail tesshelp@bigbang.gsfc.nasa.gov.
Please include a self-contained example that fully demonstrates your problem or question.
# StarCharter

<img align="right" width="500" src="example_output/orion_mini.png">

`StarCharter` is a command-line tool for producing vector-graphics charts of
the night sky in SVG, PDF and PNG formats. It can also overlay the paths of
solar system objects, such as planets and comets, across the sky if the tool
[ephemerisCompute](https://github.com/dcf21/ephemeris-compute-de430) is also
installed.

`StarCharter` was written to produce all the star charts on the website
<https://in-the-sky.org>, which is maintained by the author.

### Supported operating systems

`StarCharter` is written in C and runs in Linux, MacOS, and other Unix-like
operating systems.  The installation scripts require python3.  `StarCharter`
uses `libcairo` to produce its graphical output.

The build process requires a minimum of 4GB RAM. Note that Docker Desktop for
Mac imposes a default memory limit of 2GB, which needs to be increased to build
`StarCharter` successfully.

### License

This code is distributed under the Gnu General Public License. It is (C)
Dominic Ford 2015 - 2022.

### Set up

Before you start, `StarCharter` needs to download various data from the
internet, including star catalogues, deep sky catalogues, and an image of the
Milky Way to use to shade the background of star charts.

This can be done with the shell script `setup.sh`. The total download size will
be around 500 MB.

### Docker container

A `Dockerfile` is provided to build `StarCharter`. A `docker compose` script is
provided to build a selection of example starcharts:

```
docker compose build
docker compose run star-charter
```

This builds some example starcharts, which are written to the directory
`examples/output`. To make other star charts, open a shell within the Docker
container as follows:

```
docker run -it star-charter:v1 /bin/bash
```

## Generating a star chart

Once you have compiled the `StarCharter` code, you need to write a
configuration file to generate each star chart you want, specifying which
portion of the sky should be charted, and what labels you want on the chart.
There are some examples in the `examples` directory, and so a good starting
point is to generate one of these:

```
cd examples
../bin/starchart.bin orion.sch
```

This will generate three star charts in the `output` directory, in PNG, SVG and
PDF formats.

The file `orion.sch` reads as follows:

```
DEFAULTS
ra_central=5.5
dec_central=4.0
angular_width=29.0
mag_min=7
width=15.0
aspect=1.41421356
ra_dec_lines=1
constellation_boundaries=1
constellation_sticks=1
coords=ra_dec
projection=gnomonic
star_names=1
star_flamsteed_labels=0
constellation_names=1
plot_galaxy_map=1
plot_equator=0
plot_ecliptic=0
plot_galactic_plane=1
font_size=1.2

CHART
output_filename=output/orion.png

CHART
output_filename=output/orion.svg

CHART
output_filename=output/orion.pdf

CHART
output_filename=output/orion.eps
```

Settings are arranged in blocks which are headed by the words `DEFAULTS` or
`CHART`. Settings in a `DEFAULTS` block do not themselves produce a star chart,
but change the default settings which are applied to all subsequent charts.
Settings in a `CHART` relate to a specific chart that is to be rendered, and do
not affect any subsequent charts which may be rendered later in the same
configuration file.

The file above configures a large number of parameters to produce a star chart
of the constellation Orion, and makes these the default settings. It then
produces three identical copies of the star chart, in three different graphic
formats.

The configuration settings which are recognised are listed below under
'Configuration settings'.

## Paths of solar system objects

The `draw_ephemeris` option in a configuration file can be used to draw the
path of a solar system object across the sky.  This requires the tool
[ephemerisCompute](https://github.com/dcf21/ephemeris-compute-de430) to be installed.

The syntax is as follows:

```
draw_ephemeris = <body>,<jd_start>,<jd_end>
```

where `body` is the name of the solar system object to plot, and `jd_start` and
`jd_end` are the Julian day numbers of the beginning and end of the time period
for which the object's path should be plotted.

Recognised object names include any of the following:

* `p1`, `pmercury`, `mercury`: Mercury
* `p2`, `pvenus`, `venus`: Venus
* `p3`, `pearth`, `earth`: Earth
* `p301`, `pmoon`, `moon`: The Moon
* `p4`, `pmars`, `mars`: Mars
* `p5`, `pjupiter`, `jupiter`: Jupiter
* `p6`, `psaturn`, `saturn`: Saturn
* `p7`, `puranus`, `uranus`: Uranus
* `p8`, `pneptune`, `neptune`: Neptune
* `p9`, `ppluto`, `pluto`: Pluto
* `A<n>`: Asteroid number `n`, e.g. `A1` for Ceres, or `A4` for Vesta
* `C/1995 O1`. Comets may be referred to by their names in this format
* `1P/Halley`. Comets may be referred to by their names in this format
* `0001P`. Periodic comets may be referred to by their names in the format %4dP
* `CJ95O010`. Comets may be referred to by their Minor Planet Center designations
* `C<n>`: Comer number `n`. `n` is the line number within the file [Soft00Cmt.txt](http://www.minorplanetcenter.net/iau/Ephemerides/Comets/Soft00Cmt.txt), downloaded from the Minor Planet Center.

Note also the setting `ephemeris_autoscale`, which overrides the specified
celestial coordinates for the centre of the star chart, and the specified
angular width, and scales the star chart to automatically show the requested
ephemerides.

## Configuration settings

The following settings can be included in a `StarCharter` configuration file:

* `angular_width` - The angular width of the star chart on the sky; degrees
* `aspect` - The aspect ratio of the star chart: i.e. the ratio height/width
* `axis_label` - Boolean (0 or 1) indicating whether to write "Right ascension" and "Declination" on the vertical/horizontal axes
* `axis_ticks_value_only` - If 1, axis labels will appear as simply "5h" or "30 deg". If 0, these labels will be preceded by alpha= or delta=
* `cardinals` - Boolean (0 or 1) indicating whether to write the cardinal points around the edge of alt/az star charts
* `constellation_boundaries` - Boolean (0 or 1) indicating whether we draw constellation boundaries
* `constellation_boundary_col` - Colour to use when drawing constellation boundaries
* `constellation_highlight` - Optionally, highlight the boundary of one particular constellation, identified by a three-letter abbreviation.
* `constellation_label_col` - Colour to use when writing constellation names
* `constellation_names` - Boolean (0 or 1) indicating whether we label the names of constellations
* `constellation_stick_col` - Colour to use when drawing constellation stick figures
* `constellation_stick_design` - Select which design of constellation stick figures we should draw. Set to either 'simplified' or 'rey'. See <https://github.com/dcf21/constellation-stick-figures> for more information.
* `constellation_sticks` - Boolean (0 or 1) indicating whether we draw constellation stick figures
* `coords` - Select whether to use RA/Dec or galactic coordinates. Set to either 'ra_dec' or 'galactic'.
* `copyright_gap_2` - Spacing of the copyright text beneath the plot
* `copyright_gap` - Spacing of the copyright text beneath the plot
* `copyright` - The copyright string to write under the star chart
* `dec_central` - The declination at the centre of the plot; degrees
* `draw_ephemeris` - Definitions of ephemerides to draw
* `dso_cluster_col` - Colour to use when drawing star clusters
* `dso_galaxy_col` - Colour to use when drawing galaxies
* `dso_label_col` - Colour to use when writing the labels for deep sky objects
* `dso_label_mag_min` - Do not label stars fainter than this magnitude limit (default: unlimited)
* `dso_mag_min` - Only show NGC objects down to this faintest magnitude
* `dso_mags` - Boolean (0 or 1) indicating whether we label the magnitudes of NGC objects
* `dso_names` - Boolean (0 or 1) indicating whether we label the names of NGC objects
* `dso_nebula_col` - Colour to use when drawing nebulae
* `dso_outline_col` - Colour to use when drawing the outline of deep sky objects
* `dso_symbol_key` - Boolean (0 or 1) indicating whether we include a key to the symbols used to represent deep sky objects
* `ecliptic_col` - Colour to use when drawing a line along the ecliptic
* `ephemeris_autoscale` - Boolean (0 or 1) indicating whether to auto-scale the star chart to contain the requested ephemerides. This overrides settings for ra_central, dec_central and angular_width.
* `ephemeris_col` - Colour to use when drawing ephemerides for solar system objects
* `ephemeris_compute_path` - The path to the tool <ephemerisCompute>, used to compute paths for solar system objects. See <https://github.com/dcf21/ephemeris-compute-de430>. If this tool is installed in the same directory as StarCharter, the default value should be <../ephemerisCompute/bin/ephem.bin>.
* `equator_col` - Colour to use when drawing a line along the equator
* `font_size` - A normalisation factor to apply to the font size of all text (default 1.0)
* `galactic_plane_col` - Colour to use when drawing a line along the galactic plane
* `galaxy_col0` - The colour to use to shade the dark parts of the map of the Milky Way
* `galaxy_col` - The colour to use to shade the bright parts of the map of the Milky Way
* `galaxy_map_filename` - The binary file from which to read the shaded map of the Milky Way
* `galaxy_map_width_pixels` - The number of horizontal pixels across the shaded map of the Milky Way
* `great_circle_key` - Boolean (0 or 1) indicating whether to draw a key to the great circles under the star chart
* `grid_col` - Colour to use when drawing grid of RA/Dec lines
* `label_ecliptic` - Boolean (0 or 1) indicating whether to label the months along the ecliptic, showing the Sun's annual progress
* `label_font_size_scaling` - Scaling factor to be applied to the font size of all star and DSO labels (default 1.0)
* `language` - The language used for the constellation names. Either "english" or "french".
* `mag_alpha` - The multiplicative scaling factor to apply to the radii of stars differing in magnitude by one <mag_step>
* `mag_max` - Used to regulate the size of stars. A star of this magnitude is drawn with size mag_size_norm. Also, this is the brightest magnitude of star which is shown in the magnitude key below the chart.
* `mag_min` - The faintest magnitude of star which we draw
* `magnitude_key` - Boolean (0 or 1) indicating whether to draw a key to the magnitudes of stars under the star chart
* `mag_size_norm` - The radius of a star of magnitude <mag_max> (default 1.0)
* `mag_step` - The magnitude interval between the samples shown on the magnitude key under the chart
* `maximum_dso_count` - The maximum number of deep sky objects to draw. If this is exceeded, only the brightest objects are shown.
* `maximum_dso_label_count` - The maximum number of deep sky objects which may be labelled
* `maximum_star_count` - The maximum number of stars to draw. If this is exceeded, only the brightest stars are shown.
* `maximum_star_label_count` - The maximum number of stars which may be labelled
* `messier_only` - Boolean (0 or 1) indicating whether we plot only Messier objects, and no other deep sky objects
* `must_show_all_ephemeris_labels` - Boolean (0 or 1) indicating whether we show all ephemeris text labels, even if they collide with other text.
* `output_filename` - The target filename for the star chart. The file type (svg, png, eps or pdf) is inferred from the file extension.
* `photo_filename` - The filename of a PNG image to render behind the star chart. Leave blank to show no image.
* `plot_dso` - Boolean (0 or 1) indicating whether we plot any deep-sky objects
* `plot_ecliptic` - Boolean (0 or 1) indicating whether to draw a line along the ecliptic
* `plot_equator` - Boolean (0 or 1) indicating whether to draw a line along the equator
* `plot_galactic_plane` - Boolean (0 or 1) indicating whether to draw a line along the galactic plane
* `plot_galaxy_map` - Boolean (0 or 1) indicating whether to draw a shaded map of the Milky Way behind the star chart
* `plot_stars` - Boolean (0 or 1) indicating whether we plot any stars
* `position_angle` - The position angle of the plot - i.e. the tilt of north, counter-clockwise from up, at the centre of the plot
* `projection` - Select projection to use. Set to either flat, peters, gnomonic, sphere or alt_az
* `ra_central` - The right ascension at the centre of the plot; hours, J2000.0
* `ra_dec_lines` - Boolean (0 or 1) indicating whether we draw a grid of RA/Dec lines in background of star chart
* `star_allow_multiple_labels` - Boolean (0 or 1) indicating whether we allow multiple labels next to a single star. If false, we only include the highest-priority label for each object.
* `star_bayer_labels` - Boolean (0 or 1) indicating whether we label the Bayer numbers of stars
* `star_catalogue_numbers` - Boolean (0 or 1) indicating whether we label the catalogue numbers of stars
* `star_catalogue` - Select the star catalogue to use when showing the catalogue numbers of stars. Set to 'hipparcos', 'ybsc' or 'hd'.
* `star_col` - Colour to use when drawing stars
* `star_flamsteed_labels` - Boolean (0 or 1) indicating whether we label the Flamsteed designations of stars
* `star_label_mag_min` - Do not label stars fainter than this magnitude limit (default: unlimited)
* `star_mag_labels` - Boolean (0 or 1) indicating whether we label the magnitudes of stars
* `star_names` - Boolean (0 or 1) indicating whether we label the English names of stars
* `star_variable_labels` - Boolean (0 or 1) indicating whether we label the variable-star designations of stars, e.g. V337_Car
* `title` - The heading to write at the top of the star chart
* `width` - The width of the star chart, in cm
* `x_label_slant` - A slant to apply to all labels on the horizontal axes
* `y_label_slant` - A slant to apply to all labels on the vertical axes
* `zodiacal_only` - Boolean (0 or 1) indicating whether we plot only the zodiacal constellations

## Author

This code was developed by Dominic Ford <https://dcford.org.uk>. It is distributed under the Gnu General Public License V3.

![GW150914](https://raw.githubusercontent.com/gwastro/pycbc-logo/master/pycbc_logo_name.png)

[PyCBC](http://pycbc.org) is a software package used to explore astrophysical sources of gravitational waves.
It contains algorithms to analyze gravitational-wave data,
detect coalescing compact binaries, and make bayesian inferences from gravitational-wave data.
PyCBC was used in the [first direct detection of gravitational waves](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.116.061102) and
is used in flagship analyses of LIGO and Virgo data.

PyCBC is collaboratively developed by the community and is lead by a team of GW astronomers with the
aim to build accessible tools for gravitational-wave data analysis.

The PyCBC home page is located on github at

 * https://pycbc.org/

Documentation is automatically built from the latest master version

 * https://pycbc.org/pycbc/latest/html/

For the detailed installation instructions of PyCBC

 * https://pycbc.org/pycbc/latest/html/install.html

Want to get going using PyCBC?

 * [Try out our tutorials](https://github.com/gwastro/PyCBC-Tutorials). No software installation required and these can run entirely from the browser.

Quick Installation
```
pip install pycbc
```

To test the code on your machine
```
pip install pytest "tox<4.0.0"
tox
```

If you use any code from PyCBC in a scientific publication, then please see our [citation guidelines](http://pycbc.org/pycbc/latest/html/credit.html) for more details on how to cite pycbc algorithms and
programs.

For the citation of the ``pycbc library``,  please use a bibtex entry and DOI for the
appropriate release of the PyCBC software (or the latest available release).
A bibtex key and DOI for each release is avaliable from [Zenodo](http://zenodo.org/).

[![DOI](https://zenodo.org/badge/31596861.svg)](https://zenodo.org/badge/latestdoi/31596861) [![Build Status](https://travis-ci.org/gwastro/pycbc.svg?branch=master)](https://travis-ci.org/gwastro/pycbc)
[![PyPI version](https://badge.fury.io/py/PyCBC.svg)](https://badge.fury.io/py/PyCBC) ![PyPI - Downloads](https://img.shields.io/pypi/dm/pycbc) [![Anaconda-Server Badge](https://anaconda.org/conda-forge/pycbc/badges/version.svg)](https://anaconda.org/conda-forge/pycbc) [![Anaconda-Server Badge](https://anaconda.org/conda-forge/pycbc/badges/downloads.svg)](https://anaconda.org/conda-forge/pycbc)
[![astropy](http://img.shields.io/badge/powered%20by-AstroPy-orange.svg?style=flat)](http://www.astropy.org/)
# Astropy Tutorials

This repository contains tutorial IPython notebooks for the
[Astropy](http://astropy.org) project. These are typically longer-form, more
narrative presentations of functionality in the [Astropy core
package](https://github.com/astropy/astropy) and any [affiliated
packages](http://www.astropy.org/affiliated/index.html). The tutorials are
therefore different from the [Astropy core package
documentation](http://docs.astropy.org), which presents a more structured and
exhaustive view of the Astropy core package.


## View the tutorials rendered as HTML pages

To see the tutorials rendered as static web pages, see the [Learn Astropy
website](https://learn.astropy.org).

To execute the tutorials interactively, you can either clone this repository to
your local machine or use Binder to run the tutorials remotely, as described
below.


## Run the tutorials locally

To run the tutorials locally, you should start by cloning this repository with
`git` or downloading an archive of this repository from GitHub. You will need to
have [Jupyter notebook](http://jupyter.org/) and IPython installed and will need
to install the tutorial dependencies specified in `requirements.txt`:

    python -m pip install -r requirements.txt

To check that your environment is set up to run the tutorials, you can use the
Makefile provided in this repository with the custom `envcheck` command:

    make envcheck

If this line fails, your environment is missing packages, and you should run the
pip install line shown above.

The notebook files themselves live in the `tutorials` directory of this
repository, organized by the names of the tutorials. These can be opened with
Jupyter notebook as with any other notebook files.


## Run the tutorials on Binder

You can also get started with a remote environment to run the tutorial notebooks
in your browser using [Binder](http://mybinder.org)

[![Binder](http://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/astropy/astropy-tutorials/main?filepath=tutorials)


Contributing tutorial material
------------------------------

We are always interested in incorporating new tutorials into Learn Astropy and
the Astropy Tutorials series. We welcome tutorials covering astro-relevant topics and they do not
necessarily need to use the Astropy package in order to be hosted or indexed here.
If you have astronomy tutorials that you would like to contribute to this repository,
or if you have a separate tutorial series that you would like indexed by the
Learn Astropy website, please see the [Contributing
Guide](https://learn.astropy.org/contributing) on the Learn Astropy website for
information on how to get started.
The Solar System
================

This is a project powered by Three.js and WebGL. All objects within this project have been modeled to scale based on real astronomical data. The scene currently renders the sun, all eight planets (nine if you side with Pluto being a planet), each planet's moons, the asteriod belt and thousands of stars.

[Demo](http://sanderblue.github.io/solar-system-threejs/)

![Image](http://sanderblue.github.io/assets/screenshots/screenshot_solarsystem_saturn.png)
# Topographic Maps of Planets and Moons

[![License: GPL v3](https://img.shields.io/badge/License-GPL%20v3-blue.svg?style=flat-square)](https://www.gnu.org/licenses/gpl-3.0)
[![GitHub Follow](https://img.shields.io/github/followers/eleanorlutz.svg?style=flat-square&logo=github&label=Follow)](https://github.com/eleanorlutz)

This repository explains how to make topographic maps of planets and moons using open-source data from the [USGS](https://www.usgs.gov/centers/astrogeo-sc/data-tools), [IAU](https://planetarynames.wr.usgs.gov/), and [NASA](https://solarsystem.nasa.gov/). Software used includes `Python 3.7.1`, `GDAL 2.4.1`, `Illustrator CC 2019` and `Photoshop CC 2019`. If you have comments or suggestions for this tutorial, please let me know [on my blog](http://tabletopwhale.com/2019/06/17/a-topographic-map-of-mercury.html)! You can also buy these topographic maps for [Mars](https://www.redbubble.com/people/eleanorlutz/works/39425769), [Venus](https://www.redbubble.com/people/eleanorlutz/works/39425752), [Mercury](https://www.redbubble.com/people/eleanorlutz/works/39425767), and [the Moon](https://www.redbubble.com/people/eleanorlutz/works/39425758).

**Python dependencies:** `matplotlib` `numpy` `pandas` `os` `cartopy` `json` `osgeo` `math` `scipy` `jupyter`. Dependencies can be installed with `pip install -r requirements.txt`.

![Snapshot of final product](./readme_figures/header_image.jpg)

## Special instructions for beginners

##### If you're new to coding:

[Software Carpentry](https://software-carpentry.org/) has great tutorials for [installing Python](https://carpentries.github.io/workshop-template/) (scroll down and follow the directions in  the Bash Shell and Python sections), [getting starting with Jupyter Notebooks](http://swcarpentry.github.io/python-novice-inflammation/setup/index.html), and [beginner-friendly Python programming](http://swcarpentry.github.io/python-novice-inflammation/aio/index.html). After you've installed Python using these tutorials, you can use [Git Desktop](https://desktop.github.com/) and the instructions in [this tutorial](https://help.github.com/en/desktop/contributing-to-projects/cloning-a-repository-from-github-desktop) to download the code and data in this tutorial. For the code in this repository you will also need to install [GDAL](https://gdal.org/download.html). The [installation instructions](https://gdal.org/download.html) in the *Conda* section are probably the most relevant if you've installed Python as described above.

##### If you're new to design:

You'll need software for editing raster and vector images ([this article](https://vector-conversions.com/vectorizing/raster_vs_vector.html) explains the difference). I use [Adobe Photoshop](https://www.adobe.com/products/photoshop.html) and [Illustrator](https://www.adobe.com/products/illustrator.html), but you can also use the free open-source programs [Gimp](https://www.gimp.org/downloads/) and [Inkscape](https://inkscape.org/release/inkscape-0.92.4/). There is no perfect software that fits everyone's needs, so you'll want to understand the pros and cons for the different [raster](https://www.colorexpertsbd.com/blog/brief-comparison-photoshop-gimp) and [vector](https://logosbynick.com/inkscape-vs-illustrator-vs-coreldraw/) programs before choosing.

## Table of Contents

1. [Gathering and processing data](#data)
2. [Map design in Python](#python)
3. [Map design in Illustrator and Photoshop](#illustrator_photoshop)
4. [References](#references)
5. [License](#license)

<a name="data"/>

## Gathering and processing data

![Data layers used to design this map](./readme_figures/data_layers.jpg)

#### Digital Elevation Models
Digital Elevation Models (DEMs) are data files that provide height information. For this project I'm using the United States Geologic Survey's DEMs for [Mars](https://astrogeology.usgs.gov/search/map/Mars/Topography/HRSC_MOLA_Blend/Mars_HRSC_MOLA_BlendDEM_Global_200mp_v2), [Mercury](https://astrogeology.usgs.gov/search/map/Mercury/Topography/MESSENGER/Mercury_Messenger_USGS_DEM_Global_665m_v2), [Venus](https://astrogeology.usgs.gov/search/map/Venus/Magellan/RadarProperties/Venus_Magellan_Topography_Global_4641m), and the [Earth's Moon](https://astrogeology.usgs.gov/search/details/Moon/LRO/LOLA/Lunar_LRO_LOLA_Global_LDEM_118m_Mar2014/cub). Each pixel in these `GeoTIFF` files describes the elevation at that specific location on the planet. `GeoTIFF` files also have embedded geographic data that allows tools like `GDAL` to correctly position the elevation data onto a globe.

To run the code in this tutorial, you will need to download one of the DEM files linked above. **Note:** Many software programs can't read this kind of file, so it's normal if the downloaded DEM looks strange in Preview or other default image applications.

![DEM files for Mercury, Mars, Venus, and the Moon](./readme_figures/DEM_files.jpg)

#### Map Projections
**A Quick Introduction:** Before we get into the details of map projection transformations, here's a quick overview of what this actually means. To map a 3D object in 2D space, the surface must be transformed using a map projection. There are many different projections, and for the maps in the *Atlas of Space* series I used Eckert IV, Orthographic, and Plate Carrée projections. To visually compare these different map projections, you can use a Tissot's indicatrix - a set of circles of the same size plotted at different places on the globe. All map projections distort space, but you can see that the effects are quite different depending on the projection:

![Tissots indicatrices and map projections](./readme_figures/tissots_indicatrix.jpg)

The choice of projection depends on the purpose of the map. For example, Eckert IV preserves area measurements, so I used Eckert IV in geologic maps to show how much area on the planet was made up of each geological formation. I used an Orthographic projection for these topographic maps to visualize what planets look like from outer space. And finally I used a Plate Carrée projection for constellation charts, because the perpendicular gridlines make it easy to read coordinates (which are essential for finding stars that rise and set throughout the night).

**Changing the Map Projection of a DEM File:** In this project I wanted to use an orthographic projection to show each hemisphere of the planet (North, South, East and West). However, the original DEM data file uses a Plate Carrée projection. To create a new orthographic map, I used the command line installation of `GDAL` - short for Geospatial Data Abstraction Library.

The code below, typed into a `bash` shell, uses the original `intif` file to create a new file `outtif` centered at a latitude of `90` degrees and longitude of `0` degrees in the `ortho` (orthographic) projection.

```bash
gdalwarp -t_srs "+proj=ortho +lat_0=90 +lon_0=0" ./path_to_intif.tif ./path_to_outtif.tif
```

![Transformed orthographic DEM files](./readme_figures/orthographic.jpg)

Next I downsample the DEM by decreasing the resolution of each pixel to `1500`x`1500` meters using the `average` method. It's useful to decrease file size to lower computation times, and it's much faster to downsample at this point than to scale images later on in the process.

```bash
gdalwarp -tr 1500 1500 -r average ./path_to_intif.tif ./path_to_outtif.tif
```

#### Hillshade and Slope
Next, I used the downsampled DEM to generate hillshade and slope maps for each hemisphere of the planet.

**Hillshade maps** show the shadows cast by a hypothetical light source suspended above the map. It’s hypothetical because in the real world, a single light source would cast different shadow angles at different places on a globe. The `GDAL` hillshade calculation sets the light source angle to be the same everywhere. In this hillshade I set `z`, or the vertical exaggeration, to 20. This multiplies the real elevation values by 20 to increase visual contrast and help the hillshade show up under all of the other map elements.

```bash
gdaldem hillshade -z 20 ./path_to_intif.tif ./path_to_hillshade.tif
```
![Global hillshade](./readme_figures/hillshade.jpg)

**Slope maps** emphasize the steep parts of a map, and adds more information to the topographic hillshade (which emphasizes absolute height rather than steepness).  

```bash
gdaldem slope ./path_to_intif.tif ./path_to_slope.tif
```
![Global slope](./readme_figures/slope.jpg)

#### Automating Repetitive Tasks in Bash
Although these `GDAL` commands are fairly straightforward, some of them take a long time to run on my computer. I wanted to write a single script that would make all of my orthographic maps without having to sit and wait for each command to finish running.

The `bash` file `1_ortho_dem.sh` generates all four orthographic plots for Mars, Mercury, Venus, and the Moon, and then downsamples the data and creates hillshades and slopes for each projection. This `bash` script is a little more complex because you can specify the central longitude for the central map (for the Moon I decided to make maps of the near side and far side instead of the Eastern and Western hemispheres). I run `bash` scripts directly through my `bash` shell:

```bash
bash ./path_to/1_ortho_dem.sh
```

#### Additional notes about GDAL
It's worth noting that hillshades and slopes can also be generated in Python using the `osgeo` library. I haven't included this code because I'm less familiar with `osgeo`, but [this tutorial](https://geohackweek.github.io/raster/05-pygeotools_rainier/) may be helpful if you prefer pure Python. You can also customize hillshade and slope in many ways not mentioned here, as well as make other kinds of generated maps by [looking through the list of available GDAL commands](https://gdal.org/programs/gdaldem.html).

#### Planetary Nomenclature
The [International Astronomical Union](https://planetarynames.wr.usgs.gov/) is responsible for naming features of extraterrestrial objects. You can download a `CSV` file of all features from each planet from the IAU website (though the data for this project is already included in the `./data/planetary_features` folder).

To download nomenclature data, use the [Advanced Search Function](https://planetarynames.wr.usgs.gov/AdvancedSearch) and select `All Feature Types` from your `Target` of only an Approval Status of `Adopted by IAU`. In the `Columns to Include` section, select `Feature ID`, `Feature Name`, `Clean Feature Name`, `Target`, `Diameter`, `Center Lat/Lon`, `Feature Type`, and `Feature Type Code`. You can also include `Origin` if you'd like additional information about each feature, such as who it is named after. The `Output Format` should be `CSV`.

<a name="python"/>

## Map design in Python

Next, I made five Python plots with the contour fills, contour lines, text labels, and two types of gridlines. I often split up data for plotting so I can easily apply section-specific effects in Photoshop or Illustrator. The plotting code for all of these maps are shared in `2_plot_maps.ipynb`.

For this project I wanted all of my maps to fit nicely inside the decorative border I designed in Photoshop. To do this in Python, I use `matplotlib gridspec` to set up my figures so that each of my subplots occupy the exact pixel locations inside my decorative border.

![Different pieces of Matplotlib plotting](./readme_figures/saved_pieces.jpg)

#### Smoothing and Filling in Data
There are two steps in this map where I smoothed or cleaned the original data. First, I needed to display the data at different scales for the smaller inset maps in the corners of the design. This is similar to what we see in apps like Google Maps: as you zoom out, the map removes smaller features like streets and buildings. Earth maps also use several different coastline shapes at different zoom levels.

Because I only had one `DEM` file, I made these coarser shapes myself by applying a Gaussian filter. Smoothing map data is a legibility step that's fairly subjective. The arrow in the diagram below shows the smoothing level I picked for my own Mercury maps, but other people might pick smoother or finer detail levels.

![Example of Gaussian filtering](./readme_figures/gaussian_filtering.jpg)

I also filled in missing pixels in the original data using the information in the surrounding pixels. Again, this is a data cleaning step that other people might implement differently. The `limit` and `limit_small` parameters in the configuration file describe the maximum sized hole that can be filled in (extremely large areas of missing data are left empty).

#### Configuration Files for Multiple Designs
Although the code is more or less the same for every map, I wanted to use different colors and input files for each planet. I organized all of these parameters inside the `config.json` configuration file. Configuration files are helpful because it's very easy to add or remove new planets - I could easily make a topographic map of Earth or Pluto by adding a new entry. The parameters include topographic levels, color, input files, and the amount of smoothing to apply to each map:

```javascript
"moon":{
    "cmap": ["#e6dfcf", "#ef9f30", "#638b71", "#24293c"],
    "levels": [-10000, 10000, 1000],
    "levels_small": [-20000, 20000, 5000],
    "file_large": "A:/ATLAS_OF_SPACE/image_outputs/ortho_DEMs/moon_lat30_lon0_downsampled.tif",
    "file_small": [ "A:/ATLAS_OF_SPACE/image_outputs/ortho_DEMs/moon_lat90_lon0_downsampled.tif",
                    "A:/ATLAS_OF_SPACE/image_outputs/ortho_DEMs/moon_lat-90_lon0_downsampled.tif",
                    "A:/ATLAS_OF_SPACE/image_outputs/ortho_DEMs/moon_lat0_lon180_downsampled.tif"],
    "save_head": "A:/ATLAS_OF_SPACE/image_outputs/topography/",
    "labelfile": "./data/planetary_features/moon.csv",
    "limit": 10,
    "limit_small": 10,
    "gauss": 10,
    "gauss_small": 30,
    "ortho": [0, 30]
  }
```

#### Planet Core Diagrams
For each planet I also wanted to make a cutaway diagram showing the interior layers. But when I started to plot this data, I ran into an issue where you couldn't actually see some of the layers because they were so thin. To solve this problem, I decided to use an adjusted visualization where every layer has a minimum visible thickness (I also added a disclaimer in the key that the figures were not to scale). This code is shared in `3_plot_cores.ipynb`.

In the diagram below, the left half shows the actual thickness of each layer, and the right half shows the adjusted version. For Mercury and the Moon there's actually no difference, but the effect is much stronger for the other planets with a very thin crust or atmosphere.

![Diagram of planet core layers](./readme_figures/cores.jpg)

Each of the planet core diagrams also has a blurred image of the surface on the outside of the sphere. To make these I used the open-source stock images from [Stellarium](https://stellarium.org/), which I transformed from a Plate Carrée to an Orthographic projection in `3_plot_cores.ipynb`. I also intentionally blurred these images in Photoshop, because a more detailed surface illustration would take the focus away from the cutaway core diagram layers.

![Diagram of Stellarium core images](./readme_figures/core_surface.jpg)

#### Saving Matplotlib figures

I usually save figures as a PDF so I can edit the text and shapes in Illustrator. There are a couple standard commands I use to export Matplotlib figures so they're easy to edit:

```python
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.backends.backend_pdf as pdf

# Export text as editable text instead of shapes:
matplotlib.rcParams['pdf.fonttype'] = 42

# Preserve the vertical order of embedded images:
matplotlib.rcParams['image.composite_image'] = False

# Remove borders and ticks from subplots:
ax.axis('off')

# Remove padding and margins from the figure and all its subplots
plt.margins(0,0)
plt.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)
plt.gca().xaxis.set_major_locator(plt.NullLocator())
plt.gca().yaxis.set_major_locator(plt.NullLocator())

# Save the Matplotlib figure as a PDF file:
pp = pdf.PdfPages('./savename.pdf', keep_empty=False)
pp.savefig(fig)
pp.close()

# If I don't need to edit vector paths I save the file as a
# PNG so I can import it directly into Photoshop:
plt.savefig('./savename.png', format='png', dpi=600, pad_inches=0, transparent=True)
```

After saving the figure, the `PDF` file needs to be edited so that each object can be manipulated individually. In Illustrator,  select everything in the file and then go to `Object` --> `Clipping Mask` --> `Release`. At this point you can also delete the background and axis border objects, if you included them in the output file.

<a name="illustrator_photoshop"/>

## Map design in Illustrator and Photoshop

I export Python figures to Illustrator and Photoshop because several great design features are impossible or very time-consuming in Matplotlib. I'm linking tutorials here for the features I use most often - [font alternates](https://helpx.adobe.com/illustrator/using/special-characters.html) and [ligatures](https://helpx.adobe.com/illustrator/using/special-characters.html#use_ligatures_and_contextual_alternates), [custom brushes](https://helpx.adobe.com/illustrator/using/brushes.html), [layering effects](https://helpx.adobe.com/photoshop/using/layer-effects-styles.html), [blur effects](https://helpx.adobe.com/photoshop/using/blur-gallery.html), [gradients along a path](http://blog.gilbertconsulting.com/2017/06/using-gradients-on-strokes-in.html), [variable width paths](https://iamsteve.me/blog/entry/creating-custom-stroke-width-profiles-in-illustrator), [type on a path](https://helpx.adobe.com/illustrator/using/creating-type-path.html), and [selecting objects by characteristic](https://helpx.adobe.com/illustrator/using/selecting-objects.html#select_objects_by_characteristic).

![Features not easily available in Python](./readme_figures/illustrator_photoshop_effects.png)

#### Layering in Photoshop

I've included a small section of the map in the `figures` folder as the Photoshop file `topography_sample.psd`. The file is small enough to upload online, but since it still has the original layers you should be able to use it as a reference for layering effects.

![Layers of the map Photoshop file](./readme_figures/photoshop_sample.jpg)

#### Text Annotation in Illustrator
I decided to annotate this map using text labels that followed the spherical contour lines of the planet. First I used Python to plot a series of latitude lines up and down the globe. I also made a Python output file that placed each text annotation next to a scatterpoint at the center of the feature. Finally I opened these files in Illustrator and manually combined each label with a nearby latitude line:
1. Use the `Type on a Path` tool to copy and paste the text for each object onto an appropriate latitude vector.
2. Use `Character` -> `Set the baseline shift` to center the text vertically to the desired location.

![Text annotation in Illustrator](./readme_figures/typography.jpg)

#### Shadows Underneath Text Labels in Photoshop

To create a shadow effect around the text labels, first save the text as a transparent `PNG` file and import it into Photoshop. Duplicate this annotation layer and go to `Filter` --> `Blur Gallery` --> `Field Blur`. For shadow text I usually create two blur layers set to 20% opacity - one with a `Blur` of 4px and the other 10px.

#### Color and Font

I wanted the maps in this series to look cohesive, so I made a palette of ~70 different colors and picked from these choices in every map. I also used the same two fonts ([Redflowers](https://creativemarket.com/TypeandStudio/923689-RedFlower-Typeface) and [Moon](https://harvatt.house/store/moon-font)) in all maps. You're welcome to use the color palette and font styling if you'd like.

![Color palette used in all maps](./readme_figures/colors.jpg)

![Fonts used in all maps](./readme_figures/fonts.jpg)

#### Designing a color scheme

To develop this set of colors, I started the project by designing 14 different color schemes. My initial idea was to have a unique color palette for every planet, but in the end I used the same collection of colors throughout all of the projects to make the maps look more cohesive.

![The initial color palettes designed for this project](./readme_figures/color_palettes_initial.jpg)

Each color palette is shown in several different ways, because I wanted to design versatile color schemes that could work as discrete elements, or as pieces of a complex pattern, or as a gradient in topographic maps. I updated these three visualizations while designing to make sure each color scheme would work for each application.

#### Decorative illustrations in Photoshop

For this project I wanted to combine large datasets with the hand-crafted design style of artists like William Morris or Alphonse Mucha. To organize my thoughts I collected a big folder of inspiration images from sources like the [New York Public Library Digital Database](https://www.nypl.org/):

![Inspiration images](./readme_figures/inspiration.jpg)

When I started this project I initially wanted to design different border decorations for every topic. I sketched a collection of 18 different repeated patterns, each meant to go alongside a unique astronomy theme like planets, galaxies, space missions, or satellites.

![Pencil sketches of border illustrations](./readme_figures/borders.jpg)

But as the project continued I realized there was so much data that the detailed borders made the maps look too cluttered. In the end I removed all of the borders and designed just one scrollwork illustration to wrap around rounded map projections. In these round maps I thought the shift from detailed map to blank paper was a bit too abrupt, so this was a good compromise between data-heavy and illustrative design styles.

![Scrollwork design process](./readme_figures/scrollwork_design.jpg)

For this scrollwork design I started with a pencil sketch, and tried a couple different iterations of leafy scrolls before finally picking a less botanically inspired design. When I paint decorations like these in Photoshop, I begin each design as a solid white shape and then gradually break away pieces into detailed chunks. Next, I brush away pieces of each section with the brush eraser tool until the pieces look like a fully-shaded monochrome design. I wait to add color until the very last step, where I use many different colors and overlay layers for a richer effect.

I've included two different examples of these painted Photoshop illustrations in the `figures` folder as `scrollwork_sample.psd` and `decorations_sample.psd`. These files still have the original layers, so you should be able to use it as a reference for layering, painting, and color effects.

![Layers of the scrollwork Photoshop file](./readme_figures/scrollwork_sample.jpg)

![Layers of the decoration Photoshop file](./readme_figures/decoration_sample.jpg)

<a name="references"/>

## References
- [Astronomy](https://openstax.org/details/astronomy). Andrew Fraknoi, David Morrison, Sidney C. Wolff et al. OpenStax 2016.
- [Gazetteer of Planetary Nomenclature](https://planetarynames.wr.usgs.gov/). International Astronomical Union (IAU) Working Group for Planetary System Nomenclature (WGPSN) 2019.
- [LRO LOLA Elevation Model 118m (LDEM GDR)](https://astrogeology.usgs.gov/search/details/Moon/LRO/LOLA/Lunar_LRO_LOLA_Global_LDEM_118m_Mar2014/cub). NASA PDS and Derived Products Annex. LOLA Science Team 2018.
- [Mars HRSC MOLA Blended DEM Global 200m v2](https://astrogeology.usgs.gov/search/map/Mars/Topography/HRSC_MOLA_Blend/Mars_HRSC_MOLA_BlendDEM_Global_200mp_v2). NASA PDS and Derived Products Annex. USGS Astrogeology Science Center 2018.
- [Magellan Global Topography 4641m](https://astrogeology.usgs.gov/search/map/Venus/Magellan/RadarProperties/Venus_Magellan_Topography_Global_4641m). NASA PDS and Derived Products Annex. Magellan Team 2014.
- [Mercury MESSENGER Global DEM 665m (64ppd) v2 Oct. 2016](https://astrogeology.usgs.gov/search/map/Mercury/Topography/MESSENGER/Mercury_Messenger_USGS_DEM_Global_665m_v2). NASA PDS and Derived Products Annex. USGS Astrogeology Science Center 2016.
- [NASA Science Solar System Exploration](https://solarsystem.nasa.gov/). 2019.
- [Stellarium](https://stellarium.org/) 2019 version 0.19.0.
- **Fonts:** [Moon](https://harvatt.house/store/moon-font) by Jack Harvatt and [RedFlower](https://creativemarket.com/TypeandStudio/923689-RedFlower-Typeface) by Type & Studio.
- **Advice:** Thank you to Oliver Fraser, Henrik Hargitai, Jennifer Hsiao, Chloe Pursey, and Leah Willey for their helpful advice in making this map.

<a name="license"/>

## License

**Code:** All of the code in this repository is shared under the [GPL-3.0 license](https://www.gnu.org/licenses/gpl-3.0).

**Data:** The data in this repository belongs to the original authors of the data. Please use the references section to look up the original version. In cases where I edited or revised the data, I impose no additional restrictions to the original license. Any data files I created myself are shared under the [ODC Open Database License](https://opendatacommons.org/licenses/odbl/summary/).

**Artwork:** The artwork included in this repository are shared under a [Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License](https://creativecommons.org/licenses/by-nc-nd/4.0/).
[![Build status](https://github.com/gnudatalanguage/gdl/workflows/build/badge.svg)](https://github.com/gnudatalanguage/gdl/actions)
[![Coverage Status](https://img.shields.io/codecov/c/github/gnudatalanguage/gdl/master.svg)](https://codecov.io/github/gnudatalanguage/gdl?branch=master)
[![License: GPL v2](https://img.shields.io/badge/License-GPL%20v2-blue.svg)](https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html)
[![DOI](https://joss.theoj.org/papers/10.21105/joss.04633/status.svg)](https://doi.org/10.21105/joss.04633)

GDL - GNU Data Language
=======================

GDL is a free/libre/open source incremental compiler compatible with IDL (Interactive Data Language) and to some extent with PV-WAVE. 
Together with its library routines it serves as a tool for data analysis and visualization in such disciplines 
as astronomy, geosciences and medical imaging. 
GDL development had been started by **Marc Schellens** back in early noughties and has since continued 
with help of a team of maintainers, developers, packagers and thanks to feedback from users.

IDL is a registered trademark of [Harris Geospatial Solutions](https://www.harrisgeospatial.com).
PV-WAVE is a product of [Rogue Wave Software](https://www.roguewave.com).

Overview
--------

GDL is a domain-specific programming language and a data analysis environment.
As a language, it is dynamically-typed, array-oriented, vectorised and has 
object-oriented programming capabilities. 
GDL library routines handle numerical calculations, data visualisation, signal/image processing, 
interaction with host OS and data input/output. 
GDL supports several data formats such as netCDF, HDF4, HDF5, GRIB, PNG, TIFF, DICOM, etc. 
Graphical output is handled by X11, PostScript, SVG or z-buffer terminals, the last one allowing 
output graphics (plots) to be saved in a variety of raster graphics formats. 
GDL features integrated debugging facilities. 
The built-in widget functionality enables development of GUI-based software.
GDL has also a Python bridge (Python code can be called from GDL; GDL can be compiled as a Python module). 
Development and maintenance of GDL is carried out targeting Linux, BSD, OSX and Windows (MinGW, Cygwin).

GDL is invoked just by typing `gdl` but see `gdl -h` as it has a number of commandline options.
GDL may be known as `gnudl` or `gnudatalanguage` on some operating systems.

Other open-source numerical data analysis tools similar to GDL include
[SciPy](http://www.scipy.org/),
[GNU Octave](http://www.gnu.org/software/octave/),
[Scilab](http://www.scilab.org/),
[PDL](http://pdl.perl.org/),
[NCL](http://www.ncl.ucar.edu/),
[R](http://www.r-project.org/),
[Yorick](http://yorick.sourceforge.net/).

Getting GDL
-------------------------------------

See:
- [Cloning GDL](https://github.com/gnudatalanguage/gdl/wiki/Cloning-gnudatalanguage-gdl) (new!)
- [GDL on Linux](https://github.com/gnudatalanguage/gdl/wiki/GDL-on-Linux)
- [GDL on OSX](https://github.com/gnudatalanguage/gdl/wiki/GDL-on-OSX)
- [GDL on BSD](https://github.com/gnudatalanguage/gdl/wiki/GDL-on-BSD)
- [GDL on Windows](https://github.com/gnudatalanguage/gdl/wiki/GDL-on-Windows)

Alerts
-------------------------------------

Check the [WIKI](https://github.com/gnudatalanguage/gdl/wiki/Known-issues) for (transient) alerts.

Dependencies 
-------------------------------------

Packaged versions of GDL are available for several Linux distributions, BSD and Mac OS X. 
Please note that several features of GDL depend on compile-time configuration, and might not 
be available in pre-built or pre-configured packages. 

GDL has numerous dependencies, most of the optional but highly recommended if you want it to be areally useful tool.
- [readline](https://tiswww.cwru.edu/php/chet/readline/rltop.html) mandatory. For easy command line editing, recalling, history. 
- [\[n\]curses](https://www.gnu.org/software/ncurses/) mandatory. Terminal management.
- [zlib](https://zlib.net/) mandatory. compressed file access.
- [GSL](https://www.gnu.org/software/gsl/) mandatory, for many math functions.
- [OpenMP](http://www.openmp.org/) optional, but speed will suffer if not present
- [Magick++](https://imagemagick.org/) / [GraphicsMagick](http://graphicsmagick.org/) optional, but don't you want to read/write many image formats?
- [wxWidgets](https://www.wxwidgets.org/) mandatory unless you do not want graphic outputs and widgets?
- [Xlib/X11](https://sourceforge.net/projects/libx11/) not used unless you explictly ask for it (replaced by wxWidgets for sake of compatibility on Windows, linux and MacOSX. 
- [netCDF](https://www.unidata.ucar.edu/software/netcdf/) optional, but useful for reading this kind of data.
- [HDF4](https://support.hdfgroup.org/products/hdf4/)  optional, but useful for reading this kind of data.
- [HDF5](https://support.hdfgroup.org/HDF5/)   optional, but useful for reading this kind of data.
- [FFTW](http://www.fftw.org/) optional, but don't you need a fast fft at times?
- [PROJ](http://proj.org/) optional but forget about mapping capabilities if absent.
- [Shapelib](http://shapelib.maptools.org/) optional but forget about mapping capabilities if absent.
- [Expat](https://libexpat.github.io/) optional but helps implement IDLffXMLSAX parser objects. 
- [MPI](https://en.wikipedia.org/wiki/Message_Passing_Interface) optional but provides clustering facilities.
- [Python](https://www.python.org/)/[NumPy](http://www.numpy.org/) optional but add python bridge and jupyter notebook.
- [udunits](https://www.unidata.ucar.edu/software/udunits/) optional, units conversion
- [Eigen](https://eigen.tuxfamily.org/) optional but provides inordinate speed enhancements...
- [ecCodes](https://confluence.ecmwf.int/display/ECC/ecCodes+Home) optional, for GRIB support.
- [GLPK](https://www.gnu.org/software/glpk/) optional, provides the SIMPLEX command.

Besides, for optimal use (speed mainly), GDL incorporates slightly edited code of
- [dSFMT](http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/SFMT) as our parallel random Generator.
- [delaunator](https://github.com/mapbox/delaunator) as our new hyperfast triangulation.
- [ANTLR3](https://www.antlr3.org/) as interpretor.
- [Median Filtering (S. Perreault)](http://nomis80.org/ctmf.html )
- [Median Filtering (J. Suomela)](http://users.ics.aalto.fi/suomela)
- [Radix Sorting](https://github.com/Pierre-Terdiman/RadixRedux) (we have written all variants up to doubles).
- [whereami](https://github.com/gpakosz/whereami) 

Build-time dependencies
-----------------------

Build and test automation is carried out using [CMake](http://cmake.org/).

GDL interpreter has been developed using [ANTLR v2](http://www.antlr2.org) but unless you want 
to change the grammar (\*.g files) you don't need ANTLR. 
All relevant ANTLR files are included in the source tree.

Support, feedback and contributions
-----------------------------------

Your comments are welcome! Let us know what you use GDL for. Or if you don't, why not. 
Which functionality are you missing/would appreciate most for coming versions. 
Please use the github issue-tracking system to report 
bugs, complaints, suggestions and comments.

Code enhancements in the form of pull requests are very welcome!
Note that contributions can be made in C++, IDL/GDL or Python, as well as
by providing enhancements and extensions of the README files, diagnostic messages, etc.

Among the major challenges GDL development is facing currently, there are:
- [enhancing test coverage](https://codecov.io/github/gnudatalanguage/gdl?branch=master) by writing test programs in GDL
- streamlining development and maintenance of GDL reference docs and examples (using the [Jupyter kernel](https://github.com/gnudatalanguage/idl_kernel)?)
- bringing in into the team the needed know-how to address the [backlog of ANTLR-related issues](https://github.com/gnudatalanguage/gdl/labels/antlr)
- increasing presence within and interoperability with the Python ecosystem, including adding support for Python 3 (calling GDL from Python 2 and calling Python 2 from GDL is already implemented!)

Help welcome!

Information resources
---------------------
GDL does not maintain a proper documentation: as GDL is aimed as a drop-in replacement for IDL,
resources for IDL constitute the valuable sources of information for GDL users as well. GDL MUST behave (at least) as IDL, and any discrepancy should be reported by opening an issue.
Conversely, the GDL issues and discussion forum on GitHub are not the good place for beginners to ask for advice on how to use IDL (or GDL). Use the forum below.
IDL freely available resources include:
- the [official IDL documentation](https://www.harrisgeospatial.com/docs/)
- the [idl-pvwave Google Group](https://groups.google.com/forum/#!forum/idl-pvwave)
- the [comp.lang.idl-pvwave usenet group archives](http://www.idlcoyote.com/comp.lang.idl-pvwave/) (dating back to 1991!)
- Wikipedia article on [IDL](https://en.wikipedia.org/wiki/IDL_\(programming_language\)) and references therein
- websites of IDL gurus including [David Fanning](http://www.idlcoyote.com/) and [Michael Galloy](http://michaelgalloy.com/)
- numerous [tutorials and lecture notes](https://www.google.com/search?q=interactive+data+language) introducing IDL
- old, used, but still very valid IDL booklets can be found in various libraries, second-hand bookstores etc.

There are several open source packages compatible or interoperable with GDL, including:
- the [MPFIT](https://pages.physics.wisc.edu/~craigm/idl/cmpfit.html) curve fitting library written in IDL (also available as a [Debian package](https://packages.debian.org/gdl-mpfit))
- the [IDL Astronomy User's Library](https://idlastro.gsfc.nasa.gov/) written in IDL (also available as a [Debian package](https://packages.debian.org/gdl-idlastro))
- the [Coyote](https://www.idlcoyote.com) library of IDL-written utilities (also available as a [Debian package](https://packages.debian.org/gdl-coyote))
- the [TeXtoIDL](http://physics.mnstate.edu/craig/textoidl/) package 
- the [gdlde](https://github.com/gnudatalanguage/gdlde) IDE
- the [IDL/GDL Jupyter kernel](https://github.com/gnudatalanguage/idl_kernel)
- the [IDLWAVE Emacs mode](https://www.gnu.org/software/emacs/manual/html_mono/idlwave.html)
- IDL [syntax highlighting module for Vim](https://github.com/vim/vim/blob/master/runtime/syntax/idlang.vim)
- the [SingleCompile extension for Vim](https://github.com/vim-scripts/SingleCompile)

Alain Coulais maintains the [GDL-announces mailing list](https://sympa.obspm.fr/wws/info/gdl-announces).

There have been quite some [mentions of GDL in scientific literature](https://scholar.google.com/scholar?q="gnu+data+language") 
which also provide example use cases.
The Coulais et al. papers from the ADASS conferences are the best way to cite GDL as of now.

Acknowledgements
----------------

GDL development had been carried out at [SourceForge](http://sourceforge.net/) in years 2003-2018 - thank you!
# ESCAPE data science summer school 2021

[![SWH](https://archive.softwareheritage.org/badge/origin/https://github.com/escape2020/school2021/)](https://archive.softwareheritage.org/browse/origin/?origin_url=https://github.com/escape2020/school2021)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.5093909.svg)](https://doi.org/10.5281/zenodo.5093909)

All information on the school may be found on the main page:     
https://indico.in2p3.fr/event/20306/

## School Program:

The school is devoted to project development for astrophysics, astroparticle physics & particle physics.    
The aim of the school is to provide theoretical and hands-on training on Data Science and Python development (coding environment and good code practices, version control and collaborative development, Python packaging, scientific libraries for data science and analysis and machine learning).

The lectures content may be found here:
https://escape2020.github.io/school2021/

## Setup

![env workflow](https://github.com/escape2020/school2021/actions/workflows/python-package-conda.yml/badge.svg)


### Install anaconda

[Go to anaconda](https://www.anaconda.com/products/individual) and follow install instructions for your OS.

If you had already installed anaconda in the past, you might want to update it:
```
conda update -n base --all
```

### Install Git

In case you don't have Git installed (try to execute `git` in your terminal to
check), you should install it first.

#### Linux
Use your distribution's package manager to install the `git` package. E.g. on Ubuntu:

```
$ sudo apt-get update
$ sudo apt-get install git
```

#### macOS

Install the XCode Command Line Tools to get git by running this command in a terminal:
```
$ xcode-select --install
```

#### Windows
[go to git-scm.com](http://www.git-scm.com/download), download the windows installer and follow the installation procedure.

### clone the repository

Open a terminal and go to your working directory

```
git clone --recursive https://github.com/escape2020/school2021.git
```

The `--recursive` is needed because we use submodules for the LaTeX slides and
the web page. You can leave it out in case you don't want to build the slides or web page.

If you cloned without recursive and need the submodules, run
```
cd school2021
git submodule update --init --recursive
```

### Setup the conda environment

We recommend the use of [mamba](https://github.com/mamba-org/mamba) to solve environment dependencies.    
However, you may use only conda (just replace `mamba` commands with `conda`).

```
cd school2021
conda install mamba -n base -c conda-forge
mamba env create -f environment.yml
conda activate eschool2021
```

If you have already created the `eschool2021` env previously, you can update it using:

```
conda activate eschool2021
mamba env update -f environment.yml
```


# binder

You may run the content of this repository on [mybinder service](https://mybinder.readthedocs.io/en/latest/).
This should be used rather for test purposes, if you are participating to the school, you should install the virtual environment as explained above and run courses and exercises for yourself.

[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/escape2020/school2021.git/HEAD)

---

# Install Docker
Some lectures will require the usage of [containers](https://www.docker.com/resources/what-container) to exemplify big data processing and software reproducibility.

*Do not worry, like with Git, you will get an introduction and hands-on sessions on containers during the school.*

[Docker documentation](https://docs.docker.com/engine/install/) is great. So, please use this **[link](https://docs.docker.com/engine/install/)**, find the Docker Desktop app that matches your Operative System, download and installs it.

**Important** For Windows users, it is possible that you will need to enable the virtualization in your machine (it comes disabled by default by some vendors). However, this is **highly** vendor/hardware-dependent, making it impractical to list a series of instructions.

For that reason, the best option is to Google ```enable virtualization in windows X``` where ```X``` is your Windows OS version. And/or search for ```enable virtualization in YZ``` where ```YZ``` is your machine brand/model.

---

# Cite as

Thomas Vuillaume, Maximilian Nöthe, Julien Peloton, Axel Donath, Arturo Sanchez Pineda, Eduardo Rodrigues, Enrique Garcia, Karl Kosack, Tamas Gal, Benson Muite, Alberto Iess, Martino Sorbaro, Claudia Beleites, Jutta Schnabel, & Rachael Ainsworth. (2021, July 12). ESCAPE Data Science Summer School 2021. Zenodo. https://doi.org/10.5281/zenodo.5093909



---

| <img src="https://projectescape.eu/sites/default/files/logo-Escape_0.png" alt="escape-logo" width="200"/> | <img src="https://projectescape.eu/sites/all/themes/escape/images/eu-flag.png" alt="eu-flag" width="200"/> | _This project has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No 824064 (ESCAPE, the European Science Cluster of Astronomy & Particle Physics ESFRI Research Infrastructures)._ |
| --- | --- | --- |
# Astroberry Server
Astroberry Server is a ready to use system for Raspberry Pi for controlling all your astronomy equipment.
It handles all astronomy equipment supported by INDI server.

Visit [www.astroberry.io](https://www.astroberry.io) for details and system image.

Visit [Facebook profile](https://www.facebook.com/astroberryserver) to meet other users.

Visit [YouTube channel](https://www.youtube.com/channel/UCQfeJZsRZQrm7O1Gl8yAt5A) for featured videos.

Visit [INDI forum](https://indilib.org/forum/astroberry.html) to share your experience.

![alt img2](https://raw.githubusercontent.com/rkaczorek/astroberry-server/master/files/sneakpreview.jpg)


The system features:
- Support for Raspberry Pi 3 and 4, Pi Zero and... probably any other Raspberry Pi version released so far
- Raspberry Pi OS Desktop
- APT repository for Raspberry Pi OS (yes, now any Raspberry Pi OS user can install Astroberry Server with 'apt install')
- Web interface featuring GPS Panel and Astro Panel (celestial almanac for your localization)
- Astroberry Wireless Hotspot allowing to access the system directly i.e. without external wireless network eg. in the field
- Remote desktop accessible over VNC at astroberry.local:5900 or a web browser at http://astroberry.local/desktop
- INDI framework with all available device drivers
- KStars planetarium software and Ekos with all available device drivers plus custom astroberry drivers
- SkyChart / Cartes du Ciel planetarium program (only in precooked image)
- Hallo Northern SKY planetarium program (only in precooked image)
- CCDciel capture software (only in precooked image)
- Astrometry for field solving
- ASTAP, the Astrometric STAcking Program (only in precooked image)
- PHD2 for autoguiding
- Gnome Predict for satellite tracking
- oaCapture for planetary imaging
- FireCapture for planetary imaging
- SER Player for watching captured video streams (only in precooked image)
- Astroberry DIY drivers for focuser and relay board
- Astroberry PiFace drivers for focuser and relay board
- Astroberry Motor HAT for focuser based on Adafruit Motor HAT
- Virtual GPS for users who do not have GPS device
- File sharing server allowing for network access to captured images
- Support for raspi-config (console) and rc_gui (graphical UI) for easy configuration of Raspberry Pi options

# How to start?
Starting from version 2.0.0 you can install Astroberry Server using two modes:

Download the image file from https://www.astroberry.io/distro/

Verify SHA256 checksums of downloaded image in [SHA256SUMS](https://github.com/rkaczorek/astroberry-server/blob/master/SHA256SUMS) to ensure that it is authentic and not corrupted.

Unpack the image file and flash your microSD card (minimum 16GB required) using [etcher.io](https://etcher.io/) or running the below commands in your terminal:
```
unzip astroberry-server_2.0.4.img.zip
sudo dd if=astroberry-server_2.0.4.img of=/dev/sdX bs=8M status=progress
```
Note 1: **Replace sdX with your microSD card identifier**. Make sure it is correct before running the above command!

After flashing your microSD card, boot your Raspberry Pi and enjoy! It is recommended to update your system after first boot. Run 'sudo apt update && sudo apt upgrade' to keep your system up to date.

OR

Download official [Raspberry Pi OS with desktop](https://www.raspberrypi.org/downloads/raspberry-pi-os/) image and flash your microSD card with it.
After the first boot, connect your Raspberry Pi to a screen, setup your system with the first boot wizard and run the following commands in your terminal:
```
wget -O - https://www.astroberry.io/repo/key | sudo apt-key add -
sudo su -c "echo 'deb https://www.astroberry.io/repo/ buster main' > /etc/apt/sources.list.d/astroberry.list"
sudo apt update
sudo apt upgrade
sudo apt install astroberry-server-full 
```
Note: You should not run this procedure over network (i.e. ssh) as the network connection will be reset during installation procedure.

# How to use it?
It's as simple as this:
- Start your Raspberry Pi with the flashed microSD card.
- Connect to an Astroberry Wireless Hotspot (default password is astroberry) 
- Point your browser to http://astroberry.local or http://IP_ADDRESS
- Click Connect button to access Astroberry Server
- Connect to Astroberry desktop (default password is astroberry)

Note 1: If you connect via Hotspot default IP_ADDRESS is 10.42.0.1, if you connect via wire or your home wireless network, IP_ADDRESS will be assigned by your router/access point.

Note 2: Astroberry Server is accessible via insecure at http://astroberry.local or http://IP_ADDRESS or
secure https://astroberry.local or https://IP_ADDRESS. If you use the latter you need to trust provided certificate or install your own. Otherwise your browser will warn you of security risk.

Note 3: If your display cannot handle FullHD resolution (1920x1080) you need to either connect via web browser and set Local in sliding menu Settings / Scaling OR you need to change the screen resolution by running raspi-config in terminal or Raspberry Pi Configuration from Prefferences menu.
      
# How to upgrade?
Starting from version 2.0.0 you can upgrade all system components using regular system upgrade using apt, apt-get, aptitude or Software Updater. If you use terminal just run:
```
sudo apt update
sudo apt upgrade
```
There is no need to reflash your microSD card with the latest image file to upgrade the system anymore!

# How to reconfigure it?
You can use it as any Raspberry Pi OS system, however there are some mission critical packages installed for you. Don't uninstall them if you want to
keep your Astroberry Server in good shape. These are:
- astroberry-server-full
- astroberry-server-sysmod
- astroberry-server-wui
- astroberry-server-artwork

# What is default username and password?
It's (almost) always **astroberry**:
- For SSH access run: ssh astroberry@astroberry.local and use 'astroberry' for password
- For VNC access connect to astroberry.local:5900 and use astroberry for username and password
- For secure browser access use https://astroberry.local/ or https://IP_ADDRESS then click Connect button and use 'astroberry' for password
- For insecure browser access use http://astroberry.local/ or http://IP_ADDRESS then click Connect button and use 'astrober' for password (up to 8 characters)

# Installing your own certificates
Using secure connection requires a security certificate installed on your Astroberry Server. Basic certificate is provided with the system.
However, you need to trust this certificate at the first conenction to use it! Due to security constraints of modern browsers default certificate
configuration might not work for you. In such a case just use unencrypted connection or install commercial certificates.
To do this you need to get your certificate issued by a public certification authority recognized by your browser.
As soon as you get your own certificate you can install it by replacing the content of the file /opt/noVNC/server.pem. To activate your changes run:
```
sudo systemctl restart novnc.service
sudo systemctl restart nginx.service
```

# Where is the source code of the system?
The core of the system is based on [Raspberry Pi OS with desktop](https://www.raspberrypi.org/downloads/raspberry-pi-os/) and is maintained by Raspberry Foundation. The core is is enriched with bunch of tools and configurationscoming from the following subprojects:

- [astroberry-server-wui](https://github.com/rkaczorek/astroberry-server-wui)
- [astroberry-server-artwork](https://github.com/rkaczorek/astroberry-server-artwork)
- [astroberry-server-sysmod](https://github.com/rkaczorek/astroberry-server-sysmod)
- [astroberry-server-wiz](https://github.com/rkaczorek/astroberry-server-wiz)
- [astroberry-server-hotspot](https://github.com/rkaczorek/astroberry-server-hotspot)
- [astroberry-server-full](https://github.com/rkaczorek/astroberry-server-full)

Plus it is enhanced by these projects:
- [astroberry-diy](https://github.com/rkaczorek/astroberry-diy)
- [astroberry-amh](https://github.com/rkaczorek/astroberry-amh)
- [astroberry-piface](https://github.com/rkaczorek/astroberry-piface)
- [virtualgps](https://github.com/rkaczorek/virtualgps)
- [gpspanel](https://github.com/rkaczorek/gpspanel)
- [astropanel](https://github.com/rkaczorek/astropanel)
- [indi-mqtt](https://github.com/rkaczorek/indi-mqtt)

# FAQ
**Q: How can I update the system?**

A: You can upgrade all system components using regular system upgrade using apt, apt-get, aptitude or Software Updater.

**Q: The image is too large for my microSD card**

A: If the image appears to be too big shrink it according to [this example](https://softwarebakery.com//shrinking-images-on-linux)

**Q: How to connect to my wireless home network?**

A: Wireless connection is predefined for you. Just edit it and change network name and password.
   - Right-click wireless icon on the taskbar
   - Select Edit connections
   - Double-click Wireless connection
   - Enter your network name in SSID field
   - Go to Wi-Fi Security tab
   - Enter your network password in Password field
   - Reboot

**Q: I cannot login to astroberry HotSpot**

A: Note that default keyboard layout used in the image is [QUERTY](https://en.wikipedia.org/wiki/QWERTY). If you use other keyboard layout the password you type in might be different than you think e.g. for French keyboard it may become astroberrz (instead astroberry). Change your keyboard layout using raspi-config or gui_rc to aligh system configuration and your keyboard.

**Q: How can I change my regional settings or add support for my language?**

A: The easiest way is to run raspi-config (console) and rc_gui (graphical UI). The latter is accessible in Menu / Preferences / Raspberry Pi Configuration

**Q: Screen resolution does not match my display. How can I fix it?**

A: If your display cannot handle FullHD resolution (1920x1080) you need to either connect via web browser and set Local in sliding menu Settings / Scaling OR you need to change the system resolution by running raspi-config in terminal or Raspberry Pi Configuration from Prefferences menu.

**Q: What is the source of location data in GPS Panel and Astro Panel accessible in sliding panel (when connected with web browser)?**

A: The panels use GPS readings for your location. If you don't have GPS the panel uses virtualgps provided with Astroberry Server. You can set your static location by editing /etc/location.conf file or using Preferences/Geographic Location menu. After the change reboot or restart virtual GPS by running: sudo systemctl restart virtualgps.service

**Q: How can I login to default pi user account?**

A: Pi user account is disabled for security reasons. You can reenable it anytime by running: sudo passwd -u pi

# Issues
File any issues on https://github.com/rkaczorek/astroberry-server

<h1>Update 2</h1>
 Updated documentation for using Tensorflow-directml on windows for broad support on any modern gpu with sufficient memory.

<hr>
<h1>Update</h1>

Pushed a new implementation os starnet in TF2.x. The whole implementation is in one file *starnet_v1_TF2.py*.

I also created a few Jupyter notebooks for ease of use:

1. starnet_v1_TF2_transform.ipynb - loads and transforms an image.
2. starnet_v1_TF2.ipynb - more detailed example that loads a model and shows how to train it (really simple as well I think).

Weights for the new model can be found <a href="https://www.dropbox.com/s/lcgn5gvnxpo27s5/starnet_weights2.zip?dl=0">here</a>.

<hr>

**StarNet** is a neural network that can remove stars from images in one simple step leaving only background.

More technically it is a convolutional residual net with encoder-decoder architecture and with L1, Adversarial and Perceptual losses.

**Small example:**

<div align="center">
  <img src="https://github.com/nekitmm/starnet/blob/master/for_git/1.jpg"><br><br>
</div>

<center><h1>Intro</h1></center>

Star removal using classical methods is a very tricky and painful multi-step procedure, which is hard to master
and hard to get nice results from, especially in case of images busy with stars.

This neural net will remove most of stars from input image in one step, leaving only really huge ones, and leaving (well, hopefully)
intact all other small bright things whose shape is significantly different from that of a typical star, like small spiral
galaxies, fine details in nebulosity, HH objects, etc.

It is intended to be used by astrophotographers. Primary use is for background nebulosity enhancement in rich star fields,
but it can also help in creation of nice starless image.

<center><h1>Literature</h1></center>

This code is partially based on pix2pix code and ideas from pix2pix paper.

pix2pix code: https://github.com/phillipi/pix2pix

pix2pix paper: <a href="https://arxiv.org/pdf/1611.07004v1.pdf">Image-to-Image Translation with Conditional Adversarial Networks</a>

Udea of using Perceptual Adversarial losses is from this paper as well as some other ideas:

<a href="https://arxiv.org/abs/1706.09138">Perceptual Adversarial Networks for Image-to-Image Transformation</a>

Other papers I took ideas from or found useful during development:

<a href="https://arxiv.org/abs/1701.05957">Image De-raining Using a Conditional Generative Adversarial Network</a>

<a href="https://arxiv.org/abs/1606.08921">Image Restoration Using Convolutional Auto-encoders with Symmetric Skip Connections</a>

<a href="http://www.columbia.edu/~jwp2128/Papers/FuHuangetal2017.pdf">Removing rain from single images via a deep detail network</a>

<center><h1>Usage</h1></center>

Its primary purpose is to partially replace initial steps of star removal in tutorials, like one by Gerald Wechselberger,
aiming to enhance nebulosity without pushing stars up. The tutorial itself was available under
<a href="https://dl.dropboxusercontent.com/u/57910417/Howto_enhance_nebuala_without_pushing_stars.wmv">this</a> link, but not any more,
for some reason. Haven't found any newer links to it. Anyway, you got the idea.

<center><h1>Suggested Work Flow</h1></center>

The transformation by this neural net can be part of PixInsight/Photoshop processing work flow. Something like this:

1. Start from **stretched** LRGB image. Save as 8 bits/channel tif file.
2. Feed to StarNet.
3. Open output in Photoshop, correct some of the worst artifacts that will most likely appear in the image. If there are huge stars
in the image left, you will have to take care of them in some other way.
4. Perhaps use some noise reduction (we don't want to push noise up).
5. Use resulting image to enhance nebulosity using some method (Screen-Mask-Invert for example) or enjoy the result.
6. ?
7. Profit!

<center><h1>Weights for the network</h1></center>

This repository contains only a code base needed to run the net, but does not contain all the weights (which are uploaded into LFS.
Pre-trained weights are also available for now through my dropbox account
because they weight too much (lol) - about 700 Mb. You need to download them and unpack into root folder of starnet (the one with all
python scripts, not into some sub-folder) to begin using StarNet:

<div align="center">
<a href="https://www.dropbox.com/s/atcs42ox4n99w96/starnet_weights.zip?dl=0">LINK</a>
</div>

This will rewrite some files in this repo!

The weights are also uploaded into LFS, but depending how you clone the repo they might or might not download.

<center><h1>Some tips and tricks</h1></center>

1. Do not use heavily processed images for input. If star shapes are unusual (if star reduction techniques were used, too much sharpening,
deconvolution, image was heavily resized, etc) the performance might be much worse than it could be. I am almost sure. Or maybe it will be
better in your case, but that's unlikely.

2. This newral net was trained using data from refractor telescope (FSQ106 + QSI 683 wsg-8), so will work best for data from similar imaging
systems. That's a bit of a bad news for many users of reflector telescopes. If you have long spikes in your images, then the net will not take
care of these spikes very well, I tried and didn't like results too much. What you can do, however, is you can train the net a bit more
using your own data. Just prepare one or two starless images from your data and run training for 20 epochs or so. This should significantly
improve results and make the net much better for **your** data.

3. The point above is valid for all images, for which you are not getting good results. You can prepare a starless version even of a **small
part** of that image (but not smaller than 256x256 pixels) and run training for 20 epochs or so on this image. This should improve quality of
transformation of the whole image. This will take a lot of time, of course, but in the end you not only getting a starless image, but also
train a net so it will perform better next time on a similar image.

4. Also it might help, for example, to make image brighter (darker) if it is unusually dark (bright), or things like that.

5. Sometimes the net will leave small stars in the output, if you feed it very busy image. In this case it is helpful to feed output to the 
net again.

<center><h1>Training Dataset</h1></center>

This is one part I'd like to keep for myself for now, but you can create your own dataset creating starless versions of your images.
One extremely important note: the only difference between two images (original and starless) should be stars, which are replaced
by background in the starless version. The rest of the image should be perfectly intact. If you will throw in a starless image which
is super nice looking, but in a process of creation of this image you altered much more than just stars, this will only degrade
network performance. Also be aware that quality of star removal by the net will never be better than that in your training set, so
if you want a top-notch quality starless images, be ready to provide training images of even higher quality.

I left one training image to show organization of folders my code expects. Inside a folder named 'train' there are two sub-folders named
'original' and starless', both should contain equal number of images with identical name pairs.

<center><h1>Some technical info</h1></center>
 
Throughout the code all input and output images I use are 8 bits per channel **tif** images.
This code should read some other image formats (like jpeg, 16bit tiff, etc), but I did not check all of them.

<center><h1>Prerequisites and installation Guide</h1></center>

for all environments, using conda is strongly encouraged, installation instructions assume a conda install of either Anaconda python or miniconda:
  - https://docs.conda.io/en/latest/miniconda.html

## Windows (New!)

On windows we can now run starnet on GPU on any modern graphics card! (yes AMD and Intel included)

### Prerequisites

Windows 10 Version 1709, 64-bit (Build 16299 or higher) or Windows 11 Version 21H2, 64-bit (Build 22000 or higher)

### Installation

Once anaconda is installed, you can open an "anaconda powershell prompt" to proceed.

We use the environment config file provided to configure and install all the dependencies:

#### With GPU support (Windows):
```
conda env create -f environment-windows.yml
```
#### With CUDA support (linux or windows):
```
conda env create -f environment-lnx-cuda.yml
```
#### CPU only(Mac, Linux, Windows):
```
conda env create -f environment-cpu.yml
```
### Post installation
Initialize the environment with:
```
conda activate starnet
```
And you're ready to go!


Originally tested on:
- Win 10 + Cygwin
- NVidia GeForce 840M 2Gb, compute capability 5.0, CUDA version 9.1

Windows general GPU support tested on:
- Win 10 12H1
- AMD RX 6800-XT 16GB

<center><h1>Usage</h1></center>
 
      
      python.exe -u starnet.py transform <input_image> - The most probable use. This command will transform 
                                                         input image (namely will remove stars) and will 
                                                         create a mask showing changes regions. Output images
                                                         names will be <input_image>_starless.tif and
                                                         <input_image>_mask.tif
      
      python.exe -u starnet.py train                   - Use if you want to train the model some more using
                                                         your training data. This will also output logs and
                                                         showcases of training transformations in 
                                                         './logs' sub-folder.
                                                         
      python.exe -u starnet.py plot                    - Will plot graphs from log files inside './logs' 
                                                         sub-folder.
      
      python.exe -u starnet.py train new               - Use only if you want to train a completely new model,
                                                         erasing all older weights and other output, such as
                                                         logs. Use only if you know what you are doing!
 
      python.exe -u starnet.py test <input_image>      - This will create some test transformations of patches
                                                         of the input. Similar to transform, but instead of
                                                         transforming an entire image, will create showcases
                                                         of transformations. Fast option to take a look at 
                                                         possible result.
                                                         By default output will be in './test' sub-folder.


<center><h1>Couple more examples</h1></center>

More examples can be found <a href="https://www.astrobin.com/339099/0/">here</a>.

<div align="center">
  <img src="https://github.com/nekitmm/starnet/blob/master/for_git/2.jpg"><br><br>
</div>

Original:

<div align="center">
  <img src="https://github.com/nekitmm/starnet/blob/master/for_git/3.jpg"><br><br>
</div>

Starless:

<div align="center">
  <img src="https://github.com/nekitmm/starnet/blob/master/for_git/4.jpg"><br><br>
</div>


<center><h1>FAQ</h1></center>

**What is all this 'python-sudo-mumbo-jumbo'**?

This whole thing works as command line program, which means that there is no graphical interface: you have to
run it in a console using some text commands (like ones you see above) and it outputs text (and writes image files
of course!).

2. Where exactly do I put weights of the network?

All the files you download should be in one folder: all the files with extension .py (starnet.py, train.py, transform.py, etc.) should
be in the same folder with weights for the network (model.ckpt.data-00000-of-00001, model.ckpt.index, model.ckpt.meta, etc.)

<center><h1>Some Troubleshooting</h1></center>

1. <b>Error: 'No package named tensorflow'.</b> Should be pretty self-explanatory: your python can not find tensorflow. That means you did not
run pip to install it (<b>pip install tensorflow</b>) or something went wrong during this step if you did.

2. <b>Error: 'ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory.'</b> You are trying to use GPU version of
tensorflow and you don't have CUDA properly installed.

3. <b>Error: 'ValueError: The passed save_path is not a valid checkpoint: ./model.ckpt.'</b> You did not copy network weights into proper location. See above.

Let me know if you have any other issues with the code. (Preferably through *Astrobin*)

<center><h1>Licenses</h1></center>

Code is available under MIT License, please review LICENSE.md file inside repo. Its very permissive, but no liability
or warranty of any kind.

Weights are available under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
Attribution-NonCommercial-ShareAlike 4.0 International Creative Commons</a> license.

In short:
You are free to use and redistribute them in any medium or format, but only **under the same** license terms.
You can transform, and build your projects upon them.
You can **NOT** use them for commercial purposes.
You must give appropriate credit for usage of these weights.

The weights are distributed on an "AS IS" BASIS WITHOUT WARRANTIES OF ANY KIND, EXPRESS OR IMPLIED.
# astro-rust [![](http://meritbadge.herokuapp.com/astro)](https://crates.io/crates/astro) [![](https://travis-ci.org/saurvs/astro-rust.svg?branch=master)](https://travis-ci.org/saurvs/astro-rust) [![](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/saurvs/astro-rust/blob/master/LICENSE.md)

**Contents**

[API Docs](https://saurvs.github.io/astro-rust/)

* [About](#about)
* [Usage](#usage)
* [Contributing](#contributing)
* [References](#references)

## About

```astro-rust``` is a library of advanced astronomical algorithms for the Rust programming language.

Implemented algorithms include:

* planetary and solar positioning by the complete set of elements of Bretagnon and Francou's VSP087 theory
* lunar positioning by the principle elements of Chapront's ELP-2000/82 theory
* satellite positioning for Saturn and Jupiter
* finding Julian dates, sidereal time, dynamical time, equinoxes, rising and setting times, times of lunar phases
* coordinate transformations
* corrections for precession, nutation, parallax, aberration, atmospheric refraction
* calculation of the physical ephemeris for Mars, Jupiter, and the rings of Saturn
* finding position angles, illuminated fractions, visual magnitudes
* and [much more](https://saurvs.github.io/astro-rust/).

## Usage

* Add the dependency ```astro``` in your ```Cargo.toml```
  ```toml
  [dependencies]
  astro = "2.0.0"
  ```

* Include the crate ```astro``` in your code
  ```rust
  extern crate astro;

  use astro::*;
  ```

* Specify your time of interest using the [Julian day](http://quasar.as.utexas.edu/BillInfo/JulianDatesG.html)
  ```rust
  // for example, the time of the Apollo 11 moon landing

  let day_of_month = time::DayOfMonth{day      : 20,
				 			          hr       : 20,
                                      min      : 18,
                                      sec      : 4.0,
                                      time_zone: 0.0};

  let date = time::Date{year       : 1969,
                        month      : 7, // July
                        decimal_day: time::decimal_day(&day_of_month),
                        cal_type   : time::CalType::Gregorian};

  let julian_day = time::julian_day(&date);

  // for higher accuracy in specifying the time of interest,
  // find the Julian Ephemeris day; this slightly differs from
  // the Julian day by ΔT, which is usually a few seconds. you
  // can get a reported value of it from the Astronomical
  // Almanac, or calculate it using the built-in function

  let delta_t = time::delta_t(date.year, date.month);

  let julian_ephm_day = time::julian_ephemeris_day(julian_day, delta_t);
  ```

* Find the position of the Sun and the Moon with respect to the Earth
  ```rust

  // geocentric ecliptic point and radius vector of the Sun
  let (sun_ecl_point, rad_vec_sun) = sun::geocent_ecl_pos(julian_day);

  // sun_ecl_point.long    - ecliptic longitude (radians)
  // sun_ecl_point.lat     - ecliptic latitude  (radians)
  // rad_vec_sun - distance between the Sun and the Earth (AU)

  // and similarly for the Moon
  let (moon_ecl_point, rad_vec_moon) = lunar::geocent_ecl_pos(julian_day);

  ```

* Find the position of a planet with respect to the Sun
  ```rust
  // the heliocentric point and radius vector of a planet, like Jupiter
  let (jup_long, jup_lat, rad_vec) = planet::heliocent_pos(&planet::Planet::Jupiter, julian_day);

  // or neptune
  let (nep_long, nep_lat, rad_vec) = planet::heliocent_pos(&planet::Planet::Neptune, julian_day);

  // positioning for all the eight planets (and (the dwarf planet) Pluto) is supported
  let (plut_long, plut_lat, rad_vec) = pluto::heliocent_pos(julian_day);
  ```

* Find the geodesic distance between two locations on Earth
  ```rust
	// geodesic distance between the Observatoire de Paris and
    // the US Naval Observatory at Washington DC

    let paris = coords::GeographPoint{long: angle::deg_frm_dms(-2, 20, 14.0).to_radians(),
                                      lat : angle::deg_frm_dms(48, 50, 11.0).to_radians()};

    let washington = coords::GeographPoint{long: angle::deg_frm_dms(77,  3, 56.0).to_radians(),
                                           lat : angle::deg_frm_dms(38, 55, 17.0).to_radians()};

	// angle::deg_frm_dms() converts degrees expressed in degrees,
	// minutes and seconds into a fractional degree

    let distance = planet::earth::geodesic_dist(&paris, &washington); // in meters
  ```

* Convert equatorial coordinates to ecliptic coordinates
  ```rust
	// equatorial coordinates of the star Pollux

    let right_ascension = 116.328942_f64.to_radians();
    let declination = 28.026183_f64.to_radians();

    // mean obliquity of the ecliptic

    let oblq_eclip = 23.4392911_f64.to_radians();

    // you can also get oblq_eclip from ecliptic::mn_oblq_IAU(julian_day)
    // for the Julian day on which the coordinates of the star
    // were observed

    // also make sure to type #[macro_use] before including the crate
    // to use macros

    // now, convert equatorial coordinates to ecliptic coordinates

    let (ecl_long, ecl_lat) = ecl_frm_eq!(right_ascension, declination, oblq_eclip);
  ```

* Convert equatorial coordinates to galactic coordinates
  ```rust
	// equatorial coordinates of the Nova Serpentis 1978

    let right_ascension = angle::deg_frm_hms(17, 48, 59.74).to_radians();
    let declination = angle::deg_frm_dms(-14, 43, 8.2).to_radians();

    // convert to galactic coordinates

    let (gal_long, gal_lat) = gal_frm_eq!(right_ascension, declination);
  ```

* Correct for nutation in different coordinate systems
  ```rust
  // nutation in ecliptic longitude and obliquity of the ecliptic
  let (nut_in_long, nut_in_oblq) = nutation::nutation(julian_day);

  // nutation in equatorial coordinates
  let (nut_in_asc, nut_in_dec) = nutation::nutation_in_eq_coords(julian_day);
  ```

## Contributing

Anyone interested to contribute in any way possible is encouraged to do so. Not all the algorithms in Meeus's book have been implemented yet. Documentation and tests need to be written for them as well. Refactored code and minor optimizations for the existing code are also welcome.

The end goal (of this project) is to build a modern, well-tested, well-documented library of algorithms for future use in astronomy. And Rust is very much the right choice for building that.

A fun suggestion is the addition of the recent [IAU 2000/2006 precession-nutation model](http://62.161.69.131/iers/conv2010/conv2010_c5.html). This method improves upon the existing model implemented here *"by taking into account the effect of mantle anelasticity, ocean tides, electromagnetic couplings produced between the fluid outer core and the mantle as well as between the solid inner core and fluid outer core"*.

## References

The main reference used as the source of algorithms is the famous book *Astronomical Algorithms by Jean Meeus*, whose almost every chapter has been addressed here, with functions that are well-documented and tests that use example data from the book; in some cases, such as ΔT approximation and planetary heliocentric positioning, more accurate methods have been implemented.

* Most algorithms: [Astronomical Algorithms, 2nd edition (Meeus)](http://www.willbell.com/math/mc1.htm)
* Planetary heliocentric positioning: [VSOP87-D](http://cdsarc.u-strasbg.fr/viz-bin/qcat?VI/81/)
* Approximating ΔT: [Five Millennium Canon of Solar Eclipses (Espenak and Meeus)](http://eclipse.gsfc.nasa.gov/SEcat5/deltatpoly.html)
* Some physical constants: [World Geodetic System 1984](https://confluence.qps.nl/pages/viewpage.action?pageId=29855173)
=========
Photutils
=========

|PyPI Version| |Conda Version| |PyPI Downloads| |Astropy|

|CI Status| |Codecov Status| |Latest RTD Status|

Photutils is an `Astropy`_ package for detection and photometry of
astronomical sources.

Please see the `online documentation
<https://photutils.readthedocs.io>`_ for `installation instructions
<https://photutils.readthedocs.io/en/stable/install.html>`_ and usage
information.


Citing Photutils
----------------

|Zenodo|

If you use Photutils for a project that leads to a publication,
whether directly or as a dependency of another package, please include
the following acknowledgment::

    This research made use of Photutils, an Astropy package for
    detection and photometry of astronomical sources (Bradley et al.
    <YEAR>).

where (Bradley et al. <YEAR>) is a citation to the `Zenodo record
<https://doi.org/10.5281/zenodo.596036>`_ of the Photutils
version that was used. We also encourage citations in the
main text wherever appropriate. Please see the `CITATION
<https://github.com/astropy/photutils/blob/main/photutils/CITATION.rst>`_
file for details and an example BibTeX entry.


License
-------

Photutils is licensed under a 3-clause BSD license.  Please see the
`LICENSE
<https://github.com/astropy/photutils/blob/main/LICENSE.rst>`_ file
for details.


.. |PyPI Version| image::  https://img.shields.io/pypi/v/photutils.svg?logo=pypi&logoColor=white&label=PyPI
    :target: https://pypi.org/project/photutils/
    :alt: PyPI Latest Release

.. |Conda Version| image:: https://img.shields.io/conda/vn/conda-forge/photutils
    :target: https://anaconda.org/conda-forge/photutils
    :alt: Conda Latest Release

.. |PyPI Downloads| image:: https://img.shields.io/pypi/dm/photutils?label=PyPI%20Downloads
    :target: https://pypistats.org/packages/photutils
    :alt: PyPI Downloads

.. |Astropy| image:: https://img.shields.io/badge/powered%20by-AstroPy-orange.svg?style=flat
    :target: https://www.astropy.org/
    :alt: Powered by Astropy

.. |Zenodo| image:: https://zenodo.org/badge/2640766.svg
    :target: https://zenodo.org/badge/latestdoi/2640766
    :alt: Zenodo Latest DOI

.. |CI Status| image:: https://github.com/astropy/photutils/workflows/CI%20Tests/badge.svg#
    :target: https://github.com/astropy/photutils/actions
    :alt: CI Status

.. |Codecov Status| image:: https://img.shields.io/codecov/c/github/astropy/photutils?logo=codecov
    :target: https://codecov.io/gh/astropy/photutils
    :alt: Coverage Status

.. |Stable RTD Status| image:: https://img.shields.io/readthedocs/photutils/latest.svg?logo=read%20the%20docs&logoColor=white&label=Docs&version=stable
    :target: https://photutils.readthedocs.io/en/stable/
    :alt: Stable Documentation Status

.. |Latest RTD Status| image:: https://img.shields.io/readthedocs/photutils/latest.svg?logo=read%20the%20docs&logoColor=white&label=Docs&version=latest
    :target: https://photutils.readthedocs.io/en/latest/
    :alt: Latest Documentation Status

.. _Astropy: https://www.astropy.org/
